# -*- coding: utf-8 -*-
"""
æ¨¡å‹è¯„ä¼°é¡µé¢ (Model Evaluation Page)
æ­¤æ¨¡å—æä¾›è®­ç»ƒå®Œæˆæ¨¡å‹çš„è¯¦ç»†æ€§èƒ½åˆ†æå’Œå¯¹æ¯”åŠŸèƒ½

ä¸»è¦åŠŸèƒ½:
1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ
2. é¢„æµ‹ç»“æœå¯è§†åŒ–
3. è¯¯å·®åˆ†æå’Œæ®‹å·®æ£€éªŒ
4. æ¨¡å‹è¯Šæ–­å·¥å…·
5. è¯¦ç»†è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ

æŠ€æœ¯æ ˆ:
- streamlit: Webåº”ç”¨æ¡†æ¶
- pandas: æ•°æ®å¤„ç†å’Œåˆ†æ
- numpy: æ•°å­¦è®¡ç®—
- streamlit_echarts: å›¾è¡¨å¯è§†åŒ–
- sklearn: æœºå™¨å­¦ä¹ è¯„ä¼°æŒ‡æ ‡
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import json
from pathlib import Path
import sys
import traceback
from streamlit_echarts import st_echarts
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy import stats
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = str(Path(__file__).parent.parent)
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥å·¥å…·å‡½æ•°
try:
    from src.utils.session import get_state, set_state
    from src.utils.visualization import ModelVisualization
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºç©ºå‡½æ•°
    def get_state(key, default=None):
        return st.session_state.get(key, default)
    
    def set_state(key, value):
        st.session_state[key] = value

# å¯¼å…¥ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°
arima_import_success = False
try:
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    import sys
    from pathlib import Path
    project_root = str(Path(__file__).parent.parent)
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    
    from src.models.arima_model import (
        create_timeseries_chart,
        create_histogram_chart,
        prepare_arima_charts
    )
    arima_import_success = True
except ImportError as e:
    arima_import_error = str(e)
    # åˆ›å»ºå ä½å‡½æ•°
    def create_timeseries_chart(*args, **kwargs):
        return {"title": {"text": "å›¾è¡¨å‡½æ•°æœªå¯¼å…¥"}}
    def create_histogram_chart(*args, **kwargs):
        return {"title": {"text": "å›¾è¡¨å‡½æ•°æœªå¯¼å…¥"}}
    def prepare_arima_charts(*args, **kwargs):
        return {"residuals_chart": None, "residuals_hist": None}
    
    # åˆ›å»ºå¤‡ç”¨çš„å›¾è¡¨å‡½æ•°ï¼Œä½¿ç”¨ä¸æ¨¡å‹è®­ç»ƒé¡µé¢ç›¸åŒçš„å®ç°
    def create_timeseries_chart_backup(data, title='æ—¶é—´åºåˆ—å›¾'):
        """å¤‡ç”¨æ—¶é—´åºåˆ—å›¾è¡¨å‡½æ•°"""
        if isinstance(data, pd.DataFrame):
            # å¦‚æœæ˜¯DataFrameï¼Œå–ç¬¬ä¸€åˆ—æ•°æ®
            series_data = data.iloc[:, 0].values
            dates = data.index.tolist() if hasattr(data.index, 'tolist') else list(range(len(series_data)))
        else:
            # å¦‚æœæ˜¯Seriesæˆ–æ•°ç»„
            series_data = data if hasattr(data, '__iter__') else [data]
            dates = list(range(len(series_data)))
        
        option = {
            "title": {
                "text": title,
                "left": "center",
                "textStyle": {"fontSize": 14}
            },
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": [str(d) for d in dates],
                "axisLabel": {"rotate": 45}
            },
            "yAxis": {
                "type": "value"
            },
            "series": [{
                "type": "line",
                "data": [float(x) for x in series_data],
                "lineStyle": {"color": "#5470c6", "width": 2},
                "symbol": "none"
            }],
            "dataZoom": [{
                "type": "slider",
                "start": 0,
                "end": 100
            }]
        }
        return option
    
    def create_histogram_chart_backup(data, title='åˆ†å¸ƒç›´æ–¹å›¾', bins=30):
        """å¤‡ç”¨ç›´æ–¹å›¾å‡½æ•°"""
        if hasattr(data, 'values'):
            data = data.values
        if hasattr(data, 'flatten'):
            data = data.flatten()
        
        # è¿‡æ»¤NaNå€¼
        clean_data = [float(x) for x in data if not pd.isna(x) and not np.isnan(float(x))]
        
        if not clean_data:
            return {
                "title": {"text": f"{title} - æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
                "xAxis": {"type": "category", "data": []},
                "yAxis": {"type": "value"},
                "series": [{"type": "bar", "data": []}]
            }
        
        hist, bin_edges = np.histogram(clean_data, bins=bins)
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
        
        option = {
            "title": {
                "text": title,
                "left": "center",
                "textStyle": {"fontSize": 14}
            },
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": [f"{float(x):.3f}" for x in bin_centers],
                "name": "å€¼"
            },
            "yAxis": {
                "type": "value",
                "name": "é¢‘æ¬¡"
            },
            "series": [{
                "type": "bar",
                "data": [int(x) for x in hist],
                "itemStyle": {"color": "#73c0de"}
            }]
        }
        return option
    
    # å¦‚æœARIMAå‡½æ•°å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å‡½æ•°
    if not arima_import_success:
        create_timeseries_chart = create_timeseries_chart_backup
        create_histogram_chart = create_histogram_chart_backup

def fix_datetime_for_arrow(df):
    """
    ä¿®å¤DataFrameä¸­çš„æ—¶é—´æˆ³æ•°æ®ä»¥å…¼å®¹PyArrow
    
    å‚æ•°:
        df (DataFrame): åŒ…å«æ—¶é—´æˆ³æ•°æ®çš„DataFrame
        
    è¿”å›:
        DataFrame: ä¿®å¤åçš„DataFrame
    """
    df_fixed = df.copy()
    
    # æ£€æŸ¥æ¯ä¸€åˆ—æ˜¯å¦åŒ…å«æ—¶é—´æˆ³æ•°æ®
    for col in df_fixed.columns:
        if df_fixed[col].dtype == 'datetime64[ns]':
            # å°†çº³ç§’ç²¾åº¦çš„æ—¶é—´æˆ³è½¬æ¢ä¸ºå¾®ç§’ç²¾åº¦
            df_fixed[col] = pd.to_datetime(df_fixed[col]).dt.floor('us')
        elif pd.api.types.is_datetime64_any_dtype(df_fixed[col]):
            # å¤„ç†å…¶ä»–æ—¶é—´æˆ³æ ¼å¼
            try:
                df_fixed[col] = pd.to_datetime(df_fixed[col]).dt.floor('us')
            except Exception as e:
                st.warning(f"åˆ— {col} çš„æ—¶é—´æˆ³è½¬æ¢å¤±è´¥: {e}")
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                df_fixed[col] = df_fixed[col].astype(str)
    
    return df_fixed

# ä¿®å¤PyTorchä¸Streamlitçš„å…¼å®¹æ€§é—®é¢˜
torch.classes.__path__ = []

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨¡å‹è¯„ä¼°",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜å’Œç®€ä»‹
st.title("ğŸ“ˆ æ¨¡å‹è¯„ä¼°")
st.markdown("å¯¹è®­ç»ƒå®Œæˆçš„æ¨¡å‹è¿›è¡Œè¯¦ç»†æ€§èƒ½åˆ†æå’Œå¯¹æ¯”è¯„ä¼°")

# æ˜¾ç¤ºARIMAå›¾è¡¨å‡½æ•°å¯¼å…¥çŠ¶æ€
if arima_import_success:
    st.success("âœ… ARIMAå›¾è¡¨å‡½æ•°å¯¼å…¥æˆåŠŸ")
else:
    st.error(f"âŒ æ— æ³•å¯¼å…¥ARIMAå›¾è¡¨å‡½æ•°: {arima_import_error}")
    st.warning("è¯¯å·®åˆ†æå›¾è¡¨å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºï¼Œè¯·æ£€æŸ¥ARIMAæ¨¡å‹æ–‡ä»¶")

def check_model_availability():
    """æ£€æŸ¥å¯ç”¨çš„è®­ç»ƒæ¨¡å‹"""
    available_models = []
    model_info = {}
    
    # æ£€æŸ¥LSTMæ¨¡å‹
    lstm_available = False
    # æ›´ä¸¥æ ¼çš„LSTMæ£€æµ‹ï¼šå¿…é¡»æœ‰æ˜ç¡®çš„LSTMè®­ç»ƒå®Œæˆæ ‡å¿—æˆ–è€…æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    if st.session_state.get('lstm_training_complete', False):
        lstm_available = True
    elif st.session_state.get('training_complete', False) and st.session_state.get('trained_model') is not None:
        # åªæœ‰å½“æœ‰å®é™…çš„è®­ç»ƒæ¨¡å‹æ—¶æ‰è®¤ä¸ºLSTMå¯ç”¨
        lstm_available = True
    
    if lstm_available:
        available_models.append("LSTM")
        metrics = st.session_state.get('model_metrics', {})
        model_info["LSTM"] = {
            "status": "å·²è®­ç»ƒ",
            "metrics": metrics,
            "training_time": st.session_state.get('training_time', "æœªçŸ¥"),
            "has_predictions": 'y_test' in st.session_state or 'lstm_test_predictions' in st.session_state
        }
    
    # æ£€æŸ¥ARIMAæ¨¡å‹
    arima_available = False
    if st.session_state.get('arima_training_complete', False):
        if st.session_state.get('arima_model') is not None:
            arima_available = True
        elif 'arima_model_metrics' in st.session_state and st.session_state['arima_model_metrics']:
            arima_available = True
        elif 'arima_training_result' in st.session_state:
            arima_available = True
    
    if arima_available:
        available_models.append("ARIMA")
        metrics = st.session_state.get('arima_model_metrics', {})
        model_info["ARIMA"] = {
            "status": "å·²è®­ç»ƒ",
            "metrics": metrics,
            "training_time": st.session_state.get('arima_training_time', "æœªçŸ¥"),
            "has_predictions": 'arima_training_result' in st.session_state
        }
    
    return available_models, model_info

def create_model_comparison_radar():
    """åˆ›å»ºæ¨¡å‹æ€§èƒ½é›·è¾¾å›¾"""
    # ç¤ºä¾‹æ•°æ®ï¼Œå®é™…åº”è¯¥ä»session stateè·å–
    radar_option = {
        "title": {
            "text": "æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾",
            "left": "center",
            "textStyle": {"fontSize": 16}
        },
        "tooltip": {
            "trigger": "item"
        },
        "legend": {
            "data": ["LSTM", "ARIMA"],
            "bottom": "10px"
        },
        "radar": {
            "indicator": [
                {"name": "å‡†ç¡®æ€§", "max": 100},
                {"name": "ç¨³å®šæ€§", "max": 100},
                {"name": "é€Ÿåº¦", "max": 100},
                {"name": "é²æ£’æ€§", "max": 100},
                {"name": "å¯è§£é‡Šæ€§", "max": 100}
            ],
            "center": ["50%", "50%"],
            "radius": "70%"
        },
        "series": [{
            "type": "radar",
            "data": [
                {
                    "value": [85, 90, 70, 80, 60],
                    "name": "LSTM",
                    "itemStyle": {"color": "#5470c6"}
                },
                {
                    "value": [75, 85, 95, 85, 90],
                    "name": "ARIMA",
                    "itemStyle": {"color": "#91cc75"}
                }
            ]
        }]
    }
    return radar_option

def create_prediction_comparison_chart(dates, actual_values, lstm_pred=None, arima_pred=None):
    """åˆ›å»ºé¢„æµ‹å¯¹æ¯”å›¾è¡¨"""
    # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯PythonåŸç”Ÿç±»å‹
    actual_values = np.array(actual_values).astype(float).tolist()
    
    series_data = [
        {
            "name": "å®é™…å€¼",
            "type": "line",
            "smooth": True,
            "data": actual_values,
            "showSymbol": False,
            "connectNulls": True
        }
    ]
    
    legend_data = ["å®é™…å€¼"]
    
    if lstm_pred is not None:
        lstm_pred = np.array(lstm_pred).astype(float).tolist()
        series_data.append({
            "name": "LSTMé¢„æµ‹",
            "type": "line",
            "smooth": True,
            "data": lstm_pred,
            "showSymbol": False,
            "connectNulls": True
        })
        legend_data.append("LSTMé¢„æµ‹")
    
    if arima_pred is not None:
        arima_pred = np.array(arima_pred).astype(float).tolist()
        series_data.append({
            "name": "ARIMAé¢„æµ‹",
            "type": "line",
            "smooth": True,
            "data": arima_pred,
            "showSymbol": False,
            "connectNulls": True
        })
        legend_data.append("ARIMAé¢„æµ‹")
    
    option = {
        "title": {
            "text": "é¢„æµ‹å€¼ vs å®é™…å€¼å¯¹æ¯”",
            "left": "center"
        },
        "tooltip": {
            "trigger": "axis",
            "axisPointer": {"type": "shadow"}
        },
        "legend": {
            "data": legend_data,
            "top": "30px"
        },
        "grid": {
            "left": "3%",
            "right": "4%",
            "bottom": "3%",
            "containLabel": True
        },
        "toolbox": {
            "feature": {
                "saveAsImage": {}
            }
        },
        "xAxis": {
            "type": "category",
            "boundaryGap": False,
            "data": dates
        },
        "yAxis": {
            "type": "value",
            "scale": True,
            "splitLine": {
                "show": True
            }
        },
        "dataZoom": [
            {
                "type": "inside",
                "start": 0,
                "end": 100
            },
            {
                "start": 0,
                "end": 100
            }
        ],
        "series": series_data
    }
    return option

def create_error_distribution_chart(errors, model_name="æ¨¡å‹"):
    """åˆ›å»ºè¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(errors, 'values'):
            errors = errors.values
        if hasattr(errors, 'flatten'):
            errors = errors.flatten()
        
        # è¿‡æ»¤NaNå€¼
        clean_errors = []
        for err in errors:
            try:
                if not pd.isna(err) and not np.isnan(float(err)):
                    clean_errors.append(float(err))
            except (ValueError, TypeError):
                continue
        
        if not clean_errors:
            return {
                "title": {"text": f"{model_name}è¯¯å·®åˆ†å¸ƒ - æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
                "xAxis": {"type": "category", "data": []},
                "yAxis": {"type": "value"},
                "series": [{"type": "bar", "data": []}]
            }
        
        # è®¡ç®—ç›´æ–¹å›¾æ•°æ®
        hist, bin_edges = np.histogram(clean_errors, bins=30)
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
        
        option = {
            "title": {
                "text": f"{model_name}è¯¯å·®åˆ†å¸ƒ",
                "left": "center",
                "textStyle": {"fontSize": 14}
            },
            "tooltip": {
                "trigger": "axis"
            },
            "xAxis": {
                "type": "category",
                "data": [f"{float(x):.3f}" for x in bin_centers],
                "name": "è¯¯å·®å€¼"
            },
            "yAxis": {
                "type": "value",
                "name": "é¢‘æ¬¡"
            },
            "series": [{
                "type": "bar",
                "data": [int(x) for x in hist],
                "itemStyle": {"color": "#73c0de"}
            }]
        }
        return option
    except Exception as e:
        st.error(f"åˆ›å»ºè¯¯å·®åˆ†å¸ƒå›¾è¡¨å¤±è´¥: {e}")
        return {
            "title": {"text": f"{model_name}è¯¯å·®åˆ†å¸ƒ - åˆ›å»ºå¤±è´¥", "left": "center"},
            "xAxis": {"type": "category", "data": []},
            "yAxis": {"type": "value"},
            "series": [{"type": "bar", "data": []}]
        }

def create_residual_analysis_chart(residuals, dates):
    """åˆ›å»ºæ®‹å·®åˆ†æå›¾è¡¨"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(residuals, 'values'):
            residuals = residuals.values
        if hasattr(residuals, 'flatten'):
            residuals = residuals.flatten()
        
        # ç¡®ä¿æ•°æ®æ˜¯PythonåŸç”Ÿç±»å‹ï¼Œå¤„ç†NaNå€¼
        clean_residuals = []
        clean_dates = []
        for i, (res, date) in enumerate(zip(residuals, dates)):
            try:
                if pd.isna(res) or np.isnan(float(res)):
                    continue  # è·³è¿‡NaNå€¼
                clean_residuals.append(float(res))
                clean_dates.append(str(date))
            except (ValueError, TypeError):
                continue  # è·³è¿‡æ— æ³•è½¬æ¢çš„å€¼
        
        if not clean_residuals:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¿”å›ç©ºå›¾è¡¨
            return {
                "title": {"text": "æ®‹å·®åˆ†æ - æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
                "xAxis": {"type": "category", "data": []},
                "yAxis": {"type": "value"},
                "series": [{"type": "line", "data": []}]
            }
        
        option = {
            "title": {
                "text": "æ®‹å·®æ—¶é—´åºåˆ—åˆ†æ",
                "left": "center",
                "textStyle": {"fontSize": 14}
            },
            "tooltip": {
                "trigger": "axis"
            },
            "xAxis": {
                "type": "category",
                "data": clean_dates,
                "axisLabel": {"rotate": 45}
            },
            "yAxis": {
                "type": "value",
                "name": "æ®‹å·®"
            },
            "series": [{
                "type": "line",
                "data": clean_residuals,
                "lineStyle": {"color": "#ee6666", "width": 1},
                "symbol": "none"
            }],
            "dataZoom": [{
                "type": "slider",
                "start": 0,
                "end": 100
            }]
        }
        return option
    except Exception as e:
        st.error(f"åˆ›å»ºæ®‹å·®åˆ†æå›¾è¡¨å¤±è´¥: {e}")
        return {
            "title": {"text": "æ®‹å·®åˆ†æ - åˆ›å»ºå¤±è´¥", "left": "center"},
            "xAxis": {"type": "category", "data": []},
            "yAxis": {"type": "value"},
            "series": [{"type": "line", "data": []}]
        }

def create_scatter_plot(actual, predicted, model_name="æ¨¡å‹"):
    """åˆ›å»ºæ•£ç‚¹å›¾ï¼šé¢„æµ‹vså®é™…"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(actual, 'values'):
            actual = actual.values
        if hasattr(predicted, 'values'):
            predicted = predicted.values
        if hasattr(actual, 'flatten'):
            actual = actual.flatten()
        if hasattr(predicted, 'flatten'):
            predicted = predicted.flatten()
        
        # è¿‡æ»¤NaNå€¼ï¼Œç¡®ä¿ä¸¤ä¸ªæ•°ç»„é•¿åº¦ä¸€è‡´
        clean_actual = []
        clean_predicted = []
        for i, (a, p) in enumerate(zip(actual, predicted)):
            try:
                if not pd.isna(a) and not pd.isna(p) and not np.isnan(float(a)) and not np.isnan(float(p)):
                    clean_actual.append(float(a))
                    clean_predicted.append(float(p))
            except (ValueError, TypeError):
                continue
        
        if not clean_actual or not clean_predicted:
            return {
                "title": {"text": f"{model_name}é¢„æµ‹æ•£ç‚¹å›¾ - æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
                "xAxis": {"type": "value"},
                "yAxis": {"type": "value"},
                "series": [{"type": "scatter", "data": []}]
            }
        
        # è®¡ç®—RÂ²
        r2 = float(r2_score(clean_actual, clean_predicted))
        
        # åˆ›å»ºå¯¹è§’çº¿æ•°æ®ï¼ˆå®Œç¾é¢„æµ‹çº¿ï¼‰
        min_val = float(min(min(clean_actual), min(clean_predicted)))
        max_val = float(max(max(clean_actual), max(clean_predicted)))
        diagonal_line = [min_val, max_val]
        
        option = {
            "title": {
                "text": f"{model_name}é¢„æµ‹æ•£ç‚¹å›¾ (RÂ² = {r2:.3f})",
                "left": "center"
            },
            "tooltip": {
                "trigger": "item",
                "formatter": "å®é™…å€¼: {data[0]}<br/>é¢„æµ‹å€¼: {data[1]}"
            },
            "grid": {
                "left": "3%",
                "right": "4%",
                "bottom": "3%",
                "containLabel": True
            },
            "toolbox": {
                "feature": {
                    "saveAsImage": {}
                }
            },
            "xAxis": {
                "type": "value",
                "name": "å®é™…å€¼",
                "min": min_val,
                "max": max_val
            },
            "yAxis": {
                "type": "value",
                "name": "é¢„æµ‹å€¼",
                "min": min_val,
                "max": max_val
            },
            "series": [
                {
                    "type": "scatter",
                    "data": [[clean_actual[i], clean_predicted[i]] for i in range(len(clean_actual))],
                    "itemStyle": {"color": "#5470c6", "opacity": 0.6},
                    "symbolSize": 6
                },
                {
                    "type": "line",
                    "data": [[diagonal_line[0], diagonal_line[0]], [diagonal_line[1], diagonal_line[1]]],
                    "lineStyle": {"color": "#ee6666", "type": "dashed"},
                    "symbol": "none",
                    "name": "å®Œç¾é¢„æµ‹çº¿"
                }
            ]
        }
        return option
    except Exception as e:
        st.error(f"åˆ›å»ºæ•£ç‚¹å›¾å¤±è´¥: {e}")
        return {
            "title": {"text": f"{model_name}é¢„æµ‹æ•£ç‚¹å›¾ - åˆ›å»ºå¤±è´¥", "left": "center"},
            "xAxis": {"type": "value"},
            "yAxis": {"type": "value"},
            "series": [{"type": "scatter", "data": []}]
        }

def calculate_model_metrics(actual, predicted):
    """è®¡ç®—æ¨¡å‹è¯„ä¼°æŒ‡æ ‡"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(actual, 'values'):
            actual = actual.values
        if hasattr(predicted, 'values'):
            predicted = predicted.values
        if hasattr(actual, 'flatten'):
            actual = actual.flatten()
        if hasattr(predicted, 'flatten'):
            predicted = predicted.flatten()
        
        # è¿‡æ»¤NaNå€¼ï¼Œç¡®ä¿ä¸¤ä¸ªæ•°ç»„é•¿åº¦ä¸€è‡´
        clean_actual = []
        clean_predicted = []
        for i, (a, p) in enumerate(zip(actual, predicted)):
            try:
                if not pd.isna(a) and not pd.isna(p) and not np.isnan(float(a)) and not np.isnan(float(p)):
                    clean_actual.append(float(a))
                    clean_predicted.append(float(p))
            except (ValueError, TypeError):
                continue
        
        if not clean_actual or not clean_predicted:
            return {
                "MSE": 0.0,
                "RMSE": 0.0,
                "MAE": 0.0,
                "MAPE": 0.0,
                "æ–¹å‘å‡†ç¡®ç‡": 0.0,
                "RÂ²": 0.0
            }
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        actual_array = np.array(clean_actual)
        predicted_array = np.array(clean_predicted)
        
        mse = float(mean_squared_error(actual_array, predicted_array))
        rmse = float(np.sqrt(mse))
        mae = float(mean_absolute_error(actual_array, predicted_array))
        
        # è®¡ç®—MAPEï¼Œé¿å…é™¤é›¶é”™è¯¯
        try:
            mape = float(np.mean(np.abs((actual_array - predicted_array) / actual_array)) * 100)
        except (ZeroDivisionError, RuntimeWarning):
            mape = 0.0
        
        # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡
        if len(actual_array) > 1:
            actual_direction = np.sign(actual_array[1:] - actual_array[:-1])
            pred_direction = np.sign(predicted_array[1:] - predicted_array[:-1])
            direction_accuracy = float(np.mean(actual_direction == pred_direction) * 100)
        else:
            direction_accuracy = 0.0
        
        # è®¡ç®—RÂ²
        r2 = float(r2_score(actual_array, predicted_array))
        
        return {
            "MSE": mse,
            "RMSE": rmse,
            "MAE": mae,
            "MAPE": mape,
            "æ–¹å‘å‡†ç¡®ç‡": direction_accuracy,
            "RÂ²": r2
        }
    except Exception as e:
        st.error(f"è®¡ç®—æ¨¡å‹æŒ‡æ ‡å¤±è´¥: {e}")
        return {
            "MSE": 0.0,
            "RMSE": 0.0,
            "MAE": 0.0,
            "MAPE": 0.0,
            "æ–¹å‘å‡†ç¡®ç‡": 0.0,
            "RÂ²": 0.0
        }

def get_prediction_data():
    """
    ç»Ÿä¸€è·å–é¢„æµ‹æ•°æ®å’Œå®é™…å€¼
    
    è¿”å›:
        tuple: (actual_values, lstm_pred, arima_pred, dates, has_real_data)
    """
    has_real_data = False
    dates = []
    actual_values = []
    lstm_pred = None
    arima_pred = None
    
    # å°è¯•è·å–çœŸå®çš„æµ‹è¯•æ•°æ®å’Œé¢„æµ‹ç»“æœ
    if 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
        df = st.session_state['raw_data'].copy()
        
        # ä¿®å¤æ•°æ®ç±»å‹é—®é¢˜
        try:
            # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
            numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯æ­£ç¡®çš„æ—¥æœŸæ—¶é—´æ ¼å¼
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                # ç§»é™¤æ— æ•ˆçš„æ—¥æœŸ
                df = df.dropna(subset=['Date'])
                # æŒ‰æ—¥æœŸæ’åº
                df = df.sort_values('Date').reset_index(drop=True)
        except Exception as e:
            st.warning(f"æ•°æ®ç±»å‹ä¿®å¤å¤±è´¥: {e}")
            return [], None, None, [], False
        
        # é¦–å…ˆå°è¯•è·å–ç»Ÿä¸€çš„actual_valuesåŸºå‡†
        base_actual_values = []
        
        # è·å–LSTMé¢„æµ‹æ•°æ®
        if st.session_state.get('lstm_training_complete', False):
            try:
                # ä¼˜å…ˆä½¿ç”¨ä¿å­˜çš„é¢„æµ‹ç»“æœ
                if 'lstm_test_predictions' in st.session_state:
                    lstm_pred = st.session_state['lstm_test_predictions']
                    
                    # å…³é”®ä¿®å¤ï¼šç›´æ¥ä»åŸå§‹æ•°æ®è·å–çœŸå®çš„å®é™…å€¼ï¼Œä¸è®­ç»ƒé¡µé¢ä¿æŒä¸€è‡´
                    train_test_ratio = st.session_state.get('train_test_ratio', 0.8)
                    
                    # è·å–ç›®æ ‡åˆ—ï¼ˆé€šå¸¸æ˜¯Closeï¼‰
                    target_column = 'Close'  # é»˜è®¤ä½¿ç”¨Closeåˆ—
                    if 'selected_features' in st.session_state:
                        selected_features = st.session_state['selected_features']
                        # å¦‚æœCloseåœ¨é€‰æ‹©çš„ç‰¹å¾ä¸­ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾
                        if 'Close' in selected_features:
                            target_column = 'Close'
                        elif selected_features:
                            target_column = selected_features[0]
                    
                    # ä»åŸå§‹æ•°æ®ä¸­è·å–çœŸå®çš„æµ‹è¯•é›†å®é™…å€¼
                    if target_column in df.columns:
                        # ä½¿ç”¨ä¸ARIMAå®Œå…¨ä¸€è‡´çš„æ•°æ®åˆ’åˆ†æ–¹å¼
                        train_size = int(len(df) * train_test_ratio)
                        test_actual_values = df[target_column].iloc[train_size:].values
                        
                        # ç°åœ¨LSTMæµ‹è¯•é›†åº”è¯¥ä¸ARIMAæµ‹è¯•é›†å¤§å°ä¸€è‡´
                        # ä½†ç”±äºåºåˆ—åˆ›å»ºï¼ŒLSTMé¢„æµ‹æ•°é‡å¯èƒ½ä»ç„¶å°‘äºåŸå§‹æµ‹è¯•é›†
                        if len(lstm_pred) < len(test_actual_values):
                            # æˆªå–å¯¹åº”é•¿åº¦çš„å®é™…å€¼ï¼Œä»æµ‹è¯•é›†æœ«å°¾å¼€å§‹
                            base_actual_values = test_actual_values[-len(lstm_pred):]
                        elif len(lstm_pred) > len(test_actual_values):
                            # å¦‚æœLSTMé¢„æµ‹ç‚¹æ•°å¤šäºå®é™…å€¼ï¼Œæˆªå–LSTMé¢„æµ‹
                            lstm_pred = lstm_pred[:len(test_actual_values)]
                            base_actual_values = test_actual_values
                        else:
                            base_actual_values = test_actual_values
                        
                        if len(base_actual_values) > 0 and len(lstm_pred) > 0:
                            has_real_data = True
                    
                # å¦‚æœæ²¡æœ‰ä¿å­˜çš„é¢„æµ‹ç»“æœï¼Œå°è¯•é‡æ–°ç”Ÿæˆ
                elif 'trained_model' in st.session_state and 'X_test' in st.session_state:
                    model = st.session_state['trained_model']
                    X_test = st.session_state['X_test']
                    target_scaler = st.session_state.get('target_scaler')
                    
                    # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
                    if not isinstance(X_test, (int, float)):
                        # è½¬æ¢ä¸ºtorch tensor
                        if not isinstance(X_test, torch.Tensor):
                            X_test_tensor = torch.FloatTensor(X_test)
                        else:
                            X_test_tensor = X_test
                        
                        model.eval()
                        with torch.no_grad():
                            predictions = model(X_test_tensor)
                            lstm_pred = predictions.detach().cpu().numpy().flatten()
                            
                            # åå½’ä¸€åŒ–é¢„æµ‹å€¼
                            if target_scaler is not None:
                                lstm_pred = target_scaler.inverse_transform(lstm_pred.reshape(-1, 1)).flatten()
                            
                            # è·å–çœŸå®çš„å®é™…å€¼ï¼ˆä¸ä¸Šé¢çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
                            train_test_ratio = st.session_state.get('train_test_ratio', 0.8)
                            target_column = 'Close'
                            if 'selected_features' in st.session_state:
                                selected_features = st.session_state['selected_features']
                                if 'Close' in selected_features:
                                    target_column = 'Close'
                                elif selected_features:
                                    target_column = selected_features[0]
                            
                            if target_column in df.columns:
                                train_size = int(len(df) * train_test_ratio)
                                test_actual_values = df[target_column].iloc[train_size:].values
                                
                                # ç°åœ¨LSTMæµ‹è¯•é›†åº”è¯¥ä¸ARIMAæµ‹è¯•é›†å¤§å°ä¸€è‡´
                                # ä½†ç”±äºåºåˆ—åˆ›å»ºï¼ŒLSTMé¢„æµ‹æ•°é‡å¯èƒ½ä»ç„¶å°‘äºåŸå§‹æµ‹è¯•é›†
                                if len(lstm_pred) < len(test_actual_values):
                                    # æˆªå–å¯¹åº”é•¿åº¦çš„å®é™…å€¼ï¼Œä»æµ‹è¯•é›†æœ«å°¾å¼€å§‹
                                    base_actual_values = test_actual_values[-len(lstm_pred):]
                                elif len(lstm_pred) > len(test_actual_values):
                                    # å¦‚æœLSTMé¢„æµ‹ç‚¹æ•°å¤šäºå®é™…å€¼ï¼Œæˆªå–LSTMé¢„æµ‹
                                    lstm_pred = lstm_pred[:len(test_actual_values)]
                                    base_actual_values = test_actual_values
                                else:
                                    base_actual_values = test_actual_values
                            
                            has_real_data = True
                            
            except Exception as e:
                st.warning(f"è·å–LSTMé¢„æµ‹æ•°æ®å¤±è´¥: {e}")
        
        # è·å–ARIMAé¢„æµ‹æ•°æ®
        if st.session_state.get('arima_training_complete', False) and 'arima_training_result' in st.session_state:
            try:
                arima_result = st.session_state['arima_training_result']
                if 'test_pred' in arima_result:
                    # ç¡®ä¿ARIMAé¢„æµ‹æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
                    arima_pred_raw = arima_result['test_pred']
                    if hasattr(arima_pred_raw, 'values'):
                        arima_pred = arima_pred_raw.values.flatten()
                    elif hasattr(arima_pred_raw, 'flatten'):
                        arima_pred = arima_pred_raw.flatten()
                    else:
                        arima_pred = np.array(arima_pred_raw).flatten()
                    
                    # å¦‚æœè¿˜æ²¡æœ‰base_actual_valuesï¼Œä»ARIMAç»“æœè·å–
                    if len(base_actual_values) == 0 and 'test_data' in arima_result:
                        test_data_raw = arima_result['test_data']
                        if hasattr(test_data_raw, 'values'):
                            base_actual_values = test_data_raw.values.flatten()
                        elif hasattr(test_data_raw, 'flatten'):
                            base_actual_values = test_data_raw.flatten()
                        else:
                            base_actual_values = np.array(test_data_raw).flatten()
                    
                    has_real_data = True
            except Exception as e:
                st.warning(f"è·å–ARIMAé¢„æµ‹æ•°æ®å¤±è´¥: {e}")
        
        # è®¾ç½®æœ€ç»ˆçš„actual_values
        actual_values = base_actual_values
        
        # ç”Ÿæˆæ—¥æœŸåºåˆ—
        if len(actual_values) > 0:
            if 'Date' in df.columns and len(df) > 0:
                try:
                    # ä½¿ç”¨æµ‹è¯•é›†å¯¹åº”çš„æ—¥æœŸ
                    train_test_ratio = st.session_state.get('train_test_ratio', 0.8)
                    train_size = int(len(df) * train_test_ratio)
                    test_end_idx = train_size + len(actual_values)
                    
                    # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
                    if test_end_idx <= len(df):
                        test_dates_raw = df['Date'].iloc[train_size:test_end_idx]
                        # å®‰å…¨åœ°è½¬æ¢æ—¥æœŸä¸ºå­—ç¬¦ä¸²
                        dates = []
                        for date in test_dates_raw:
                            try:
                                if pd.isna(date):
                                    dates.append(f"Day {len(dates)+1}")
                                elif hasattr(date, 'strftime'):
                                    dates.append(date.strftime('%Y-%m-%d'))
                                else:
                                    dates.append(str(date))
                            except Exception:
                                dates.append(f"Day {len(dates)+1}")
                    else:
                        # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œç”Ÿæˆé»˜è®¤æ—¥æœŸ
                        dates = [f"Day {i+1}" for i in range(len(actual_values))]
                except Exception as e:
                    st.warning(f"æ—¥æœŸç”Ÿæˆå¤±è´¥: {e}")
                    dates = [f"Day {i+1}" for i in range(len(actual_values))]
            else:
                dates = [f"Day {i+1}" for i in range(len(actual_values))]
    
    # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤º
    if not has_real_data:
        # ç”Ÿæˆç¤ºä¾‹æ•°æ®
        np.random.seed(42)
        actual_values = np.random.randn(50).cumsum() + 100
        dates = [f"Day {i}" for i in range(50)]
        
        if st.session_state.get('lstm_training_complete', False):
            lstm_pred = actual_values + np.random.randn(50) * 0.5
        
        if st.session_state.get('arima_training_complete', False):
            arima_pred = actual_values + np.random.randn(50) * 0.3
    
    return actual_values, lstm_pred, arima_pred, dates, has_real_data

# æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
available_models, model_info = check_model_availability()

# æ·»åŠ è°ƒè¯•ä¿¡æ¯å±•å¼€æ¡†
with st.expander("ğŸ”§ è°ƒè¯•ä¿¡æ¯", expanded=False):
    st.markdown("**Session State å…³é”®ä¿¡æ¯:**")
    debug_info = {
        "LSTMè®­ç»ƒå®Œæˆ": st.session_state.get('lstm_training_complete', False),
        "é€šç”¨è®­ç»ƒå®Œæˆ": st.session_state.get('training_complete', False),
        "ARIMAè®­ç»ƒå®Œæˆ": st.session_state.get('arima_training_complete', False),
        "å·²è®­ç»ƒæ¨¡å‹": st.session_state.get('trained_model') is not None,
        "ARIMAæ¨¡å‹": st.session_state.get('arima_model') is not None,
        "æ¨¡å‹æŒ‡æ ‡": 'model_metrics' in st.session_state,
        "ARIMAæŒ‡æ ‡": 'arima_model_metrics' in st.session_state,
        "æµ‹è¯•æ•°æ®": 'y_test' in st.session_state,
        "Xæµ‹è¯•æ•°æ®": 'X_test' in st.session_state,
        "LSTMé¢„æµ‹ç»“æœ": 'lstm_test_predictions' in st.session_state,
        "ARIMAç»“æœ": 'arima_training_result' in st.session_state,
        "åŸå§‹æ•°æ®": 'raw_data' in st.session_state
    }
    
    # æ·»åŠ æ•°æ®ç±»å‹å’Œå½¢çŠ¶ä¿¡æ¯
    if 'y_test' in st.session_state:
        y_test = st.session_state['y_test']
        debug_info[f"y_testç±»å‹"] = f"{type(y_test)} - å½¢çŠ¶: {getattr(y_test, 'shape', 'N/A')}"
    
    if 'X_test' in st.session_state:
        X_test = st.session_state['X_test']
        debug_info[f"X_testç±»å‹"] = f"{type(X_test)} - å½¢çŠ¶: {getattr(X_test, 'shape', 'N/A')}"
    
    for key, value in debug_info.items():
        if value:
            st.success(f"âœ… {key}: {value}")
        else:
            st.error(f"âŒ {key}: {value}")
    
    st.markdown("**å¯ç”¨æ¨¡å‹:**")
    if available_models:
        for model in available_models:
            st.success(f"âœ… {model}")
            info = model_info[model]
            st.json(info)
    else:
        st.warning("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")

if not available_models:
    st.warning("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°å·²è®­ç»ƒçš„æ¨¡å‹ã€‚è¯·å…ˆåœ¨æ¨¡å‹è®­ç»ƒé¡µé¢è®­ç»ƒæ¨¡å‹ã€‚")
    st.info("ğŸ’¡ æç¤ºï¼šæ‚¨éœ€è¦å…ˆå®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š")
    st.markdown("""
    1. åœ¨**æ•°æ®æŸ¥çœ‹**é¡µé¢åŠ è½½æ•°æ®
    2. åœ¨**æ¨¡å‹è®­ç»ƒ**é¡µé¢è®­ç»ƒLSTMæˆ–ARIMAæ¨¡å‹
    3. è®­ç»ƒå®Œæˆåè¿”å›æ­¤é¡µé¢è¿›è¡Œè¯„ä¼°
    """)
    st.stop()

# å¿«é€ŸçŠ¶æ€æ¦‚è§ˆ
st.subheader("ğŸ“Š æ¨¡å‹çŠ¶æ€æ¦‚è§ˆ")
status_cols = st.columns(len(available_models) + 2)

with status_cols[0]:
    st.metric("å·²è®­ç»ƒæ¨¡å‹", f"{len(available_models)}ä¸ª", 
              " + ".join(available_models))

with status_cols[1]:
    # ç¡®å®šæœ€ä½³æ¨¡å‹
    best_model = "æœªçŸ¥"
    best_metric = "N/A"
    if available_models:
        # ç®€å•æ¯”è¾ƒMSEæ¥ç¡®å®šæœ€ä½³æ¨¡å‹
        best_mse = float('inf')
        for model in available_models:
            metrics = model_info[model]['metrics']
            if 'MSE' in metrics and metrics['MSE'] < best_mse:
                best_mse = metrics['MSE']
                best_model = model
                best_metric = f"MSE: {best_mse:.4f}"
    
    st.metric("æœ€ä½³æ¨¡å‹", best_model, best_metric)

# ä¸ºæ¯ä¸ªå¯ç”¨æ¨¡å‹æ˜¾ç¤ºçŠ¶æ€
for i, model in enumerate(available_models):
    with status_cols[i + 2]:
        metrics = model_info[model]['metrics']
        rmse_value = metrics.get('RMSE', 0)
        st.metric(f"{model} RMSE", f"{rmse_value:.4f}", 
                  model_info[model]['status'])

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.subheader("ğŸ“‹ è¯„ä¼°é…ç½®")
    
    # æ¨¡å‹é€‰æ‹©
    with st.expander("æ¨¡å‹é€‰æ‹©", expanded=True):
        selected_models = st.multiselect(
            "é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹",
            options=available_models,
            default=available_models,
            help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”åˆ†æ"
        )
    
    # è¯„ä¼°æŒ‡æ ‡é€‰æ‹©
    with st.expander("è¯„ä¼°æŒ‡æ ‡", expanded=True):
        metrics_options = ["MSE", "RMSE", "MAE", "MAPE", "æ–¹å‘å‡†ç¡®ç‡", "RÂ²"]
        selected_metrics = st.multiselect(
            "é€‰æ‹©è¯„ä¼°æŒ‡æ ‡",
            options=metrics_options,
            default=["MSE", "RMSE", "MAE", "æ–¹å‘å‡†ç¡®ç‡"],
            help="é€‰æ‹©ç”¨äºæ¨¡å‹è¯„ä¼°çš„æŒ‡æ ‡"
        )
    
    # æ—¶é—´èŒƒå›´é€‰æ‹©
    with st.expander("æ—¶é—´èŒƒå›´", expanded=True):
        evaluation_period = st.selectbox(
            "è¯„ä¼°æ—¶é—´æ®µ",
            options=["æµ‹è¯•é›†", "è®­ç»ƒé›†", "å…¨éƒ¨æ•°æ®"],
            index=0,
            help="é€‰æ‹©ç”¨äºè¯„ä¼°çš„æ•°æ®èŒƒå›´"
        )
    
    # å›¾è¡¨é…ç½®
    with st.expander("å›¾è¡¨è®¾ç½®", expanded=True):
        chart_height = st.slider(
            "å›¾è¡¨é«˜åº¦",
            min_value=300,
            max_value=800,
            value=400,
            step=50,
            help="è°ƒæ•´å›¾è¡¨æ˜¾ç¤ºé«˜åº¦"
        )
        
        show_confidence_interval = st.checkbox(
            "æ˜¾ç¤ºç½®ä¿¡åŒºé—´", 
            value=False,
            help="åœ¨é¢„æµ‹å›¾è¡¨ä¸­æ˜¾ç¤ºç½®ä¿¡åŒºé—´"
        )
        
        show_residuals = st.checkbox(
            "æ˜¾ç¤ºæ®‹å·®åˆ†æ", 
            value=True,
            help="æ˜¾ç¤ºæ¨¡å‹æ®‹å·®åˆ†æå›¾è¡¨"
        )

# ä¸»è¦è¯„ä¼°æ ‡ç­¾é¡µ
eval_tabs = st.tabs([
    "ğŸ“Š æ¨¡å‹å¯¹æ¯”", 
    "ğŸ“ˆ é¢„æµ‹åˆ†æ", 
    # "ğŸ” è¯¯å·®åˆ†æ",  # æš‚æ—¶éšè—
    # "ğŸ§ª æ¨¡å‹è¯Šæ–­",  # æš‚æ—¶éšè—
    "ğŸ“‹ è¯¦ç»†æŠ¥å‘Š"
])

# æ ‡ç­¾é¡µ1: æ¨¡å‹å¯¹æ¯”
with eval_tabs[0]:
    st.header("ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    
    if len(selected_models) == 0:
        st.warning("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
    else:
        # æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
        st.subheader("æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
        comparison_col1, comparison_col2 = st.columns([2, 1])
        
        with comparison_col1:
            # é›·è¾¾å›¾æ˜¾ç¤ºå¤šç»´åº¦å¯¹æ¯”
            if len(selected_models) >= 2:
                radar_option = create_model_comparison_radar()
                st_echarts(options=radar_option, height=f"{chart_height}px")
            else:
                st.info("éœ€è¦è‡³å°‘2ä¸ªæ¨¡å‹æ‰èƒ½æ˜¾ç¤ºé›·è¾¾å›¾å¯¹æ¯”")
        
        with comparison_col2:
            # æ€§èƒ½æŒ‡æ ‡è¡¨æ ¼
            comparison_data = []
            for model in selected_models:
                metrics = model_info[model]['metrics']
                row = {"æ¨¡å‹": model}
                for metric in selected_metrics:
                    if metric in metrics:
                        row[metric] = f"{metrics[metric]:.4f}"
                    else:
                        row[metric] = "N/A"
                comparison_data.append(row)
            
            if comparison_data:
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                
                # æœ€ä½³æ¨¡å‹æ¨è
                if len(selected_models) > 1:
                    st.success(f"ğŸ† æ¨èæ¨¡å‹: {best_model}")
                    st.info("åŸºäºMSEæŒ‡æ ‡è¯„é€‰")
        
        # æŒ‡æ ‡å¯¹æ¯”æŸ±çŠ¶å›¾
        if len(selected_models) > 1 and comparison_data:
            st.subheader("æŒ‡æ ‡å¯¹æ¯”å›¾")
            
            # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºå¯¹æ¯”å›¾
            for metric in selected_metrics:
                if metric in comparison_df.columns:
                    metric_col1, metric_col2 = st.columns([3, 1])
                    
                    with metric_col1:
                        # åˆ›å»ºæŸ±çŠ¶å›¾
                        metric_values = []
                        model_names = []
                        
                        for _, row in comparison_df.iterrows():
                            if row[metric] != "N/A":
                                try:
                                    metric_values.append(float(row[metric]))
                                    model_names.append(row["æ¨¡å‹"])
                                except ValueError:
                                    continue
                        
                        if metric_values:
                            bar_option = {
                                "title": {
                                    "text": f"{metric}å¯¹æ¯”",
                                    "left": "center",
                                    "textStyle": {"fontSize": 14}
                                },
                                "tooltip": {"trigger": "axis"},
                                "xAxis": {
                                    "type": "category",
                                    "data": model_names
                                },
                                "yAxis": {"type": "value"},
                                "series": [{
                                    "type": "bar",
                                    "data": metric_values,
                                    "itemStyle": {
                                        "color": "#5470c6"
                                    }
                                }]
                            }
                            st_echarts(options=bar_option, height="250px")
                    
                    with metric_col2:
                        # æ˜¾ç¤ºæœ€ä½³å€¼
                        if metric_values:
                            if metric in ["MSE", "RMSE", "MAE", "MAPE"]:
                                best_idx = np.argmin(metric_values)
                                st.success(f"æœ€ä½³: {model_names[best_idx]}")
                                st.metric("æœ€ä½³å€¼", f"{metric_values[best_idx]:.4f}")
                            else:
                                best_idx = np.argmax(metric_values)
                                st.success(f"æœ€ä½³: {model_names[best_idx]}")
                                st.metric("æœ€ä½³å€¼", f"{metric_values[best_idx]:.4f}")

# æ ‡ç­¾é¡µ2: é¢„æµ‹åˆ†æ
with eval_tabs[1]:
    st.header("ğŸ“ˆ é¢„æµ‹ç»“æœåˆ†æ")
    
    if len(selected_models) == 0:
        st.warning("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹è¿›è¡Œåˆ†æ")
    else:
        # è·å–é¢„æµ‹æ•°æ®
        st.subheader("é¢„æµ‹ç»“æœå¯¹æ¯”")
        
        # ä»session stateè·å–å®é™…çš„é¢„æµ‹æ•°æ®
        actual_values, lstm_pred, arima_pred, dates, has_real_data = get_prediction_data()
        
        # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
        if not has_real_data:
            st.info("ğŸ“Š å½“å‰æ˜¾ç¤ºç¤ºä¾‹æ•°æ®ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ä»¥æŸ¥çœ‹çœŸå®é¢„æµ‹ç»“æœ")
        
        # æ•°æ®é•¿åº¦ä¿¡æ¯å’Œå¯¹é½å¤„ç†
        available_lengths = []
        length_info = {}
        
        if len(actual_values) > 0:
            available_lengths.append(len(actual_values))
            length_info["å®é™…å€¼"] = len(actual_values)
        
        if lstm_pred is not None and len(lstm_pred) > 0:
            available_lengths.append(len(lstm_pred))
            length_info["LSTMé¢„æµ‹"] = len(lstm_pred)
        
        if arima_pred is not None and len(arima_pred) > 0:
            available_lengths.append(len(arima_pred))
            length_info["ARIMAé¢„æµ‹"] = len(arima_pred)
        
        # æ£€æŸ¥é•¿åº¦ä¸ä¸€è‡´çš„é—®é¢˜å¹¶æä¾›å¯¹é½ç­–ç•¥é€‰æ‹©
        if len(set(available_lengths)) > 1:
            st.warning("âš ï¸ æ£€æµ‹åˆ°æ•°æ®é•¿åº¦ä¸ä¸€è‡´ï¼Œå¯èƒ½çš„åŸå› ï¼š")
            st.write("- LSTMå’ŒARIMAä½¿ç”¨äº†ä¸åŒçš„åºåˆ—é•¿åº¦è®¾ç½®")
            st.write("- æ•°æ®é¢„å¤„ç†æ–¹å¼ä¸åŒ")
            st.write("- æ¨¡å‹è®­ç»ƒæ—¶çš„å‚æ•°è®¾ç½®ä¸åŒ")
            
            # æä¾›è§£å†³å»ºè®®
            max_length = max(available_lengths)
            min_length = min(available_lengths)
            st.info(f"ğŸ’¡ å»ºè®®ï¼šä½¿ç”¨è¾ƒé•¿çš„æ•°æ®é•¿åº¦({max_length}ä¸ªç‚¹)ä»¥è·å¾—æ›´å¥½çš„æ¯”è¾ƒæ•ˆæœ")
            
            # è®©ç”¨æˆ·é€‰æ‹©å¯¹é½ç­–ç•¥
            alignment_strategy = st.radio(
                "é€‰æ‹©æ•°æ®å¯¹é½ç­–ç•¥:",
                options=["ä½¿ç”¨æœ€å°é•¿åº¦", "ä½¿ç”¨æœ€å¤§é•¿åº¦(å¯èƒ½æœ‰ç¼ºå¤±å€¼)", "ä»…æ˜¾ç¤ºå®Œæ•´æ•°æ®çš„æ¨¡å‹"],
                index=0,
                help="é€‰æ‹©å¦‚ä½•å¤„ç†é•¿åº¦ä¸ä¸€è‡´çš„æ•°æ®"
            )
        else:
            alignment_strategy = "ä½¿ç”¨æœ€å°é•¿åº¦"  # é»˜è®¤ç­–ç•¥
            st.success("âœ… æ‰€æœ‰æ•°æ®é•¿åº¦ä¸€è‡´")
        
        # ç»Ÿä¸€è°ƒè¯•ä¿¡æ¯å±•å¼€æ¡†
        with st.expander("ğŸ”§ æ•°æ®å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯", expanded=False):
            st.markdown("**æ•°æ®æ¥æºä¿¡æ¯:**")
            if "LSTM" in selected_models:
                if 'lstm_test_predictions' in st.session_state:
                    st.success("âœ… LSTM: ä½¿ç”¨ä¿å­˜çš„é¢„æµ‹ç»“æœ")
                else:
                    st.info("â„¹ï¸ LSTM: é‡æ–°ç”Ÿæˆé¢„æµ‹ç»“æœ")
                
                # æ˜¾ç¤ºå®é™…å€¼æ¥æº
                target_column = 'Close'
                if 'selected_features' in st.session_state:
                    selected_features = st.session_state['selected_features']
                    if 'Close' in selected_features:
                        target_column = 'Close'
                    elif selected_features:
                        target_column = selected_features[0]
                st.info(f"âœ… LSTMå®é™…å€¼: ä½¿ç”¨åŸå§‹æ•°æ®ä¸­çš„{target_column}åˆ—")
            
            if "ARIMA" in selected_models:
                st.success("âœ… ARIMA: ä½¿ç”¨è®­ç»ƒç»“æœä¸­çš„é¢„æµ‹æ•°æ®")
                st.info("âœ… ARIMAå®é™…å€¼: ä½¿ç”¨è®­ç»ƒæ—¶çš„æµ‹è¯•é›†æ•°æ®")
            
            st.markdown("**åŸå§‹æ•°æ®é•¿åº¦:**")
            for name, length in length_info.items():
                st.write(f"- {name}: {length} ä¸ªæ•°æ®ç‚¹")
        
        # æ ¹æ®é€‰æ‹©çš„ç­–ç•¥è¿›è¡Œæ•°æ®å¯¹é½
        if available_lengths:
            if alignment_strategy == "ä½¿ç”¨æœ€å°é•¿åº¦":
                final_length = min(available_lengths)
            elif alignment_strategy == "ä½¿ç”¨æœ€å¤§é•¿åº¦(å¯èƒ½æœ‰ç¼ºå¤±å€¼)":
                final_length = max(available_lengths)
                # å¯¹äºè¾ƒçŸ­çš„æ•°æ®ï¼Œç”¨NaNå¡«å……
                if len(actual_values) < final_length:
                    actual_values = np.pad(actual_values, (0, final_length - len(actual_values)), constant_values=np.nan)
                if lstm_pred is not None and len(lstm_pred) < final_length:
                    lstm_pred = np.pad(lstm_pred, (0, final_length - len(lstm_pred)), constant_values=np.nan)
                if arima_pred is not None and len(arima_pred) < final_length:
                    arima_pred = np.pad(arima_pred, (0, final_length - len(arima_pred)), constant_values=np.nan)
            else:  # ä»…æ˜¾ç¤ºå®Œæ•´æ•°æ®çš„æ¨¡å‹
                final_length = min(available_lengths)
                # ç§»é™¤é•¿åº¦ä¸åŒ¹é…çš„æ¨¡å‹æ•°æ®
                if lstm_pred is not None and len(lstm_pred) != max(available_lengths):
                    lstm_pred = None
                if arima_pred is not None and len(arima_pred) != max(available_lengths):
                    arima_pred = None
            
            # è°ƒæ•´æ•°æ®é•¿åº¦
            actual_values = actual_values[:final_length]
            dates = dates[:final_length] if len(dates) > final_length else dates
            if lstm_pred is not None:
                lstm_pred = lstm_pred[:final_length]
            if arima_pred is not None:
                arima_pred = arima_pred[:final_length]
        else:
            final_length = 0
        
        # æ˜¾ç¤ºæœ€ç»ˆæ•°æ®ä¿¡æ¯
        if len(actual_values) > 0:
            st.success(f"ğŸ“ˆ æœ€ç»ˆæ˜¾ç¤ºæ•°æ®ç‚¹æ•°: {len(actual_values)}")
            
            # åœ¨è°ƒè¯•æ¡†ä¸­æ˜¾ç¤ºæœ€ç»ˆæ•°æ®èŒƒå›´
            with st.expander("ğŸ“Š æœ€ç»ˆæ•°æ®èŒƒå›´", expanded=False):
                if len(actual_values) > 0:
                    st.write(f"å®é™…å€¼èŒƒå›´: {np.nanmin(actual_values):.2f} - {np.nanmax(actual_values):.2f}")
                if lstm_pred is not None and len(lstm_pred) > 0:
                    st.write(f"LSTMé¢„æµ‹èŒƒå›´: {np.nanmin(lstm_pred):.2f} - {np.nanmax(lstm_pred):.2f}")
                if arima_pred is not None and len(arima_pred) > 0:
                    st.write(f"ARIMAé¢„æµ‹èŒƒå›´: {np.nanmin(arima_pred):.2f} - {np.nanmax(arima_pred):.2f}")
                st.write(f"æ—¥æœŸèŒƒå›´: {dates[0]} åˆ° {dates[-1]}" if dates else "æ— æ—¥æœŸä¿¡æ¯")
                st.write(f"æ•°æ®ç±»å‹: {'çœŸå®æ•°æ®' if has_real_data else 'ç¤ºä¾‹æ•°æ®'}")
            
            # ä¸»é¢„æµ‹å›¾è¡¨
            try:
                # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
                if len(actual_values) == 0:
                    st.warning("å®é™…å€¼æ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºå›¾è¡¨")
                elif any(not np.isfinite(x) for x in actual_values):
                    st.warning("å®é™…å€¼åŒ…å«æ— æ•ˆæ•°æ®ï¼ˆNaNæˆ–Infï¼‰ï¼Œæ­£åœ¨æ¸…ç†...")
                    # æ¸…ç†æ— æ•ˆæ•°æ®
                    valid_indices = np.isfinite(actual_values)
                    actual_values = actual_values[valid_indices]
                    dates = [dates[i] for i in range(len(dates)) if valid_indices[i]]
                    if lstm_pred is not None:
                        lstm_pred = lstm_pred[valid_indices]
                    if arima_pred is not None:
                        arima_pred = arima_pred[valid_indices]
                
                if len(actual_values) > 0:
                    prediction_option = create_prediction_comparison_chart(
                        dates, actual_values, lstm_pred, arima_pred
                    )
                    st_echarts(options=prediction_option, height=f"{chart_height + 100}px")
                else:
                    st.error("æ¸…ç†åæ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯æ˜¾ç¤º")
                    
            except Exception as chart_error:
                st.error(f"å›¾è¡¨åˆ›å»ºå¤±è´¥: {chart_error}")
                import traceback
                st.code(traceback.format_exc())
            
            # é¢„æµ‹å‡†ç¡®æ€§åˆ†æ
            st.subheader("é¢„æµ‹å‡†ç¡®æ€§åˆ†æ")
            accuracy_cols = st.columns(len(selected_models))
            
            for i, model in enumerate(selected_models):
                with accuracy_cols[i]:
                    try:
                        if model == "LSTM" and lstm_pred is not None and len(lstm_pred) > 0:
                            scatter_option = create_scatter_plot(actual_values, lstm_pred, "LSTM")
                            st_echarts(options=scatter_option, height="300px")
                            
                            # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
                            metrics = calculate_model_metrics(actual_values, lstm_pred)
                            st.markdown(f"**LSTMæ€§èƒ½æŒ‡æ ‡:**")
                            st.markdown(f"- MSE: {metrics['MSE']:.4f}")
                            st.markdown(f"- RMSE: {metrics['RMSE']:.4f}")
                            st.markdown(f"- MAE: {metrics['MAE']:.4f}")
                            st.markdown(f"- RÂ²: {metrics['RÂ²']:.4f}")
                            
                        elif model == "ARIMA" and arima_pred is not None and len(arima_pred) > 0:
                            scatter_option = create_scatter_plot(actual_values, arima_pred, "ARIMA")
                            st_echarts(options=scatter_option, height="300px")
                            
                            # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
                            metrics = calculate_model_metrics(actual_values, arima_pred)
                            st.markdown(f"**ARIMAæ€§èƒ½æŒ‡æ ‡:**")
                            st.markdown(f"- MSE: {metrics['MSE']:.4f}")
                            st.markdown(f"- RMSE: {metrics['RMSE']:.4f}")
                            st.markdown(f"- MAE: {metrics['MAE']:.4f}")
                            st.markdown(f"- RÂ²: {metrics['RÂ²']:.4f}")
                        else:
                            st.warning(f"{model}æ¨¡å‹æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®")
                    except Exception as scatter_error:
                        st.error(f"{model}æ•£ç‚¹å›¾åˆ›å»ºå¤±è´¥: {scatter_error}")
                        import traceback
                        st.code(traceback.format_exc())
        else:
            st.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œé¢„æµ‹åˆ†æ")

# æ·»åŠ JSONåºåˆ—åŒ–è¾…åŠ©å‡½æ•°
def make_json_serializable(obj):
    """
    å°†åŒ…å«numpyæ•°ç»„çš„å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼
    
    å‚æ•°:
        obj: éœ€è¦è½¬æ¢çš„å¯¹è±¡
        
    è¿”å›:
        JSONå¯åºåˆ—åŒ–çš„å¯¹è±¡
    """
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, dict):
        return {key: make_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [make_json_serializable(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(make_json_serializable(item) for item in obj)
    elif pd.isna(obj):
        return None
    else:
        return obj

def generate_evaluation_report(report_sections, report_format, selected_models, selected_metrics, model_info, best_model, evaluation_period, include_charts=True):
    """
    ç”Ÿæˆæ¨¡å‹è¯„ä¼°æŠ¥å‘Š
    
    å‚æ•°:
        report_sections: é€‰æ‹©çš„æŠ¥å‘Šç« èŠ‚
        report_format: æŠ¥å‘Šæ ¼å¼ (HTML, Markdown, JSON)
        selected_models: é€‰æ‹©çš„æ¨¡å‹åˆ—è¡¨
        selected_metrics: é€‰æ‹©çš„æŒ‡æ ‡åˆ—è¡¨
        model_info: æ¨¡å‹ä¿¡æ¯å­—å…¸
        best_model: æœ€ä½³æ¨¡å‹åç§°
        evaluation_period: è¯„ä¼°æœŸé—´
        include_charts: æ˜¯å¦åŒ…å«å›¾è¡¨
        
    è¿”å›:
        tuple: (æŠ¥å‘Šå†…å®¹, æ–‡ä»¶æ‰©å±•å, MIMEç±»å‹)
    """
    current_time = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
    
    if report_format == "HTMLé¢„è§ˆ":
        # ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¨¡å‹è¯„ä¼°æŠ¥å‘Š</title>
    <style>
        body {{ font-family: 'Microsoft YaHei', Arial, sans-serif; margin: 40px; line-height: 1.6; }}
        .header {{ text-align: center; border-bottom: 2px solid #333; padding-bottom: 20px; margin-bottom: 30px; }}
        .section {{ margin-bottom: 30px; }}
        .metrics-table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        .metrics-table th, .metrics-table td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        .metrics-table th {{ background-color: #f2f2f2; font-weight: bold; }}
        .highlight {{ background-color: #e8f4fd; padding: 15px; border-left: 4px solid #2196F3; margin: 15px 0; }}
        .warning {{ background-color: #fff3cd; padding: 15px; border-left: 4px solid #ffc107; margin: 15px 0; }}
        .success {{ background-color: #d4edda; padding: 15px; border-left: 4px solid #28a745; margin: 15px 0; }}
        h1 {{ color: #333; }}
        h2 {{ color: #555; border-bottom: 1px solid #eee; padding-bottom: 10px; }}
        h3 {{ color: #666; }}
        .footer {{ text-align: center; margin-top: 50px; padding-top: 20px; border-top: 1px solid #eee; color: #666; font-size: 0.9em; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“Š æ¨¡å‹è¯„ä¼°æŠ¥å‘Š</h1>
        <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {current_time}</p>
        <p><strong>è¯„ä¼°æ¨¡å‹:</strong> {', '.join(selected_models)}</p>
        <p><strong>è¯„ä¼°æœŸé—´:</strong> {evaluation_period}</p>
    </div>
"""
        
        # æ‰§è¡Œæ‘˜è¦
        if "æ‰§è¡Œæ‘˜è¦" in report_sections:
            html_content += f"""
    <div class="section">
        <h2>ğŸ“‹ æ‰§è¡Œæ‘˜è¦</h2>
        <div class="highlight">
            <h3>ğŸ¯ ä¸»è¦å‘ç°</h3>
"""
            for model in selected_models:
                if model in model_info:
                    metrics = model_info[model]['metrics']
                    html_content += f"""
            <p><strong>{model}æ¨¡å‹:</strong></p>
            <ul>
                <li>RMSE: {metrics.get('RMSE', 'N/A')}</li>
                <li>MAE: {metrics.get('MAE', 'N/A')}</li>
                <li>æ–¹å‘å‡†ç¡®ç‡: {metrics.get('Direction_Accuracy', 'N/A')}</li>
            </ul>
"""
            
            html_content += f"""
        </div>
        <div class="success">
            <h3>ğŸ’¡ å»ºè®®</h3>
            <ul>
                <li><strong>æ¨èæ¨¡å‹:</strong> {best_model}</li>
                <li><strong>åº”ç”¨åœºæ™¯:</strong> é€‚ç”¨äºçŸ­æœŸä»·æ ¼é¢„æµ‹</li>
                <li><strong>æ³¨æ„äº‹é¡¹:</strong> å»ºè®®å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹ä»¥ä¿æŒé¢„æµ‹å‡†ç¡®æ€§</li>
            </ul>
        </div>
    </div>
"""
        
        # æ€§èƒ½æŒ‡æ ‡
        if "æ€§èƒ½æŒ‡æ ‡" in report_sections:
            html_content += """
    <div class="section">
        <h2>ğŸ“ˆ è¯¦ç»†æ€§èƒ½æŒ‡æ ‡</h2>
        <table class="metrics-table">
            <thead>
                <tr>
                    <th>æ¨¡å‹</th>
                    <th>çŠ¶æ€</th>
                    <th>MSE</th>
                    <th>RMSE</th>
                    <th>MAE</th>
                    <th>RÂ²</th>
                    <th>æ–¹å‘å‡†ç¡®ç‡</th>
                </tr>
            </thead>
            <tbody>
"""
            for model in selected_models:
                if model in model_info:
                    metrics = model_info[model]['metrics']
                    status = model_info[model]['status']
                    html_content += f"""
                <tr>
                    <td><strong>{model}</strong></td>
                    <td>{status}</td>
                    <td>{metrics.get('MSE', 'N/A')}</td>
                    <td>{metrics.get('RMSE', 'N/A')}</td>
                    <td>{metrics.get('MAE', 'N/A')}</td>
                    <td>{metrics.get('RÂ²', 'N/A')}</td>
                    <td>{metrics.get('Direction_Accuracy', 'N/A')}</td>
                </tr>
"""
            html_content += """
            </tbody>
        </table>
    </div>
"""
        
        # å»ºè®®å’Œç»“è®º
        if "å»ºè®®å’Œç»“è®º" in report_sections:
            html_content += """
    <div class="section">
        <h2>ğŸ¯ å»ºè®®å’Œç»“è®º</h2>
        
        <h3>ğŸ“ˆ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²</h3>
        <ul>
            <li><strong>é¦–é€‰æ¨¡å‹:</strong> æ ¹æ®ç»¼åˆæ€§èƒ½è¯„ä¼°é€‰æ‹©æœ€ä½³æ¨¡å‹</li>
            <li><strong>å¤‡é€‰æ–¹æ¡ˆ:</strong> ä¿ç•™æ¬¡ä¼˜æ¨¡å‹ä½œä¸ºå¤‡é€‰</li>
            <li><strong>ç›‘æ§ç­–ç•¥:</strong> å»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§æœºåˆ¶</li>
        </ul>
        
        <h3>ğŸ”„ æ¨¡å‹ç»´æŠ¤</h3>
        <ul>
            <li><strong>é‡è®­ç»ƒé¢‘ç‡:</strong> å»ºè®®æ¯æœˆé‡æ–°è¯„ä¼°æ¨¡å‹æ€§èƒ½</li>
            <li><strong>æ•°æ®æ›´æ–°:</strong> åŠæ—¶æ›´æ–°è®­ç»ƒæ•°æ®é›†</li>
            <li><strong>å‚æ•°è°ƒä¼˜:</strong> æ ¹æ®æ–°æ•°æ®è°ƒæ•´æ¨¡å‹å‚æ•°</li>
        </ul>
        
        <div class="warning">
            <h3>âš ï¸ é£é™©æç¤º</h3>
            <ul>
                <li>æ¨¡å‹é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·ç»“åˆä¸šåŠ¡åˆ¤æ–­ä½¿ç”¨</li>
                <li>å¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½</li>
                <li>å»ºè®®å»ºç«‹å¤šæ¨¡å‹é›†æˆç­–ç•¥é™ä½é£é™©</li>
            </ul>
        </div>
    </div>
"""
        
        html_content += """
    <div class="footer">
        <p>ğŸ’¡ æç¤ºï¼šæ¨¡å‹è¯„ä¼°ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åº”ç”¨æ—¶è¯·ç»“åˆä¸šåŠ¡åœºæ™¯å’Œä¸“ä¸šåˆ¤æ–­</p>
        <p>æŠ¥å‘Šç”±Streamlitå€ºåˆ¸é¢„æµ‹ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ</p>
    </div>
</body>
</html>
"""
        return html_content, "html", "text/html"
    
    elif report_format == "Markdown":
        # ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š
        md_content = f"""# ğŸ“Š æ¨¡å‹è¯„ä¼°æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´:** {current_time}  
**è¯„ä¼°æ¨¡å‹:** {', '.join(selected_models)}  
**è¯„ä¼°æœŸé—´:** {evaluation_period}  
**è¯„ä¼°æŒ‡æ ‡:** {', '.join(selected_metrics)}

---

"""
        
        # æ‰§è¡Œæ‘˜è¦
        if "æ‰§è¡Œæ‘˜è¦" in report_sections:
            md_content += """## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

### ğŸ¯ ä¸»è¦å‘ç°

"""
            for model in selected_models:
                if model in model_info:
                    metrics = model_info[model]['metrics']
                    md_content += f"""**{model}æ¨¡å‹:**
- RMSE: {metrics.get('RMSE', 'N/A')}
- MAE: {metrics.get('MAE', 'N/A')}
- æ–¹å‘å‡†ç¡®ç‡: {metrics.get('Direction_Accuracy', 'N/A')}

"""
            
            md_content += f"""### ğŸ’¡ å»ºè®®

- **æ¨èæ¨¡å‹:** {best_model}
- **åº”ç”¨åœºæ™¯:** é€‚ç”¨äºçŸ­æœŸä»·æ ¼é¢„æµ‹
- **æ³¨æ„äº‹é¡¹:** å»ºè®®å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹ä»¥ä¿æŒé¢„æµ‹å‡†ç¡®æ€§

---

"""
        
        # æ€§èƒ½æŒ‡æ ‡
        if "æ€§èƒ½æŒ‡æ ‡" in report_sections:
            md_content += """## ğŸ“ˆ è¯¦ç»†æ€§èƒ½æŒ‡æ ‡

| æ¨¡å‹ | çŠ¶æ€ | MSE | RMSE | MAE | RÂ² | æ–¹å‘å‡†ç¡®ç‡ |
|------|------|-----|------|-----|----|-----------| 
"""
            for model in selected_models:
                if model in model_info:
                    metrics = model_info[model]['metrics']
                    status = model_info[model]['status']
                    md_content += f"| **{model}** | {status} | {metrics.get('MSE', 'N/A')} | {metrics.get('RMSE', 'N/A')} | {metrics.get('MAE', 'N/A')} | {metrics.get('RÂ²', 'N/A')} | {metrics.get('Direction_Accuracy', 'N/A')} |\n"
            
            md_content += "\n---\n\n"
        
        # å»ºè®®å’Œç»“è®º
        if "å»ºè®®å’Œç»“è®º" in report_sections:
            md_content += """## ğŸ¯ å»ºè®®å’Œç»“è®º

### ğŸ“ˆ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- **é¦–é€‰æ¨¡å‹:** æ ¹æ®ç»¼åˆæ€§èƒ½è¯„ä¼°é€‰æ‹©æœ€ä½³æ¨¡å‹
- **å¤‡é€‰æ–¹æ¡ˆ:** ä¿ç•™æ¬¡ä¼˜æ¨¡å‹ä½œä¸ºå¤‡é€‰
- **ç›‘æ§ç­–ç•¥:** å»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§æœºåˆ¶

### ğŸ”„ æ¨¡å‹ç»´æŠ¤
- **é‡è®­ç»ƒé¢‘ç‡:** å»ºè®®æ¯æœˆé‡æ–°è¯„ä¼°æ¨¡å‹æ€§èƒ½
- **æ•°æ®æ›´æ–°:** åŠæ—¶æ›´æ–°è®­ç»ƒæ•°æ®é›†
- **å‚æ•°è°ƒä¼˜:** æ ¹æ®æ–°æ•°æ®è°ƒæ•´æ¨¡å‹å‚æ•°

### âš ï¸ é£é™©æç¤º
- æ¨¡å‹é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·ç»“åˆä¸šåŠ¡åˆ¤æ–­ä½¿ç”¨
- å¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½
- å»ºè®®å»ºç«‹å¤šæ¨¡å‹é›†æˆç­–ç•¥é™ä½é£é™©

---

ğŸ’¡ **æç¤ºï¼š** æ¨¡å‹è¯„ä¼°ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åº”ç”¨æ—¶è¯·ç»“åˆä¸šåŠ¡åœºæ™¯å’Œä¸“ä¸šåˆ¤æ–­

*æŠ¥å‘Šç”±Streamlitå€ºåˆ¸é¢„æµ‹ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
        
        return md_content, "md", "text/markdown"
    
    elif report_format == "JSONæ•°æ®":
        # ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š
        json_report = {
            "report_metadata": {
                "generation_time": current_time,
                "evaluated_models": selected_models,
                "evaluation_period": evaluation_period,
                "metrics_used": selected_metrics,
                "report_sections": report_sections
            },
            "executive_summary": {
                "best_model": best_model,
                "model_performance": {}
            },
            "detailed_metrics": {},
            "recommendations": {
                "deployment": {
                    "preferred_model": best_model,
                    "backup_strategy": "ä¿ç•™æ¬¡ä¼˜æ¨¡å‹ä½œä¸ºå¤‡é€‰",
                    "monitoring": "å»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§æœºåˆ¶"
                },
                "maintenance": {
                    "retrain_frequency": "æ¯æœˆé‡æ–°è¯„ä¼°æ¨¡å‹æ€§èƒ½",
                    "data_updates": "åŠæ—¶æ›´æ–°è®­ç»ƒæ•°æ®é›†",
                    "parameter_tuning": "æ ¹æ®æ–°æ•°æ®è°ƒæ•´æ¨¡å‹å‚æ•°"
                },
                "risk_warnings": [
                    "æ¨¡å‹é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·ç»“åˆä¸šåŠ¡åˆ¤æ–­ä½¿ç”¨",
                    "å¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½",
                    "å»ºè®®å»ºç«‹å¤šæ¨¡å‹é›†æˆç­–ç•¥é™ä½é£é™©"
                ]
            }
        }
        
        # æ·»åŠ æ¨¡å‹æ€§èƒ½æ•°æ®
        for model in selected_models:
            if model in model_info:
                json_report["executive_summary"]["model_performance"][model] = model_info[model]['metrics']
                json_report["detailed_metrics"][model] = {
                    "status": model_info[model]['status'],
                    "metrics": model_info[model]['metrics']
                }
        
        # ç¡®ä¿JSONå¯åºåˆ—åŒ–
        json_report = make_json_serializable(json_report)
        json_content = json.dumps(json_report, indent=2, ensure_ascii=False)
        
        return json_content, "json", "application/json"
    
    else:
        return "ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼", "txt", "text/plain"

# æ ‡ç­¾é¡µ3: è¯¦ç»†æŠ¥å‘Š (åŸæ¥æ˜¯æ ‡ç­¾é¡µ5)
with eval_tabs[2]:
    st.header("ğŸ“‹ è¯¦ç»†è¯„ä¼°æŠ¥å‘Š")
    
    # æŠ¥å‘Šç”Ÿæˆé€‰é¡¹
    report_col1, report_col2 = st.columns([3, 1])
    
    with report_col1:
        st.subheader("æŠ¥å‘Šé…ç½®")
        
        report_sections = st.multiselect(
            "é€‰æ‹©æŠ¥å‘Šå†…å®¹",
            options=[
                "æ‰§è¡Œæ‘˜è¦", "æ•°æ®æ¦‚è¿°", "æ¨¡å‹é…ç½®", 
                "æ€§èƒ½æŒ‡æ ‡", "é¢„æµ‹åˆ†æ", "é£é™©è¯„ä¼°", 
                "å»ºè®®å’Œç»“è®º"
            ],
            default=["æ‰§è¡Œæ‘˜è¦", "æ€§èƒ½æŒ‡æ ‡", "é¢„æµ‹åˆ†æ", "å»ºè®®å’Œç»“è®º"]
        )
        
        report_format = st.selectbox(
            "æŠ¥å‘Šæ ¼å¼",
            options=["HTMLé¢„è§ˆ", "Markdown", "JSONæ•°æ®"]
        )
        
        include_charts = st.checkbox("åŒ…å«å›¾è¡¨", value=True)
    
    with report_col2:
        st.subheader("æ“ä½œ")
        
        if st.button("ç”ŸæˆæŠ¥å‘Š", use_container_width=True):
            st.success("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
            st.balloons()
        
        # å¯¼å‡ºæŠ¥å‘ŠæŒ‰é’®
        if st.button("å¯¼å‡ºæŠ¥å‘Š", use_container_width=True):
            try:
                # ç”ŸæˆæŠ¥å‘Šå†…å®¹
                report_content, file_ext, mime_type = generate_evaluation_report(
                    report_sections=report_sections,
                    report_format=report_format,
                    selected_models=selected_models,
                    selected_metrics=selected_metrics,
                    model_info=model_info,
                    best_model=best_model,
                    evaluation_period=evaluation_period,
                    include_charts=include_charts
                )
                
                # ç”Ÿæˆæ–‡ä»¶å
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"model_evaluation_report_{timestamp}.{file_ext}"
                
                st.download_button(
                    label=f"ä¸‹è½½{report_format}æŠ¥å‘Š",
                    data=report_content,
                    file_name=filename,
                    mime=mime_type,
                    use_container_width=True
                )
                st.success("âœ… æŠ¥å‘Šå·²å‡†å¤‡å®Œæˆï¼")
                
            except Exception as report_error:
                st.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {report_error}")
                st.code(f"é”™è¯¯è¯¦æƒ…: {str(report_error)}")
                import traceback
                st.code(traceback.format_exc())
        
        # å¯¼å‡ºæ•°æ®æŒ‰é’®
        if st.button("å¯¼å‡ºæ•°æ®", use_container_width=True):
            try:
                # åˆ›å»ºå¯¼å‡ºæ•°æ®ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
                export_data = {
                    "evaluation_date": datetime.now().isoformat(),
                    "models_evaluated": selected_models,
                    "metrics_used": selected_metrics,
                    "model_performance": make_json_serializable(model_info)
                }
                
                # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                json_data = json.dumps(export_data, indent=2, ensure_ascii=False)
                
                st.download_button(
                    label="ä¸‹è½½è¯„ä¼°æ•°æ®",
                    data=json_data,
                    file_name=f"model_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True
                )
                st.success("âœ… å¯¼å‡ºæ•°æ®å·²å‡†å¤‡å®Œæˆï¼")
                
            except Exception as export_error:
                st.error(f"å¯¼å‡ºæ•°æ®æ—¶å‡ºé”™: {export_error}")
                st.code(f"é”™è¯¯è¯¦æƒ…: {str(export_error)}")
                import traceback
                st.code(traceback.format_exc())
    
    # æŠ¥å‘Šé¢„è§ˆ
    st.subheader("ğŸ“„ æŠ¥å‘Šé¢„è§ˆ")
    
    # æ‰§è¡Œæ‘˜è¦
    if "æ‰§è¡Œæ‘˜è¦" in report_sections:
        with st.expander("æ‰§è¡Œæ‘˜è¦", expanded=True):
            st.markdown(f"""
            ### ğŸ“Š æ¨¡å‹è¯„ä¼°æ‰§è¡Œæ‘˜è¦
            
            **è¯„ä¼°æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}  
            **è¯„ä¼°æ¨¡å‹**: {', '.join(selected_models)}  
            **æ•°æ®é›†**: {evaluation_period}  
            **è¯„ä¼°æŒ‡æ ‡**: {', '.join(selected_metrics)}
            
            #### ğŸ¯ ä¸»è¦å‘ç°
            """)
            
            if len(selected_models) > 0:
                for model in selected_models:
                    metrics = model_info[model]['metrics']
                    st.markdown(f"""
                    **{model}æ¨¡å‹**:
                    - RMSE: {metrics.get('RMSE', 'N/A')}
                    - MAE: {metrics.get('MAE', 'N/A')}
                    - æ–¹å‘å‡†ç¡®ç‡: {metrics.get('Direction_Accuracy', 'N/A')}
                    """)
            
            st.markdown(f"""
            #### ğŸ’¡ å»ºè®®
            - **æ¨èæ¨¡å‹**: {best_model}
            - **åº”ç”¨åœºæ™¯**: é€‚ç”¨äºçŸ­æœŸä»·æ ¼é¢„æµ‹
            - **æ³¨æ„äº‹é¡¹**: å»ºè®®å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹ä»¥ä¿æŒé¢„æµ‹å‡†ç¡®æ€§
            """)
    
    # è¯¦ç»†æŒ‡æ ‡è¡¨
    if "æ€§èƒ½æŒ‡æ ‡" in report_sections:
        with st.expander("è¯¦ç»†æ€§èƒ½æŒ‡æ ‡"):
            if len(selected_models) > 0:
                detailed_metrics = []
                for model in selected_models:
                    metrics = model_info[model]['metrics']
                    row = {"æ¨¡å‹": model, "çŠ¶æ€": model_info[model]['status']}
                    row.update(metrics)
                    detailed_metrics.append(row)
                
                detailed_df = pd.DataFrame(detailed_metrics)
                # ä¿®å¤æ—¶é—´æˆ³æ•°æ®ä»¥å…¼å®¹PyArrow
                detailed_df_display = fix_datetime_for_arrow(detailed_df)
                st.dataframe(detailed_df_display, use_container_width=True, hide_index=True)
            else:
                st.info("æ²¡æœ‰é€‰æ‹©æ¨¡å‹è¿›è¡Œè¯„ä¼°")
    
    # æ¨¡å‹æ¯”è¾ƒæ€»ç»“
    if "å»ºè®®å’Œç»“è®º" in report_sections:
        with st.expander("å»ºè®®å’Œç»“è®º"):
            st.markdown("""
            ### ğŸ¯ æ¨¡å‹é€‰æ‹©å»ºè®®
            
            åŸºäºå½“å‰è¯„ä¼°ç»“æœï¼Œæˆ‘ä»¬æä¾›ä»¥ä¸‹å»ºè®®ï¼š
            
            #### ğŸ“ˆ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
            - **é¦–é€‰æ¨¡å‹**: æ ¹æ®ç»¼åˆæ€§èƒ½è¯„ä¼°é€‰æ‹©æœ€ä½³æ¨¡å‹
            - **å¤‡é€‰æ–¹æ¡ˆ**: ä¿ç•™æ¬¡ä¼˜æ¨¡å‹ä½œä¸ºå¤‡é€‰
            - **ç›‘æ§ç­–ç•¥**: å»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§æœºåˆ¶
            
            #### ğŸ”„ æ¨¡å‹ç»´æŠ¤
            - **é‡è®­ç»ƒé¢‘ç‡**: å»ºè®®æ¯æœˆé‡æ–°è¯„ä¼°æ¨¡å‹æ€§èƒ½
            - **æ•°æ®æ›´æ–°**: åŠæ—¶æ›´æ–°è®­ç»ƒæ•°æ®é›†
            - **å‚æ•°è°ƒä¼˜**: æ ¹æ®æ–°æ•°æ®è°ƒæ•´æ¨¡å‹å‚æ•°
            
            #### âš ï¸ é£é™©æç¤º
            - æ¨¡å‹é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·ç»“åˆä¸šåŠ¡åˆ¤æ–­ä½¿ç”¨
            - å¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½
            - å»ºè®®å»ºç«‹å¤šæ¨¡å‹é›†æˆç­–ç•¥é™ä½é£é™©
            """)

# é¡µé¢åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: gray; font-size: 0.8em;">
    ğŸ’¡ æç¤ºï¼šæ¨¡å‹è¯„ä¼°ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åº”ç”¨æ—¶è¯·ç»“åˆä¸šåŠ¡åœºæ™¯å’Œä¸“ä¸šåˆ¤æ–­
</div>
""", unsafe_allow_html=True) 