# -*- coding: utf-8 -*-
"""
æ¨¡å‹è¯„ä¼°é¡µé¢ (Model Evaluation Page)
æ­¤æ¨¡å—æä¾›è®­ç»ƒå®Œæˆæ¨¡å‹çš„è¯¦ç»†æ€§èƒ½åˆ†æå’Œå¯¹æ¯”åŠŸèƒ½

ä¸»è¦åŠŸèƒ½:
1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ
2. é¢„æµ‹ç»“æœå¯è§†åŒ–
3. è¯¯å·®åˆ†æå’Œæ®‹å·®æ£€éªŒ
4. æ¨¡å‹è¯Šæ–­å·¥å…·
5. è¯¦ç»†è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ

æŠ€æœ¯æ ˆ:
- streamlit: Webåº”ç”¨æ¡†æ¶
- pandas: æ•°æ®å¤„ç†å’Œåˆ†æ
- numpy: æ•°å­¦è®¡ç®—
- streamlit_echarts: å›¾è¡¨å¯è§†åŒ–
- sklearn: æœºå™¨å­¦ä¹ è¯„ä¼°æŒ‡æ ‡
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import json
from pathlib import Path
import sys
import traceback
from streamlit_echarts import st_echarts
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy import stats
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = str(Path(__file__).parent.parent)
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥å·¥å…·å‡½æ•°
try:
    from src.utils.session import get_state, set_state
    from src.utils.visualization import ModelVisualization
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºç©ºå‡½æ•°
    def get_state(key, default=None):
        return st.session_state.get(key, default)
    
    def set_state(key, value):
        st.session_state[key] = value

# å¯¼å…¥ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°
try:
    from src.models.arima_model import (
        create_timeseries_chart,
        create_histogram_chart,
        prepare_arima_charts
    )
except ImportError as e:
    st.warning(f"æ— æ³•å¯¼å…¥ARIMAå›¾è¡¨å‡½æ•°: {e}")
    # åˆ›å»ºå ä½å‡½æ•°
    def create_timeseries_chart(*args, **kwargs):
        return {"title": {"text": "å›¾è¡¨å‡½æ•°æœªå¯¼å…¥"}}
    def create_histogram_chart(*args, **kwargs):
        return {"title": {"text": "å›¾è¡¨å‡½æ•°æœªå¯¼å…¥"}}
    def prepare_arima_charts(*args, **kwargs):
        return {"residuals_chart": None, "residuals_hist": None}

def fix_datetime_for_arrow(df):
    """
    ä¿®å¤DataFrameä¸­çš„æ—¶é—´æˆ³æ•°æ®ä»¥å…¼å®¹PyArrow
    
    å‚æ•°:
        df (DataFrame): åŒ…å«æ—¶é—´æˆ³æ•°æ®çš„DataFrame
        
    è¿”å›:
        DataFrame: ä¿®å¤åçš„DataFrame
    """
    df_fixed = df.copy()
    
    # æ£€æŸ¥æ¯ä¸€åˆ—æ˜¯å¦åŒ…å«æ—¶é—´æˆ³æ•°æ®
    for col in df_fixed.columns:
        if df_fixed[col].dtype == 'datetime64[ns]':
            # å°†çº³ç§’ç²¾åº¦çš„æ—¶é—´æˆ³è½¬æ¢ä¸ºå¾®ç§’ç²¾åº¦
            df_fixed[col] = pd.to_datetime(df_fixed[col]).dt.floor('us')
        elif pd.api.types.is_datetime64_any_dtype(df_fixed[col]):
            # å¤„ç†å…¶ä»–æ—¶é—´æˆ³æ ¼å¼
            try:
                df_fixed[col] = pd.to_datetime(df_fixed[col]).dt.floor('us')
            except Exception as e:
                st.warning(f"åˆ— {col} çš„æ—¶é—´æˆ³è½¬æ¢å¤±è´¥: {e}")
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                df_fixed[col] = df_fixed[col].astype(str)
    
    return df_fixed

# ä¿®å¤PyTorchä¸Streamlitçš„å…¼å®¹æ€§é—®é¢˜
torch.classes.__path__ = []

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨¡å‹è¯„ä¼°",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜å’Œç®€ä»‹
st.title("ğŸ“ˆ æ¨¡å‹è¯„ä¼°")
st.markdown("å¯¹è®­ç»ƒå®Œæˆçš„æ¨¡å‹è¿›è¡Œè¯¦ç»†æ€§èƒ½åˆ†æå’Œå¯¹æ¯”è¯„ä¼°")

def check_model_availability():
    """æ£€æŸ¥å¯ç”¨çš„è®­ç»ƒæ¨¡å‹"""
    available_models = []
    model_info = {}
    
    # æ£€æŸ¥LSTMæ¨¡å‹
    lstm_available = False
    # æ›´ä¸¥æ ¼çš„LSTMæ£€æµ‹ï¼šå¿…é¡»æœ‰æ˜ç¡®çš„LSTMè®­ç»ƒå®Œæˆæ ‡å¿—æˆ–è€…æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    if st.session_state.get('lstm_training_complete', False):
        lstm_available = True
    elif st.session_state.get('training_complete', False) and st.session_state.get('trained_model') is not None:
        # åªæœ‰å½“æœ‰å®é™…çš„è®­ç»ƒæ¨¡å‹æ—¶æ‰è®¤ä¸ºLSTMå¯ç”¨
        lstm_available = True
    
    if lstm_available:
        available_models.append("LSTM")
        metrics = st.session_state.get('model_metrics', {})
        model_info["LSTM"] = {
            "status": "å·²è®­ç»ƒ",
            "metrics": metrics,
            "training_time": st.session_state.get('training_time', "æœªçŸ¥"),
            "has_predictions": 'y_test' in st.session_state or 'lstm_test_predictions' in st.session_state
        }
    
    # æ£€æŸ¥ARIMAæ¨¡å‹
    arima_available = False
    if st.session_state.get('arima_training_complete', False):
        if st.session_state.get('arima_model') is not None:
            arima_available = True
        elif 'arima_model_metrics' in st.session_state and st.session_state['arima_model_metrics']:
            arima_available = True
        elif 'arima_training_result' in st.session_state:
            arima_available = True
    
    if arima_available:
        available_models.append("ARIMA")
        metrics = st.session_state.get('arima_model_metrics', {})
        model_info["ARIMA"] = {
            "status": "å·²è®­ç»ƒ",
            "metrics": metrics,
            "training_time": st.session_state.get('arima_training_time', "æœªçŸ¥"),
            "has_predictions": 'arima_training_result' in st.session_state
        }
    
    return available_models, model_info

def create_model_comparison_radar():
    """åˆ›å»ºæ¨¡å‹æ€§èƒ½é›·è¾¾å›¾"""
    # ç¤ºä¾‹æ•°æ®ï¼Œå®é™…åº”è¯¥ä»session stateè·å–
    radar_option = {
        "title": {
            "text": "æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾",
            "left": "center",
            "textStyle": {"fontSize": 16}
        },
        "tooltip": {
            "trigger": "item"
        },
        "legend": {
            "data": ["LSTM", "ARIMA"],
            "bottom": "10px"
        },
        "radar": {
            "indicator": [
                {"name": "å‡†ç¡®æ€§", "max": 100},
                {"name": "ç¨³å®šæ€§", "max": 100},
                {"name": "é€Ÿåº¦", "max": 100},
                {"name": "é²æ£’æ€§", "max": 100},
                {"name": "å¯è§£é‡Šæ€§", "max": 100}
            ],
            "center": ["50%", "50%"],
            "radius": "70%"
        },
        "series": [{
            "type": "radar",
            "data": [
                {
                    "value": [85, 90, 70, 80, 60],
                    "name": "LSTM",
                    "itemStyle": {"color": "#5470c6"}
                },
                {
                    "value": [75, 85, 95, 85, 90],
                    "name": "ARIMA",
                    "itemStyle": {"color": "#91cc75"}
                }
            ]
        }]
    }
    return radar_option

def create_prediction_comparison_chart(dates, actual_values, lstm_pred=None, arima_pred=None):
    """åˆ›å»ºé¢„æµ‹å¯¹æ¯”å›¾è¡¨"""
    # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯PythonåŸç”Ÿç±»å‹
    actual_values = np.array(actual_values).astype(float).tolist()
    
    series_data = [
        {
            "name": "å®é™…å€¼",
            "type": "line",
            "smooth": True,
            "data": actual_values,
            "showSymbol": False,
            "connectNulls": True
        }
    ]
    
    legend_data = ["å®é™…å€¼"]
    
    if lstm_pred is not None:
        lstm_pred = np.array(lstm_pred).astype(float).tolist()
        series_data.append({
            "name": "LSTMé¢„æµ‹",
            "type": "line",
            "smooth": True,
            "data": lstm_pred,
            "showSymbol": False,
            "connectNulls": True
        })
        legend_data.append("LSTMé¢„æµ‹")
    
    if arima_pred is not None:
        arima_pred = np.array(arima_pred).astype(float).tolist()
        series_data.append({
            "name": "ARIMAé¢„æµ‹",
            "type": "line",
            "smooth": True,
            "data": arima_pred,
            "showSymbol": False,
            "connectNulls": True
        })
        legend_data.append("ARIMAé¢„æµ‹")
    
    option = {
        "title": {
            "text": "é¢„æµ‹å€¼ vs å®é™…å€¼å¯¹æ¯”",
            "left": "center"
        },
        "tooltip": {
            "trigger": "axis",
            "axisPointer": {"type": "shadow"}
        },
        "legend": {
            "data": legend_data,
            "top": "30px"
        },
        "grid": {
            "left": "3%",
            "right": "4%",
            "bottom": "3%",
            "containLabel": True
        },
        "toolbox": {
            "feature": {
                "saveAsImage": {}
            }
        },
        "xAxis": {
            "type": "category",
            "boundaryGap": False,
            "data": dates
        },
        "yAxis": {
            "type": "value",
            "scale": True,
            "splitLine": {
                "show": True
            }
        },
        "dataZoom": [
            {
                "type": "inside",
                "start": 0,
                "end": 100
            },
            {
                "start": 0,
                "end": 100
            }
        ],
        "series": series_data
    }
    return option

def create_error_distribution_chart(errors, model_name="æ¨¡å‹"):
    """åˆ›å»ºè¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(errors, 'values'):
            errors = errors.values
        if hasattr(errors, 'flatten'):
            errors = errors.flatten()
        
        # è¿‡æ»¤NaNå€¼
        clean_errors = []
        for err in errors:
            try:
                if not pd.isna(err) and not np.isnan(float(err)):
                    clean_errors.append(float(err))
            except (ValueError, TypeError):
                continue
        
        if not clean_errors:
            return {
                "title": {"text": f"{model_name}è¯¯å·®åˆ†å¸ƒ - æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
                "xAxis": {"type": "category", "data": []},
                "yAxis": {"type": "value"},
                "series": [{"type": "bar", "data": []}]
            }
        
        # è®¡ç®—ç›´æ–¹å›¾æ•°æ®
        hist, bin_edges = np.histogram(clean_errors, bins=30)
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
        
        option = {
            "title": {
                "text": f"{model_name}è¯¯å·®åˆ†å¸ƒ",
                "left": "center",
                "textStyle": {"fontSize": 14}
            },
            "tooltip": {
                "trigger": "axis"
            },
            "xAxis": {
                "type": "category",
                "data": [f"{float(x):.3f}" for x in bin_centers],
                "name": "è¯¯å·®å€¼"
            },
            "yAxis": {
                "type": "value",
                "name": "é¢‘æ¬¡"
            },
            "series": [{
                "type": "bar",
                "data": [int(x) for x in hist],
                "itemStyle": {"color": "#73c0de"}
            }]
        }
        return option
    except Exception as e:
        st.error(f"åˆ›å»ºè¯¯å·®åˆ†å¸ƒå›¾è¡¨å¤±è´¥: {e}")
        return {
            "title": {"text": f"{model_name}è¯¯å·®åˆ†å¸ƒ - åˆ›å»ºå¤±è´¥", "left": "center"},
            "xAxis": {"type": "category", "data": []},
            "yAxis": {"type": "value"},
            "series": [{"type": "bar", "data": []}]
        }

def create_residual_analysis_chart(residuals, dates):
    """åˆ›å»ºæ®‹å·®åˆ†æå›¾è¡¨"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(residuals, 'values'):
            residuals = residuals.values
        if hasattr(residuals, 'flatten'):
            residuals = residuals.flatten()
        
        # ç¡®ä¿æ•°æ®æ˜¯PythonåŸç”Ÿç±»å‹ï¼Œå¤„ç†NaNå€¼
        clean_residuals = []
        clean_dates = []
        for i, (res, date) in enumerate(zip(residuals, dates)):
            try:
                if pd.isna(res) or np.isnan(float(res)):
                    continue  # è·³è¿‡NaNå€¼
                clean_residuals.append(float(res))
                clean_dates.append(str(date))
            except (ValueError, TypeError):
                continue  # è·³è¿‡æ— æ³•è½¬æ¢çš„å€¼
        
        if not clean_residuals:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¿”å›ç©ºå›¾è¡¨
            return {
                "title": {"text": "æ®‹å·®åˆ†æ - æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
                "xAxis": {"type": "category", "data": []},
                "yAxis": {"type": "value"},
                "series": [{"type": "line", "data": []}]
            }
        
        option = {
            "title": {
                "text": "æ®‹å·®æ—¶é—´åºåˆ—åˆ†æ",
                "left": "center",
                "textStyle": {"fontSize": 14}
            },
            "tooltip": {
                "trigger": "axis"
            },
            "xAxis": {
                "type": "category",
                "data": clean_dates,
                "axisLabel": {"rotate": 45}
            },
            "yAxis": {
                "type": "value",
                "name": "æ®‹å·®"
            },
            "series": [{
                "type": "line",
                "data": clean_residuals,
                "lineStyle": {"color": "#ee6666", "width": 1},
                "symbol": "none"
            }],
            "dataZoom": [{
                "type": "slider",
                "start": 0,
                "end": 100
            }]
        }
        return option
    except Exception as e:
        st.error(f"åˆ›å»ºæ®‹å·®åˆ†æå›¾è¡¨å¤±è´¥: {e}")
        return {
            "title": {"text": "æ®‹å·®åˆ†æ - åˆ›å»ºå¤±è´¥", "left": "center"},
            "xAxis": {"type": "category", "data": []},
            "yAxis": {"type": "value"},
            "series": [{"type": "line", "data": []}]
        }

def create_scatter_plot(actual, predicted, model_name="æ¨¡å‹"):
    """åˆ›å»ºæ•£ç‚¹å›¾ï¼šé¢„æµ‹vså®é™…"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(actual, 'values'):
            actual = actual.values
        if hasattr(predicted, 'values'):
            predicted = predicted.values
        if hasattr(actual, 'flatten'):
            actual = actual.flatten()
        if hasattr(predicted, 'flatten'):
            predicted = predicted.flatten()
        
        # è¿‡æ»¤NaNå€¼ï¼Œç¡®ä¿ä¸¤ä¸ªæ•°ç»„é•¿åº¦ä¸€è‡´
        clean_actual = []
        clean_predicted = []
        for i, (a, p) in enumerate(zip(actual, predicted)):
            try:
                if not pd.isna(a) and not pd.isna(p) and not np.isnan(float(a)) and not np.isnan(float(p)):
                    clean_actual.append(float(a))
                    clean_predicted.append(float(p))
            except (ValueError, TypeError):
                continue
        
        if not clean_actual or not clean_predicted:
            return {
                "title": {"text": f"{model_name}é¢„æµ‹æ•£ç‚¹å›¾ - æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
                "xAxis": {"type": "value"},
                "yAxis": {"type": "value"},
                "series": [{"type": "scatter", "data": []}]
            }
        
        # è®¡ç®—RÂ²
        r2 = float(r2_score(clean_actual, clean_predicted))
        
        # åˆ›å»ºå¯¹è§’çº¿æ•°æ®ï¼ˆå®Œç¾é¢„æµ‹çº¿ï¼‰
        min_val = float(min(min(clean_actual), min(clean_predicted)))
        max_val = float(max(max(clean_actual), max(clean_predicted)))
        diagonal_line = [min_val, max_val]
        
        option = {
            "title": {
                "text": f"{model_name}é¢„æµ‹æ•£ç‚¹å›¾ (RÂ² = {r2:.3f})",
                "left": "center"
            },
            "tooltip": {
                "trigger": "item",
                "formatter": "å®é™…å€¼: {data[0]}<br/>é¢„æµ‹å€¼: {data[1]}"
            },
            "grid": {
                "left": "3%",
                "right": "4%",
                "bottom": "3%",
                "containLabel": True
            },
            "toolbox": {
                "feature": {
                    "saveAsImage": {}
                }
            },
            "xAxis": {
                "type": "value",
                "name": "å®é™…å€¼",
                "min": min_val,
                "max": max_val
            },
            "yAxis": {
                "type": "value",
                "name": "é¢„æµ‹å€¼",
                "min": min_val,
                "max": max_val
            },
            "series": [
                {
                    "type": "scatter",
                    "data": [[clean_actual[i], clean_predicted[i]] for i in range(len(clean_actual))],
                    "itemStyle": {"color": "#5470c6", "opacity": 0.6},
                    "symbolSize": 6
                },
                {
                    "type": "line",
                    "data": [[diagonal_line[0], diagonal_line[0]], [diagonal_line[1], diagonal_line[1]]],
                    "lineStyle": {"color": "#ee6666", "type": "dashed"},
                    "symbol": "none",
                    "name": "å®Œç¾é¢„æµ‹çº¿"
                }
            ]
        }
        return option
    except Exception as e:
        st.error(f"åˆ›å»ºæ•£ç‚¹å›¾å¤±è´¥: {e}")
        return {
            "title": {"text": f"{model_name}é¢„æµ‹æ•£ç‚¹å›¾ - åˆ›å»ºå¤±è´¥", "left": "center"},
            "xAxis": {"type": "value"},
            "yAxis": {"type": "value"},
            "series": [{"type": "scatter", "data": []}]
        }

def calculate_model_metrics(actual, predicted):
    """è®¡ç®—æ¨¡å‹è¯„ä¼°æŒ‡æ ‡"""
    try:
        # å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹
        if hasattr(actual, 'values'):
            actual = actual.values
        if hasattr(predicted, 'values'):
            predicted = predicted.values
        if hasattr(actual, 'flatten'):
            actual = actual.flatten()
        if hasattr(predicted, 'flatten'):
            predicted = predicted.flatten()
        
        # è¿‡æ»¤NaNå€¼ï¼Œç¡®ä¿ä¸¤ä¸ªæ•°ç»„é•¿åº¦ä¸€è‡´
        clean_actual = []
        clean_predicted = []
        for i, (a, p) in enumerate(zip(actual, predicted)):
            try:
                if not pd.isna(a) and not pd.isna(p) and not np.isnan(float(a)) and not np.isnan(float(p)):
                    clean_actual.append(float(a))
                    clean_predicted.append(float(p))
            except (ValueError, TypeError):
                continue
        
        if not clean_actual or not clean_predicted:
            return {
                "MSE": 0.0,
                "RMSE": 0.0,
                "MAE": 0.0,
                "MAPE": 0.0,
                "æ–¹å‘å‡†ç¡®ç‡": 0.0,
                "RÂ²": 0.0
            }
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        actual_array = np.array(clean_actual)
        predicted_array = np.array(clean_predicted)
        
        mse = float(mean_squared_error(actual_array, predicted_array))
        rmse = float(np.sqrt(mse))
        mae = float(mean_absolute_error(actual_array, predicted_array))
        
        # è®¡ç®—MAPEï¼Œé¿å…é™¤é›¶é”™è¯¯
        try:
            mape = float(np.mean(np.abs((actual_array - predicted_array) / actual_array)) * 100)
        except (ZeroDivisionError, RuntimeWarning):
            mape = 0.0
        
        # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡
        if len(actual_array) > 1:
            actual_direction = np.sign(actual_array[1:] - actual_array[:-1])
            pred_direction = np.sign(predicted_array[1:] - predicted_array[:-1])
            direction_accuracy = float(np.mean(actual_direction == pred_direction) * 100)
        else:
            direction_accuracy = 0.0
        
        # è®¡ç®—RÂ²
        r2 = float(r2_score(actual_array, predicted_array))
        
        return {
            "MSE": mse,
            "RMSE": rmse,
            "MAE": mae,
            "MAPE": mape,
            "æ–¹å‘å‡†ç¡®ç‡": direction_accuracy,
            "RÂ²": r2
        }
    except Exception as e:
        st.error(f"è®¡ç®—æ¨¡å‹æŒ‡æ ‡å¤±è´¥: {e}")
        return {
            "MSE": 0.0,
            "RMSE": 0.0,
            "MAE": 0.0,
            "MAPE": 0.0,
            "æ–¹å‘å‡†ç¡®ç‡": 0.0,
            "RÂ²": 0.0
        }

def get_prediction_data():
    """
    ç»Ÿä¸€è·å–é¢„æµ‹æ•°æ®å’Œå®é™…å€¼
    
    è¿”å›:
        tuple: (actual_values, lstm_pred, arima_pred, dates, has_real_data)
    """
    has_real_data = False
    dates = []
    actual_values = []
    lstm_pred = None
    arima_pred = None
    
    # å°è¯•è·å–çœŸå®çš„æµ‹è¯•æ•°æ®å’Œé¢„æµ‹ç»“æœ
    if 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
        df = st.session_state['raw_data'].copy()
        
        # ä¿®å¤æ•°æ®ç±»å‹é—®é¢˜
        try:
            # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
            numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯æ­£ç¡®çš„æ—¥æœŸæ—¶é—´æ ¼å¼
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                # ç§»é™¤æ— æ•ˆçš„æ—¥æœŸ
                df = df.dropna(subset=['Date'])
                # æŒ‰æ—¥æœŸæ’åº
                df = df.sort_values('Date').reset_index(drop=True)
        except Exception as e:
            st.warning(f"æ•°æ®ç±»å‹ä¿®å¤å¤±è´¥: {e}")
            return [], None, None, [], False
        
        # é¦–å…ˆå°è¯•è·å–ç»Ÿä¸€çš„actual_valuesåŸºå‡†
        base_actual_values = []
        
        # è·å–LSTMé¢„æµ‹æ•°æ®
        if st.session_state.get('lstm_training_complete', False):
            try:
                # ä¼˜å…ˆä½¿ç”¨ä¿å­˜çš„é¢„æµ‹ç»“æœ
                if 'lstm_test_predictions' in st.session_state:
                    lstm_pred = st.session_state['lstm_test_predictions']
                    
                    # å…³é”®ä¿®å¤ï¼šç›´æ¥ä»åŸå§‹æ•°æ®è·å–çœŸå®çš„å®é™…å€¼ï¼Œä¸è®­ç»ƒé¡µé¢ä¿æŒä¸€è‡´
                    train_test_ratio = st.session_state.get('train_test_ratio', 0.8)
                    
                    # è·å–ç›®æ ‡åˆ—ï¼ˆé€šå¸¸æ˜¯Closeï¼‰
                    target_column = 'Close'  # é»˜è®¤ä½¿ç”¨Closeåˆ—
                    if 'selected_features' in st.session_state:
                        selected_features = st.session_state['selected_features']
                        # å¦‚æœCloseåœ¨é€‰æ‹©çš„ç‰¹å¾ä¸­ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾
                        if 'Close' in selected_features:
                            target_column = 'Close'
                        elif selected_features:
                            target_column = selected_features[0]
                    
                    # ä»åŸå§‹æ•°æ®ä¸­è·å–çœŸå®çš„æµ‹è¯•é›†å®é™…å€¼
                    if target_column in df.columns:
                        # ä½¿ç”¨ä¸ARIMAå®Œå…¨ä¸€è‡´çš„æ•°æ®åˆ’åˆ†æ–¹å¼
                        train_size = int(len(df) * train_test_ratio)
                        test_actual_values = df[target_column].iloc[train_size:].values
                        
                        # ç°åœ¨LSTMæµ‹è¯•é›†åº”è¯¥ä¸ARIMAæµ‹è¯•é›†å¤§å°ä¸€è‡´
                        # ä½†ç”±äºåºåˆ—åˆ›å»ºï¼ŒLSTMé¢„æµ‹æ•°é‡å¯èƒ½ä»ç„¶å°‘äºåŸå§‹æµ‹è¯•é›†
                        if len(lstm_pred) < len(test_actual_values):
                            # æˆªå–å¯¹åº”é•¿åº¦çš„å®é™…å€¼ï¼Œä»æµ‹è¯•é›†æœ«å°¾å¼€å§‹
                            base_actual_values = test_actual_values[-len(lstm_pred):]
                        elif len(lstm_pred) > len(test_actual_values):
                            # å¦‚æœLSTMé¢„æµ‹ç‚¹æ•°å¤šäºå®é™…å€¼ï¼Œæˆªå–LSTMé¢„æµ‹
                            lstm_pred = lstm_pred[:len(test_actual_values)]
                            base_actual_values = test_actual_values
                        else:
                            base_actual_values = test_actual_values
                        
                        if len(base_actual_values) > 0 and len(lstm_pred) > 0:
                            has_real_data = True
                    
                # å¦‚æœæ²¡æœ‰ä¿å­˜çš„é¢„æµ‹ç»“æœï¼Œå°è¯•é‡æ–°ç”Ÿæˆ
                elif 'trained_model' in st.session_state and 'X_test' in st.session_state:
                    model = st.session_state['trained_model']
                    X_test = st.session_state['X_test']
                    target_scaler = st.session_state.get('target_scaler')
                    
                    # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
                    if not isinstance(X_test, (int, float)):
                        # è½¬æ¢ä¸ºtorch tensor
                        if not isinstance(X_test, torch.Tensor):
                            X_test_tensor = torch.FloatTensor(X_test)
                        else:
                            X_test_tensor = X_test
                        
                        model.eval()
                        with torch.no_grad():
                            predictions = model(X_test_tensor)
                            lstm_pred = predictions.detach().cpu().numpy().flatten()
                            
                            # åå½’ä¸€åŒ–é¢„æµ‹å€¼
                            if target_scaler is not None:
                                lstm_pred = target_scaler.inverse_transform(lstm_pred.reshape(-1, 1)).flatten()
                            
                            # è·å–çœŸå®çš„å®é™…å€¼ï¼ˆä¸ä¸Šé¢çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
                            train_test_ratio = st.session_state.get('train_test_ratio', 0.8)
                            target_column = 'Close'
                            if 'selected_features' in st.session_state:
                                selected_features = st.session_state['selected_features']
                                if 'Close' in selected_features:
                                    target_column = 'Close'
                                elif selected_features:
                                    target_column = selected_features[0]
                            
                            if target_column in df.columns:
                                train_size = int(len(df) * train_test_ratio)
                                test_actual_values = df[target_column].iloc[train_size:].values
                                
                                # ç°åœ¨LSTMæµ‹è¯•é›†åº”è¯¥ä¸ARIMAæµ‹è¯•é›†å¤§å°ä¸€è‡´
                                # ä½†ç”±äºåºåˆ—åˆ›å»ºï¼ŒLSTMé¢„æµ‹æ•°é‡å¯èƒ½ä»ç„¶å°‘äºåŸå§‹æµ‹è¯•é›†
                                if len(lstm_pred) < len(test_actual_values):
                                    # æˆªå–å¯¹åº”é•¿åº¦çš„å®é™…å€¼ï¼Œä»æµ‹è¯•é›†æœ«å°¾å¼€å§‹
                                    base_actual_values = test_actual_values[-len(lstm_pred):]
                                elif len(lstm_pred) > len(test_actual_values):
                                    # å¦‚æœLSTMé¢„æµ‹ç‚¹æ•°å¤šäºå®é™…å€¼ï¼Œæˆªå–LSTMé¢„æµ‹
                                    lstm_pred = lstm_pred[:len(test_actual_values)]
                                    base_actual_values = test_actual_values
                                else:
                                    base_actual_values = test_actual_values
                            
                            has_real_data = True
                            
            except Exception as e:
                st.warning(f"è·å–LSTMé¢„æµ‹æ•°æ®å¤±è´¥: {e}")
        
        # è·å–ARIMAé¢„æµ‹æ•°æ®
        if st.session_state.get('arima_training_complete', False) and 'arima_training_result' in st.session_state:
            try:
                arima_result = st.session_state['arima_training_result']
                if 'test_pred' in arima_result:
                    # ç¡®ä¿ARIMAé¢„æµ‹æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
                    arima_pred_raw = arima_result['test_pred']
                    if hasattr(arima_pred_raw, 'values'):
                        arima_pred = arima_pred_raw.values.flatten()
                    elif hasattr(arima_pred_raw, 'flatten'):
                        arima_pred = arima_pred_raw.flatten()
                    else:
                        arima_pred = np.array(arima_pred_raw).flatten()
                    
                    # å¦‚æœè¿˜æ²¡æœ‰base_actual_valuesï¼Œä»ARIMAç»“æœè·å–
                    if len(base_actual_values) == 0 and 'test_data' in arima_result:
                        test_data_raw = arima_result['test_data']
                        if hasattr(test_data_raw, 'values'):
                            base_actual_values = test_data_raw.values.flatten()
                        elif hasattr(test_data_raw, 'flatten'):
                            base_actual_values = test_data_raw.flatten()
                        else:
                            base_actual_values = np.array(test_data_raw).flatten()
                    
                    has_real_data = True
            except Exception as e:
                st.warning(f"è·å–ARIMAé¢„æµ‹æ•°æ®å¤±è´¥: {e}")
        
        # è®¾ç½®æœ€ç»ˆçš„actual_values
        actual_values = base_actual_values
        
        # ç”Ÿæˆæ—¥æœŸåºåˆ—
        if len(actual_values) > 0:
            if 'Date' in df.columns and len(df) > 0:
                try:
                    # ä½¿ç”¨æµ‹è¯•é›†å¯¹åº”çš„æ—¥æœŸ
                    train_test_ratio = st.session_state.get('train_test_ratio', 0.8)
                    train_size = int(len(df) * train_test_ratio)
                    test_end_idx = train_size + len(actual_values)
                    
                    # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
                    if test_end_idx <= len(df):
                        test_dates_raw = df['Date'].iloc[train_size:test_end_idx]
                        # å®‰å…¨åœ°è½¬æ¢æ—¥æœŸä¸ºå­—ç¬¦ä¸²
                        dates = []
                        for date in test_dates_raw:
                            try:
                                if pd.isna(date):
                                    dates.append(f"Day {len(dates)+1}")
                                elif hasattr(date, 'strftime'):
                                    dates.append(date.strftime('%Y-%m-%d'))
                                else:
                                    dates.append(str(date))
                            except Exception:
                                dates.append(f"Day {len(dates)+1}")
                    else:
                        # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œç”Ÿæˆé»˜è®¤æ—¥æœŸ
                        dates = [f"Day {i+1}" for i in range(len(actual_values))]
                except Exception as e:
                    st.warning(f"æ—¥æœŸç”Ÿæˆå¤±è´¥: {e}")
                    dates = [f"Day {i+1}" for i in range(len(actual_values))]
            else:
                dates = [f"Day {i+1}" for i in range(len(actual_values))]
    
    # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤º
    if not has_real_data:
        # ç”Ÿæˆç¤ºä¾‹æ•°æ®
        np.random.seed(42)
        actual_values = np.random.randn(50).cumsum() + 100
        dates = [f"Day {i}" for i in range(50)]
        
        if st.session_state.get('lstm_training_complete', False):
            lstm_pred = actual_values + np.random.randn(50) * 0.5
        
        if st.session_state.get('arima_training_complete', False):
            arima_pred = actual_values + np.random.randn(50) * 0.3
    
    return actual_values, lstm_pred, arima_pred, dates, has_real_data

# æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
available_models, model_info = check_model_availability()

# æ·»åŠ è°ƒè¯•ä¿¡æ¯å±•å¼€æ¡†
with st.expander("ğŸ”§ è°ƒè¯•ä¿¡æ¯", expanded=False):
    st.markdown("**Session State å…³é”®ä¿¡æ¯:**")
    debug_info = {
        "LSTMè®­ç»ƒå®Œæˆ": st.session_state.get('lstm_training_complete', False),
        "é€šç”¨è®­ç»ƒå®Œæˆ": st.session_state.get('training_complete', False),
        "ARIMAè®­ç»ƒå®Œæˆ": st.session_state.get('arima_training_complete', False),
        "å·²è®­ç»ƒæ¨¡å‹": st.session_state.get('trained_model') is not None,
        "ARIMAæ¨¡å‹": st.session_state.get('arima_model') is not None,
        "æ¨¡å‹æŒ‡æ ‡": 'model_metrics' in st.session_state,
        "ARIMAæŒ‡æ ‡": 'arima_model_metrics' in st.session_state,
        "æµ‹è¯•æ•°æ®": 'y_test' in st.session_state,
        "Xæµ‹è¯•æ•°æ®": 'X_test' in st.session_state,
        "LSTMé¢„æµ‹ç»“æœ": 'lstm_test_predictions' in st.session_state,
        "ARIMAç»“æœ": 'arima_training_result' in st.session_state,
        "åŸå§‹æ•°æ®": 'raw_data' in st.session_state
    }
    
    # æ·»åŠ æ•°æ®ç±»å‹å’Œå½¢çŠ¶ä¿¡æ¯
    if 'y_test' in st.session_state:
        y_test = st.session_state['y_test']
        debug_info[f"y_testç±»å‹"] = f"{type(y_test)} - å½¢çŠ¶: {getattr(y_test, 'shape', 'N/A')}"
    
    if 'X_test' in st.session_state:
        X_test = st.session_state['X_test']
        debug_info[f"X_testç±»å‹"] = f"{type(X_test)} - å½¢çŠ¶: {getattr(X_test, 'shape', 'N/A')}"
    
    for key, value in debug_info.items():
        if value:
            st.success(f"âœ… {key}: {value}")
        else:
            st.error(f"âŒ {key}: {value}")
    
    st.markdown("**å¯ç”¨æ¨¡å‹:**")
    if available_models:
        for model in available_models:
            st.success(f"âœ… {model}")
            info = model_info[model]
            st.json(info)
    else:
        st.warning("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")

if not available_models:
    st.warning("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°å·²è®­ç»ƒçš„æ¨¡å‹ã€‚è¯·å…ˆåœ¨æ¨¡å‹è®­ç»ƒé¡µé¢è®­ç»ƒæ¨¡å‹ã€‚")
    st.info("ğŸ’¡ æç¤ºï¼šæ‚¨éœ€è¦å…ˆå®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š")
    st.markdown("""
    1. åœ¨**æ•°æ®æŸ¥çœ‹**é¡µé¢åŠ è½½æ•°æ®
    2. åœ¨**æ¨¡å‹è®­ç»ƒ**é¡µé¢è®­ç»ƒLSTMæˆ–ARIMAæ¨¡å‹
    3. è®­ç»ƒå®Œæˆåè¿”å›æ­¤é¡µé¢è¿›è¡Œè¯„ä¼°
    """)
    st.stop()

# å¿«é€ŸçŠ¶æ€æ¦‚è§ˆ
st.subheader("ğŸ“Š æ¨¡å‹çŠ¶æ€æ¦‚è§ˆ")
status_cols = st.columns(len(available_models) + 2)

with status_cols[0]:
    st.metric("å·²è®­ç»ƒæ¨¡å‹", f"{len(available_models)}ä¸ª", 
              " + ".join(available_models))

with status_cols[1]:
    # ç¡®å®šæœ€ä½³æ¨¡å‹
    best_model = "æœªçŸ¥"
    best_metric = "N/A"
    if available_models:
        # ç®€å•æ¯”è¾ƒMSEæ¥ç¡®å®šæœ€ä½³æ¨¡å‹
        best_mse = float('inf')
        for model in available_models:
            metrics = model_info[model]['metrics']
            if 'MSE' in metrics and metrics['MSE'] < best_mse:
                best_mse = metrics['MSE']
                best_model = model
                best_metric = f"MSE: {best_mse:.4f}"
    
    st.metric("æœ€ä½³æ¨¡å‹", best_model, best_metric)

# ä¸ºæ¯ä¸ªå¯ç”¨æ¨¡å‹æ˜¾ç¤ºçŠ¶æ€
for i, model in enumerate(available_models):
    with status_cols[i + 2]:
        metrics = model_info[model]['metrics']
        rmse_value = metrics.get('RMSE', 0)
        st.metric(f"{model} RMSE", f"{rmse_value:.4f}", 
                  model_info[model]['status'])

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.subheader("ğŸ“‹ è¯„ä¼°é…ç½®")
    
    # æ¨¡å‹é€‰æ‹©
    with st.expander("æ¨¡å‹é€‰æ‹©", expanded=True):
        selected_models = st.multiselect(
            "é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹",
            options=available_models,
            default=available_models,
            help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”åˆ†æ"
        )
    
    # è¯„ä¼°æŒ‡æ ‡é€‰æ‹©
    with st.expander("è¯„ä¼°æŒ‡æ ‡", expanded=True):
        metrics_options = ["MSE", "RMSE", "MAE", "MAPE", "æ–¹å‘å‡†ç¡®ç‡", "RÂ²"]
        selected_metrics = st.multiselect(
            "é€‰æ‹©è¯„ä¼°æŒ‡æ ‡",
            options=metrics_options,
            default=["MSE", "RMSE", "MAE", "æ–¹å‘å‡†ç¡®ç‡"],
            help="é€‰æ‹©ç”¨äºæ¨¡å‹è¯„ä¼°çš„æŒ‡æ ‡"
        )
    
    # æ—¶é—´èŒƒå›´é€‰æ‹©
    with st.expander("æ—¶é—´èŒƒå›´", expanded=True):
        evaluation_period = st.selectbox(
            "è¯„ä¼°æ—¶é—´æ®µ",
            options=["æµ‹è¯•é›†", "è®­ç»ƒé›†", "å…¨éƒ¨æ•°æ®"],
            index=0,
            help="é€‰æ‹©ç”¨äºè¯„ä¼°çš„æ•°æ®èŒƒå›´"
        )
    
    # å›¾è¡¨é…ç½®
    with st.expander("å›¾è¡¨è®¾ç½®", expanded=True):
        chart_height = st.slider(
            "å›¾è¡¨é«˜åº¦",
            min_value=300,
            max_value=800,
            value=400,
            step=50,
            help="è°ƒæ•´å›¾è¡¨æ˜¾ç¤ºé«˜åº¦"
        )
        
        show_confidence_interval = st.checkbox(
            "æ˜¾ç¤ºç½®ä¿¡åŒºé—´", 
            value=False,
            help="åœ¨é¢„æµ‹å›¾è¡¨ä¸­æ˜¾ç¤ºç½®ä¿¡åŒºé—´"
        )
        
        show_residuals = st.checkbox(
            "æ˜¾ç¤ºæ®‹å·®åˆ†æ", 
            value=True,
            help="æ˜¾ç¤ºæ¨¡å‹æ®‹å·®åˆ†æå›¾è¡¨"
        )

# ä¸»è¦è¯„ä¼°æ ‡ç­¾é¡µ
eval_tabs = st.tabs([
    "ğŸ“Š æ¨¡å‹å¯¹æ¯”", 
    "ğŸ“ˆ é¢„æµ‹åˆ†æ", 
    "ğŸ” è¯¯å·®åˆ†æ", 
    "ğŸ§ª æ¨¡å‹è¯Šæ–­", 
    "ğŸ“‹ è¯¦ç»†æŠ¥å‘Š"
])

# æ ‡ç­¾é¡µ1: æ¨¡å‹å¯¹æ¯”
with eval_tabs[0]:
    st.header("ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    
    if len(selected_models) == 0:
        st.warning("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
    else:
        # æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
        st.subheader("æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
        comparison_col1, comparison_col2 = st.columns([2, 1])
        
        with comparison_col1:
            # é›·è¾¾å›¾æ˜¾ç¤ºå¤šç»´åº¦å¯¹æ¯”
            if len(selected_models) >= 2:
                radar_option = create_model_comparison_radar()
                st_echarts(options=radar_option, height=f"{chart_height}px")
            else:
                st.info("éœ€è¦è‡³å°‘2ä¸ªæ¨¡å‹æ‰èƒ½æ˜¾ç¤ºé›·è¾¾å›¾å¯¹æ¯”")
        
        with comparison_col2:
            # æ€§èƒ½æŒ‡æ ‡è¡¨æ ¼
            comparison_data = []
            for model in selected_models:
                metrics = model_info[model]['metrics']
                row = {"æ¨¡å‹": model}
                for metric in selected_metrics:
                    if metric in metrics:
                        row[metric] = f"{metrics[metric]:.4f}"
                    else:
                        row[metric] = "N/A"
                comparison_data.append(row)
            
            if comparison_data:
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                
                # æœ€ä½³æ¨¡å‹æ¨è
                if len(selected_models) > 1:
                    st.success(f"ğŸ† æ¨èæ¨¡å‹: {best_model}")
                    st.info("åŸºäºMSEæŒ‡æ ‡è¯„é€‰")
        
        # æŒ‡æ ‡å¯¹æ¯”æŸ±çŠ¶å›¾
        if len(selected_models) > 1 and comparison_data:
            st.subheader("æŒ‡æ ‡å¯¹æ¯”å›¾")
            
            # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºå¯¹æ¯”å›¾
            for metric in selected_metrics:
                if metric in comparison_df.columns:
                    metric_col1, metric_col2 = st.columns([3, 1])
                    
                    with metric_col1:
                        # åˆ›å»ºæŸ±çŠ¶å›¾
                        metric_values = []
                        model_names = []
                        
                        for _, row in comparison_df.iterrows():
                            if row[metric] != "N/A":
                                try:
                                    metric_values.append(float(row[metric]))
                                    model_names.append(row["æ¨¡å‹"])
                                except ValueError:
                                    continue
                        
                        if metric_values:
                            bar_option = {
                                "title": {
                                    "text": f"{metric}å¯¹æ¯”",
                                    "left": "center",
                                    "textStyle": {"fontSize": 14}
                                },
                                "tooltip": {"trigger": "axis"},
                                "xAxis": {
                                    "type": "category",
                                    "data": model_names
                                },
                                "yAxis": {"type": "value"},
                                "series": [{
                                    "type": "bar",
                                    "data": metric_values,
                                    "itemStyle": {
                                        "color": "#5470c6"
                                    }
                                }]
                            }
                            st_echarts(options=bar_option, height="250px")
                    
                    with metric_col2:
                        # æ˜¾ç¤ºæœ€ä½³å€¼
                        if metric_values:
                            if metric in ["MSE", "RMSE", "MAE", "MAPE"]:
                                best_idx = np.argmin(metric_values)
                                st.success(f"æœ€ä½³: {model_names[best_idx]}")
                                st.metric("æœ€ä½³å€¼", f"{metric_values[best_idx]:.4f}")
                            else:
                                best_idx = np.argmax(metric_values)
                                st.success(f"æœ€ä½³: {model_names[best_idx]}")
                                st.metric("æœ€ä½³å€¼", f"{metric_values[best_idx]:.4f}")

# æ ‡ç­¾é¡µ2: é¢„æµ‹åˆ†æ
with eval_tabs[1]:
    st.header("ğŸ“ˆ é¢„æµ‹ç»“æœåˆ†æ")
    
    if len(selected_models) == 0:
        st.warning("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹è¿›è¡Œåˆ†æ")
    else:
        # è·å–é¢„æµ‹æ•°æ®
        st.subheader("é¢„æµ‹ç»“æœå¯¹æ¯”")
        
        # ä»session stateè·å–å®é™…çš„é¢„æµ‹æ•°æ®
        actual_values, lstm_pred, arima_pred, dates, has_real_data = get_prediction_data()
        
        # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
        if not has_real_data:
            st.info("ğŸ“Š å½“å‰æ˜¾ç¤ºç¤ºä¾‹æ•°æ®ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ä»¥æŸ¥çœ‹çœŸå®é¢„æµ‹ç»“æœ")
        
        # æ•°æ®é•¿åº¦ä¿¡æ¯å’Œå¯¹é½å¤„ç†
        available_lengths = []
        length_info = {}
        
        if len(actual_values) > 0:
            available_lengths.append(len(actual_values))
            length_info["å®é™…å€¼"] = len(actual_values)
        
        if lstm_pred is not None and len(lstm_pred) > 0:
            available_lengths.append(len(lstm_pred))
            length_info["LSTMé¢„æµ‹"] = len(lstm_pred)
        
        if arima_pred is not None and len(arima_pred) > 0:
            available_lengths.append(len(arima_pred))
            length_info["ARIMAé¢„æµ‹"] = len(arima_pred)
        
        # æ£€æŸ¥é•¿åº¦ä¸ä¸€è‡´çš„é—®é¢˜å¹¶æä¾›å¯¹é½ç­–ç•¥é€‰æ‹©
        if len(set(available_lengths)) > 1:
            st.warning("âš ï¸ æ£€æµ‹åˆ°æ•°æ®é•¿åº¦ä¸ä¸€è‡´ï¼Œå¯èƒ½çš„åŸå› ï¼š")
            st.write("- LSTMå’ŒARIMAä½¿ç”¨äº†ä¸åŒçš„åºåˆ—é•¿åº¦è®¾ç½®")
            st.write("- æ•°æ®é¢„å¤„ç†æ–¹å¼ä¸åŒ")
            st.write("- æ¨¡å‹è®­ç»ƒæ—¶çš„å‚æ•°è®¾ç½®ä¸åŒ")
            
            # æä¾›è§£å†³å»ºè®®
            max_length = max(available_lengths)
            min_length = min(available_lengths)
            st.info(f"ğŸ’¡ å»ºè®®ï¼šä½¿ç”¨è¾ƒé•¿çš„æ•°æ®é•¿åº¦({max_length}ä¸ªç‚¹)ä»¥è·å¾—æ›´å¥½çš„æ¯”è¾ƒæ•ˆæœ")
            
            # è®©ç”¨æˆ·é€‰æ‹©å¯¹é½ç­–ç•¥
            alignment_strategy = st.radio(
                "é€‰æ‹©æ•°æ®å¯¹é½ç­–ç•¥:",
                options=["ä½¿ç”¨æœ€å°é•¿åº¦", "ä½¿ç”¨æœ€å¤§é•¿åº¦(å¯èƒ½æœ‰ç¼ºå¤±å€¼)", "ä»…æ˜¾ç¤ºå®Œæ•´æ•°æ®çš„æ¨¡å‹"],
                index=0,
                help="é€‰æ‹©å¦‚ä½•å¤„ç†é•¿åº¦ä¸ä¸€è‡´çš„æ•°æ®"
            )
        else:
            alignment_strategy = "ä½¿ç”¨æœ€å°é•¿åº¦"  # é»˜è®¤ç­–ç•¥
            st.success("âœ… æ‰€æœ‰æ•°æ®é•¿åº¦ä¸€è‡´")
        
        # ç»Ÿä¸€è°ƒè¯•ä¿¡æ¯å±•å¼€æ¡†
        with st.expander("ğŸ”§ æ•°æ®å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯", expanded=False):
            st.markdown("**æ•°æ®æ¥æºä¿¡æ¯:**")
            if "LSTM" in selected_models:
                if 'lstm_test_predictions' in st.session_state:
                    st.success("âœ… LSTM: ä½¿ç”¨ä¿å­˜çš„é¢„æµ‹ç»“æœ")
                else:
                    st.info("â„¹ï¸ LSTM: é‡æ–°ç”Ÿæˆé¢„æµ‹ç»“æœ")
                
                # æ˜¾ç¤ºå®é™…å€¼æ¥æº
                target_column = 'Close'
                if 'selected_features' in st.session_state:
                    selected_features = st.session_state['selected_features']
                    if 'Close' in selected_features:
                        target_column = 'Close'
                    elif selected_features:
                        target_column = selected_features[0]
                st.info(f"âœ… LSTMå®é™…å€¼: ä½¿ç”¨åŸå§‹æ•°æ®ä¸­çš„{target_column}åˆ—")
            
            if "ARIMA" in selected_models:
                st.success("âœ… ARIMA: ä½¿ç”¨è®­ç»ƒç»“æœä¸­çš„é¢„æµ‹æ•°æ®")
                st.info("âœ… ARIMAå®é™…å€¼: ä½¿ç”¨è®­ç»ƒæ—¶çš„æµ‹è¯•é›†æ•°æ®")
            
            st.markdown("**åŸå§‹æ•°æ®é•¿åº¦:**")
            for name, length in length_info.items():
                st.write(f"- {name}: {length} ä¸ªæ•°æ®ç‚¹")
        
        # æ ¹æ®é€‰æ‹©çš„ç­–ç•¥è¿›è¡Œæ•°æ®å¯¹é½
        if available_lengths:
            if alignment_strategy == "ä½¿ç”¨æœ€å°é•¿åº¦":
                final_length = min(available_lengths)
            elif alignment_strategy == "ä½¿ç”¨æœ€å¤§é•¿åº¦(å¯èƒ½æœ‰ç¼ºå¤±å€¼)":
                final_length = max(available_lengths)
                # å¯¹äºè¾ƒçŸ­çš„æ•°æ®ï¼Œç”¨NaNå¡«å……
                if len(actual_values) < final_length:
                    actual_values = np.pad(actual_values, (0, final_length - len(actual_values)), constant_values=np.nan)
                if lstm_pred is not None and len(lstm_pred) < final_length:
                    lstm_pred = np.pad(lstm_pred, (0, final_length - len(lstm_pred)), constant_values=np.nan)
                if arima_pred is not None and len(arima_pred) < final_length:
                    arima_pred = np.pad(arima_pred, (0, final_length - len(arima_pred)), constant_values=np.nan)
            else:  # ä»…æ˜¾ç¤ºå®Œæ•´æ•°æ®çš„æ¨¡å‹
                final_length = min(available_lengths)
                # ç§»é™¤é•¿åº¦ä¸åŒ¹é…çš„æ¨¡å‹æ•°æ®
                if lstm_pred is not None and len(lstm_pred) != max(available_lengths):
                    lstm_pred = None
                if arima_pred is not None and len(arima_pred) != max(available_lengths):
                    arima_pred = None
            
            # è°ƒæ•´æ•°æ®é•¿åº¦
            actual_values = actual_values[:final_length]
            dates = dates[:final_length] if len(dates) > final_length else dates
            if lstm_pred is not None:
                lstm_pred = lstm_pred[:final_length]
            if arima_pred is not None:
                arima_pred = arima_pred[:final_length]
        else:
            final_length = 0
        
        # æ˜¾ç¤ºæœ€ç»ˆæ•°æ®ä¿¡æ¯
        if len(actual_values) > 0:
            st.success(f"ğŸ“ˆ æœ€ç»ˆæ˜¾ç¤ºæ•°æ®ç‚¹æ•°: {len(actual_values)}")
            
            # åœ¨è°ƒè¯•æ¡†ä¸­æ˜¾ç¤ºæœ€ç»ˆæ•°æ®èŒƒå›´
            with st.expander("ğŸ“Š æœ€ç»ˆæ•°æ®èŒƒå›´", expanded=False):
                if len(actual_values) > 0:
                    st.write(f"å®é™…å€¼èŒƒå›´: {np.nanmin(actual_values):.2f} - {np.nanmax(actual_values):.2f}")
                if lstm_pred is not None and len(lstm_pred) > 0:
                    st.write(f"LSTMé¢„æµ‹èŒƒå›´: {np.nanmin(lstm_pred):.2f} - {np.nanmax(lstm_pred):.2f}")
                if arima_pred is not None and len(arima_pred) > 0:
                    st.write(f"ARIMAé¢„æµ‹èŒƒå›´: {np.nanmin(arima_pred):.2f} - {np.nanmax(arima_pred):.2f}")
                st.write(f"æ—¥æœŸèŒƒå›´: {dates[0]} åˆ° {dates[-1]}" if dates else "æ— æ—¥æœŸä¿¡æ¯")
                st.write(f"æ•°æ®ç±»å‹: {'çœŸå®æ•°æ®' if has_real_data else 'ç¤ºä¾‹æ•°æ®'}")
            
            # ä¸»é¢„æµ‹å›¾è¡¨
            try:
                # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
                if len(actual_values) == 0:
                    st.warning("å®é™…å€¼æ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºå›¾è¡¨")
                elif any(not np.isfinite(x) for x in actual_values):
                    st.warning("å®é™…å€¼åŒ…å«æ— æ•ˆæ•°æ®ï¼ˆNaNæˆ–Infï¼‰ï¼Œæ­£åœ¨æ¸…ç†...")
                    # æ¸…ç†æ— æ•ˆæ•°æ®
                    valid_indices = np.isfinite(actual_values)
                    actual_values = actual_values[valid_indices]
                    dates = [dates[i] for i in range(len(dates)) if valid_indices[i]]
                    if lstm_pred is not None:
                        lstm_pred = lstm_pred[valid_indices]
                    if arima_pred is not None:
                        arima_pred = arima_pred[valid_indices]
                
                if len(actual_values) > 0:
                    prediction_option = create_prediction_comparison_chart(
                        dates, actual_values, lstm_pred, arima_pred
                    )
                    st_echarts(options=prediction_option, height=f"{chart_height + 100}px")
                else:
                    st.error("æ¸…ç†åæ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯æ˜¾ç¤º")
                    
            except Exception as chart_error:
                st.error(f"å›¾è¡¨åˆ›å»ºå¤±è´¥: {chart_error}")
                import traceback
                st.code(traceback.format_exc())
            
            # é¢„æµ‹å‡†ç¡®æ€§åˆ†æ
            st.subheader("é¢„æµ‹å‡†ç¡®æ€§åˆ†æ")
            accuracy_cols = st.columns(len(selected_models))
            
            for i, model in enumerate(selected_models):
                with accuracy_cols[i]:
                    try:
                        if model == "LSTM" and lstm_pred is not None and len(lstm_pred) > 0:
                            scatter_option = create_scatter_plot(actual_values, lstm_pred, "LSTM")
                            st_echarts(options=scatter_option, height="300px")
                            
                            # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
                            metrics = calculate_model_metrics(actual_values, lstm_pred)
                            st.markdown(f"**LSTMæ€§èƒ½æŒ‡æ ‡:**")
                            st.markdown(f"- MSE: {metrics['MSE']:.4f}")
                            st.markdown(f"- RMSE: {metrics['RMSE']:.4f}")
                            st.markdown(f"- MAE: {metrics['MAE']:.4f}")
                            st.markdown(f"- RÂ²: {metrics['RÂ²']:.4f}")
                            
                        elif model == "ARIMA" and arima_pred is not None and len(arima_pred) > 0:
                            scatter_option = create_scatter_plot(actual_values, arima_pred, "ARIMA")
                            st_echarts(options=scatter_option, height="300px")
                            
                            # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
                            metrics = calculate_model_metrics(actual_values, arima_pred)
                            st.markdown(f"**ARIMAæ€§èƒ½æŒ‡æ ‡:**")
                            st.markdown(f"- MSE: {metrics['MSE']:.4f}")
                            st.markdown(f"- RMSE: {metrics['RMSE']:.4f}")
                            st.markdown(f"- MAE: {metrics['MAE']:.4f}")
                            st.markdown(f"- RÂ²: {metrics['RÂ²']:.4f}")
                        else:
                            st.warning(f"{model}æ¨¡å‹æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®")
                    except Exception as scatter_error:
                        st.error(f"{model}æ•£ç‚¹å›¾åˆ›å»ºå¤±è´¥: {scatter_error}")
                        import traceback
                        st.code(traceback.format_exc())
        else:
            st.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œé¢„æµ‹åˆ†æ")

# æ ‡ç­¾é¡µ3: è¯¯å·®åˆ†æ
with eval_tabs[2]:
    st.header("ğŸ” è¯¯å·®åˆ†æ")
    
    if len(selected_models) == 0:
        st.warning("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹è¿›è¡Œåˆ†æ")
    else:
        # è·å–çœŸå®çš„é¢„æµ‹æ•°æ®å’Œå®é™…å€¼
        actual_values, lstm_pred, arima_pred, dates, has_real_data = get_prediction_data()
        
        if has_real_data and len(actual_values) > 0:
            # ä¸ºæ¯ä¸ªæ¨¡å‹å•ç‹¬è·å–å¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
            def get_model_specific_data(model_name, pred_values, base_actual_values, base_dates):
                """ä¸ºç‰¹å®šæ¨¡å‹è·å–å¯¹åº”é•¿åº¦çš„å®é™…å€¼å’Œæ—¥æœŸ"""
                if pred_values is None or len(pred_values) == 0:
                    return None, None, None
                
                pred_length = len(pred_values)
                actual_length = len(base_actual_values)
                
                if pred_length <= actual_length:
                    # å¦‚æœé¢„æµ‹é•¿åº¦å°äºç­‰äºå®é™…å€¼é•¿åº¦ï¼Œä½¿ç”¨æœ€åpred_lengthä¸ªå®é™…å€¼
                    model_actual = base_actual_values[-pred_length:]
                    model_dates = base_dates[-pred_length:] if len(base_dates) >= pred_length else base_dates
                else:
                    # å¦‚æœé¢„æµ‹é•¿åº¦å¤§äºå®é™…å€¼é•¿åº¦ï¼Œæˆªå–é¢„æµ‹å€¼
                    pred_values = pred_values[:actual_length]
                    model_actual = base_actual_values
                    model_dates = base_dates
                
                return model_actual, pred_values, model_dates
            
            # æ®‹å·®åˆ†æ - ç§»é™¤show_residualsæ¡ä»¶ï¼Œå§‹ç»ˆæ˜¾ç¤º
            st.subheader("æ®‹å·®åˆ†æ")
            
            if len(selected_models) == 1:
                # å•æ¨¡å‹æ—¶ä½¿ç”¨å…¨å®½åº¦
                model = selected_models[0]
                try:
                    if model == "LSTM" and lstm_pred is not None and len(lstm_pred) > 0:
                        # è·å–LSTMå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                        lstm_actual, lstm_pred_aligned, lstm_dates = get_model_specific_data(
                            "LSTM", lstm_pred, actual_values, dates
                        )
                        
                        if lstm_actual is not None and lstm_pred_aligned is not None:
                            # è®¡ç®—LSTMæ®‹å·®
                            lstm_residuals = np.array(lstm_actual) - np.array(lstm_pred_aligned)
                            
                            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå›¾è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
                            residual_chart_col, residual_stats_col = st.columns([2, 1])
                            
                            with residual_chart_col:
                                # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºæ®‹å·®å›¾
                                residuals_df = pd.DataFrame({'æ®‹å·®': lstm_residuals}, index=lstm_dates)
                                residual_option = create_timeseries_chart(
                                    residuals_df,
                                    title='LSTMæ¨¡å‹æ®‹å·®åˆ†æ'
                                )
                                st_echarts(options=residual_option, height="350px")
                            
                            with residual_stats_col:
                                st.markdown(f"**LSTMæ®‹å·®ç»Ÿè®¡:**")
                                st.metric("æ•°æ®ç‚¹æ•°", len(lstm_residuals))
                                st.metric("å¹³å‡æ®‹å·®", f"{np.mean(lstm_residuals):.4f}")
                                st.metric("æ®‹å·®æ ‡å‡†å·®", f"{np.std(lstm_residuals):.4f}")
                                st.metric("æœ€å¤§ç»å¯¹æ®‹å·®", f"{np.max(np.abs(lstm_residuals)):.4f}")
                        else:
                            st.warning("LSTMæ•°æ®å¯¹é½å¤±è´¥")
                        
                    elif model == "ARIMA" and arima_pred is not None and len(arima_pred) > 0:
                        # è·å–ARIMAå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                        arima_actual, arima_pred_aligned, arima_dates = get_model_specific_data(
                            "ARIMA", arima_pred, actual_values, dates
                        )
                        
                        if arima_actual is not None and arima_pred_aligned is not None:
                            # è®¡ç®—ARIMAæ®‹å·®
                            arima_residuals = np.array(arima_actual) - np.array(arima_pred_aligned)
                            
                            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå›¾è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
                            residual_chart_col, residual_stats_col = st.columns([2, 1])
                            
                            with residual_chart_col:
                                # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºæ®‹å·®å›¾
                                residuals_df = pd.DataFrame({'æ®‹å·®': arima_residuals}, index=arima_dates)
                                residual_option = create_timeseries_chart(
                                    residuals_df,
                                    title='ARIMAæ¨¡å‹æ®‹å·®åˆ†æ'
                                )
                                st_echarts(options=residual_option, height="350px")
                            
                            with residual_stats_col:
                                st.markdown(f"**ARIMAæ®‹å·®ç»Ÿè®¡:**")
                                st.metric("æ•°æ®ç‚¹æ•°", len(arima_residuals))
                                st.metric("å¹³å‡æ®‹å·®", f"{np.mean(arima_residuals):.4f}")
                                st.metric("æ®‹å·®æ ‡å‡†å·®", f"{np.std(arima_residuals):.4f}")
                                st.metric("æœ€å¤§ç»å¯¹æ®‹å·®", f"{np.max(np.abs(arima_residuals)):.4f}")
                        else:
                            st.warning("ARIMAæ•°æ®å¯¹é½å¤±è´¥")
                    else:
                        st.warning(f"{model}æ¨¡å‹æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®")
                except Exception as e:
                    st.error(f"{model}æ®‹å·®åˆ†æå¤±è´¥: {e}")
                    import traceback
                    st.code(traceback.format_exc())
            else:
                # å¤šæ¨¡å‹æ—¶ä½¿ç”¨åˆ—å¸ƒå±€
                residual_cols = st.columns(len(selected_models))
                
                for i, model in enumerate(selected_models):
                    with residual_cols[i]:
                        try:
                            if model == "LSTM" and lstm_pred is not None and len(lstm_pred) > 0:
                                # è·å–LSTMå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                                lstm_actual, lstm_pred_aligned, lstm_dates = get_model_specific_data(
                                    "LSTM", lstm_pred, actual_values, dates
                                )
                                
                                if lstm_actual is not None and lstm_pred_aligned is not None:
                                    # è®¡ç®—LSTMæ®‹å·®
                                    lstm_residuals = np.array(lstm_actual) - np.array(lstm_pred_aligned)
                                    # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºæ®‹å·®å›¾
                                    residuals_df = pd.DataFrame({'æ®‹å·®': lstm_residuals}, index=lstm_dates)
                                    residual_option = create_timeseries_chart(
                                        residuals_df,
                                        title='LSTMæ®‹å·®åˆ†æ'
                                    )
                                    st_echarts(options=residual_option, height="300px")
                                    
                                    # æ˜¾ç¤ºæ®‹å·®ç»Ÿè®¡
                                    st.markdown(f"**LSTMæ®‹å·®ç»Ÿè®¡:**")
                                    st.write(f"- æ•°æ®ç‚¹æ•°: {len(lstm_residuals)}")
                                    st.write(f"- å¹³å‡æ®‹å·®: {np.mean(lstm_residuals):.4f}")
                                    st.write(f"- æ®‹å·®æ ‡å‡†å·®: {np.std(lstm_residuals):.4f}")
                                else:
                                    st.warning("LSTMæ•°æ®å¯¹é½å¤±è´¥")
                                
                            elif model == "ARIMA" and arima_pred is not None and len(arima_pred) > 0:
                                # è·å–ARIMAå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                                arima_actual, arima_pred_aligned, arima_dates = get_model_specific_data(
                                    "ARIMA", arima_pred, actual_values, dates
                                )
                                
                                if arima_actual is not None and arima_pred_aligned is not None:
                                    # è®¡ç®—ARIMAæ®‹å·®
                                    arima_residuals = np.array(arima_actual) - np.array(arima_pred_aligned)
                                    # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºæ®‹å·®å›¾
                                    residuals_df = pd.DataFrame({'æ®‹å·®': arima_residuals}, index=arima_dates)
                                    residual_option = create_timeseries_chart(
                                        residuals_df,
                                        title='ARIMAæ®‹å·®åˆ†æ'
                                    )
                                    st_echarts(options=residual_option, height="300px")
                                    
                                    # æ˜¾ç¤ºæ®‹å·®ç»Ÿè®¡
                                    st.markdown(f"**ARIMAæ®‹å·®ç»Ÿè®¡:**")
                                    st.write(f"- æ•°æ®ç‚¹æ•°: {len(arima_residuals)}")
                                    st.write(f"- å¹³å‡æ®‹å·®: {np.mean(arima_residuals):.4f}")
                                    st.write(f"- æ®‹å·®æ ‡å‡†å·®: {np.std(arima_residuals):.4f}")
                                else:
                                    st.warning("ARIMAæ•°æ®å¯¹é½å¤±è´¥")
                            else:
                                st.warning(f"{model}æ¨¡å‹æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®")
                        except Exception as e:
                            st.error(f"{model}æ®‹å·®åˆ†æå¤±è´¥: {e}")
                            import traceback
                            st.code(traceback.format_exc())
            
            # è¯¯å·®åˆ†å¸ƒåˆ†æ
            st.subheader("è¯¯å·®åˆ†å¸ƒåˆ†æ")
            
            if len(selected_models) == 1:
                # å•æ¨¡å‹æ—¶ä½¿ç”¨å…¨å®½åº¦
                model = selected_models[0]
                try:
                    if model == "LSTM" and lstm_pred is not None and len(lstm_pred) > 0:
                        # è·å–LSTMå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                        lstm_actual, lstm_pred_aligned, _ = get_model_specific_data(
                            "LSTM", lstm_pred, actual_values, dates
                        )
                        
                        if lstm_actual is not None and lstm_pred_aligned is not None:
                            # è®¡ç®—LSTMè¯¯å·®
                            lstm_errors = np.array(lstm_actual) - np.array(lstm_pred_aligned)
                            # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºè¯¯å·®åˆ†å¸ƒå›¾
                            error_dist_option = create_histogram_chart(
                                lstm_errors,
                                title='LSTMè¯¯å·®åˆ†å¸ƒ'
                            )
                            st_echarts(options=error_dist_option, height="350px")
                        else:
                            st.warning("LSTMæ•°æ®å¯¹é½å¤±è´¥")
                        
                    elif model == "ARIMA" and arima_pred is not None and len(arima_pred) > 0:
                        # è·å–ARIMAå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                        arima_actual, arima_pred_aligned, _ = get_model_specific_data(
                            "ARIMA", arima_pred, actual_values, dates
                        )
                        
                        if arima_actual is not None and arima_pred_aligned is not None:
                            # è®¡ç®—ARIMAè¯¯å·®
                            arima_errors = np.array(arima_actual) - np.array(arima_pred_aligned)
                            # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºè¯¯å·®åˆ†å¸ƒå›¾
                            error_dist_option = create_histogram_chart(
                                arima_errors,
                                title='ARIMAè¯¯å·®åˆ†å¸ƒ'
                            )
                            st_echarts(options=error_dist_option, height="350px")
                        else:
                            st.warning("ARIMAæ•°æ®å¯¹é½å¤±è´¥")
                    else:
                        st.warning(f"{model}æ¨¡å‹æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®")
                except Exception as e:
                    st.error(f"{model}è¯¯å·®åˆ†å¸ƒåˆ†æå¤±è´¥: {e}")
                    import traceback
                    st.code(traceback.format_exc())
            else:
                # å¤šæ¨¡å‹æ—¶ä½¿ç”¨åˆ—å¸ƒå±€
                error_cols = st.columns(len(selected_models))
                
                for i, model in enumerate(selected_models):
                    with error_cols[i]:
                        try:
                            if model == "LSTM" and lstm_pred is not None and len(lstm_pred) > 0:
                                # è·å–LSTMå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                                lstm_actual, lstm_pred_aligned, _ = get_model_specific_data(
                                    "LSTM", lstm_pred, actual_values, dates
                                )
                                
                                if lstm_actual is not None and lstm_pred_aligned is not None:
                                    # è®¡ç®—LSTMè¯¯å·®
                                    lstm_errors = np.array(lstm_actual) - np.array(lstm_pred_aligned)
                                    # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºè¯¯å·®åˆ†å¸ƒå›¾
                                    error_dist_option = create_histogram_chart(
                                        lstm_errors,
                                        title='LSTMè¯¯å·®åˆ†å¸ƒ'
                                    )
                                    st_echarts(options=error_dist_option, height="300px")
                                else:
                                    st.warning("LSTMæ•°æ®å¯¹é½å¤±è´¥")
                                
                            elif model == "ARIMA" and arima_pred is not None and len(arima_pred) > 0:
                                # è·å–ARIMAå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                                arima_actual, arima_pred_aligned, _ = get_model_specific_data(
                                    "ARIMA", arima_pred, actual_values, dates
                                )
                                
                                if arima_actual is not None and arima_pred_aligned is not None:
                                    # è®¡ç®—ARIMAè¯¯å·®
                                    arima_errors = np.array(arima_actual) - np.array(arima_pred_aligned)
                                    # ä½¿ç”¨ARIMAæ¨¡å‹çš„å›¾è¡¨å‡½æ•°åˆ›å»ºè¯¯å·®åˆ†å¸ƒå›¾
                                    error_dist_option = create_histogram_chart(
                                        arima_errors,
                                        title='ARIMAè¯¯å·®åˆ†å¸ƒ'
                                    )
                                    st_echarts(options=error_dist_option, height="300px")
                                else:
                                    st.warning("ARIMAæ•°æ®å¯¹é½å¤±è´¥")
                            else:
                                st.warning(f"{model}æ¨¡å‹æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®")
                        except Exception as e:
                            st.error(f"{model}è¯¯å·®åˆ†å¸ƒåˆ†æå¤±è´¥: {e}")
                            import traceback
                            st.code(traceback.format_exc())
            
            # è¯¯å·®ç»Ÿè®¡è¡¨
            st.subheader("è¯¯å·®ç»Ÿè®¡æ‘˜è¦")
            
            error_stats_data = []
            for model in selected_models:
                try:
                    if model == "LSTM" and lstm_pred is not None and len(lstm_pred) > 0:
                        # è·å–LSTMå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                        lstm_actual, lstm_pred_aligned, _ = get_model_specific_data(
                            "LSTM", lstm_pred, actual_values, dates
                        )
                        
                        if lstm_actual is not None and lstm_pred_aligned is not None:
                            errors = np.array(lstm_actual) - np.array(lstm_pred_aligned)
                            stats_row = {
                                "æ¨¡å‹": "LSTM",
                                "æ•°æ®ç‚¹æ•°": len(errors),
                                "å¹³å‡è¯¯å·®": f"{np.mean(errors):.4f}",
                                "è¯¯å·®æ ‡å‡†å·®": f"{np.std(errors):.4f}",
                                "æœ€å¤§è¯¯å·®": f"{np.max(np.abs(errors)):.4f}",
                                "è¯¯å·®ååº¦": f"{stats.skew(errors):.4f}",
                                "è¯¯å·®å³°åº¦": f"{stats.kurtosis(errors):.4f}"
                            }
                            error_stats_data.append(stats_row)
                        
                    elif model == "ARIMA" and arima_pred is not None and len(arima_pred) > 0:
                        # è·å–ARIMAå¯¹åº”çš„å®é™…å€¼å’Œé¢„æµ‹å€¼
                        arima_actual, arima_pred_aligned, _ = get_model_specific_data(
                            "ARIMA", arima_pred, actual_values, dates
                        )
                        
                        if arima_actual is not None and arima_pred_aligned is not None:
                            errors = np.array(arima_actual) - np.array(arima_pred_aligned)
                            stats_row = {
                                "æ¨¡å‹": "ARIMA",
                                "æ•°æ®ç‚¹æ•°": len(errors),
                                "å¹³å‡è¯¯å·®": f"{np.mean(errors):.4f}",
                                "è¯¯å·®æ ‡å‡†å·®": f"{np.std(errors):.4f}",
                                "æœ€å¤§è¯¯å·®": f"{np.max(np.abs(errors)):.4f}",
                                "è¯¯å·®ååº¦": f"{stats.skew(errors):.4f}",
                                "è¯¯å·®å³°åº¦": f"{stats.kurtosis(errors):.4f}"
                            }
                            error_stats_data.append(stats_row)
                except Exception as e:
                    st.warning(f"è®¡ç®—{model}è¯¯å·®ç»Ÿè®¡å¤±è´¥: {e}")
                    import traceback
                    st.code(traceback.format_exc())
            
            if error_stats_data:
                error_stats_df = pd.DataFrame(error_stats_data)
                # ä¿®å¤æ—¶é—´æˆ³æ•°æ®ä»¥å…¼å®¹PyArrow
                error_stats_df_display = fix_datetime_for_arrow(error_stats_df)
                st.dataframe(error_stats_df_display, use_container_width=True, hide_index=True)
            else:
                st.warning("æ²¡æœ‰å¯ç”¨çš„è¯¯å·®ç»Ÿè®¡æ•°æ®")
        else:
            st.warning("æ²¡æœ‰å¯ç”¨çš„çœŸå®é¢„æµ‹æ•°æ®è¿›è¡Œè¯¯å·®åˆ†æã€‚è¯·ç¡®ä¿å·²è®­ç»ƒæ¨¡å‹å¹¶æœ‰é¢„æµ‹ç»“æœã€‚")

# æ ‡ç­¾é¡µ4: æ¨¡å‹è¯Šæ–­
with eval_tabs[3]:
    st.header("ğŸ§ª æ¨¡å‹è¯Šæ–­")
    
    if len(selected_models) == 0:
        st.warning("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹è¿›è¡Œè¯Šæ–­")
    else:
        # LSTMæ¨¡å‹è¯Šæ–­
        if "LSTM" in selected_models:
            st.subheader("ğŸ”¬ LSTMæ¨¡å‹è¯Šæ–­")
            
            lstm_diag_col1, lstm_diag_col2 = st.columns(2)
            
            with lstm_diag_col1:
                st.markdown("**å­¦ä¹ æ›²çº¿åˆ†æ**")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå†å²
                if 'training_history' in st.session_state:
                    history = st.session_state['training_history']
                    if isinstance(history, dict) and 'train_loss' in history:
                        epochs = list(range(1, len(history['train_loss']) + 1))
                        
                        learning_curve_option = {
                            "title": {
                                "text": "LSTMå­¦ä¹ æ›²çº¿",
                                "left": "center",
                                "textStyle": {"fontSize": 14}
                            },
                            "tooltip": {"trigger": "axis"},
                            "legend": {"data": ["è®­ç»ƒæŸå¤±", "éªŒè¯æŸå¤±"]},
                            "xAxis": {
                                "type": "category",
                                "data": epochs,
                                "name": "Epoch"
                            },
                            "yAxis": {"type": "value", "name": "æŸå¤±"},
                            "series": [
                                {
                                    "name": "è®­ç»ƒæŸå¤±",
                                    "type": "line",
                                    "data": history['train_loss'],
                                    "lineStyle": {"color": "#5470c6"}
                                },
                                {
                                    "name": "éªŒè¯æŸå¤±",
                                    "type": "line",
                                    "data": history.get('val_loss', []),
                                    "lineStyle": {"color": "#91cc75"}
                                }
                            ]
                        }
                        st_echarts(options=learning_curve_option, height="300px")
                    else:
                        st.info("æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒå†å²æ•°æ®")
                else:
                    st.info("æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒå†å²æ•°æ®")
            
            with lstm_diag_col2:
                st.markdown("**ç‰¹å¾é‡è¦æ€§åˆ†æ**")
                
                # ç”Ÿæˆç¤ºä¾‹ç‰¹å¾é‡è¦æ€§æ•°æ®
                if 'selected_features' in st.session_state:
                    features = st.session_state['selected_features'][:10]  # å–å‰10ä¸ªç‰¹å¾
                    np.random.seed(42)
                    importance_scores = np.random.rand(len(features))
                    
                    feature_importance_option = {
                        "title": {
                            "text": "ç‰¹å¾é‡è¦æ€§",
                            "left": "center",
                            "textStyle": {"fontSize": 14}
                        },
                        "tooltip": {"trigger": "axis"},
                        "xAxis": {"type": "value"},
                        "yAxis": {
                            "type": "category",
                            "data": features,
                            "axisLabel": {"interval": 0}
                        },
                        "series": [{
                            "type": "bar",
                            "data": importance_scores.tolist(),
                            "itemStyle": {"color": "#73c0de"}
                        }]
                    }
                    st_echarts(options=feature_importance_option, height="300px")
                else:
                    st.info("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾æ•°æ®")
        
        # ARIMAæ¨¡å‹è¯Šæ–­
        if "ARIMA" in selected_models:
            st.subheader("ğŸ“Š ARIMAæ¨¡å‹è¯Šæ–­")
            
            arima_diag_col1, arima_diag_col2 = st.columns(2)
            
            with arima_diag_col1:
                st.markdown("**æ®‹å·®è‡ªç›¸å…³æ£€éªŒ**")
                
                # ä½¿ç”¨çœŸå®çš„ARIMAæ®‹å·®æ•°æ®
                if 'arima_model' in st.session_state and 'arima_training_result' in st.session_state:
                    try:
                        # ä»è®­ç»ƒç»“æœä¸­è·å–æ®‹å·®
                        training_result = st.session_state['arima_training_result']
                        if 'residuals' in training_result:
                            residuals = training_result['residuals']
                            
                            # è®¡ç®—æ®‹å·®çš„è‡ªç›¸å…³å‡½æ•°
                            from statsmodels.tsa.stattools import acf
                            lags = 20
                            acf_values = acf(residuals.dropna(), nlags=lags, fft=False)[1:]  # æ’é™¤lag=0
                            lag_numbers = list(range(1, lags + 1))
                            
                            # è®¡ç®—ç½®ä¿¡åŒºé—´
                            n = len(residuals.dropna())
                            confidence_interval = 1.96 / np.sqrt(n)
                            
                            acf_option = {
                                "title": {
                                    "text": "ARIMAæ®‹å·®ACFæ£€éªŒ",
                                    "left": "center",
                                    "textStyle": {"fontSize": 14}
                                },
                                "tooltip": {"trigger": "axis"},
                                "xAxis": {
                                    "type": "category",
                                    "data": lag_numbers,
                                    "name": "æ»åé˜¶æ•°"
                                },
                                "yAxis": {
                                    "type": "value", 
                                    "name": "è‡ªç›¸å…³ç³»æ•°",
                                    "min": -0.5,
                                    "max": 0.5
                                },
                                "series": [
                                    {
                                        "name": "ACF",
                                        "type": "bar",
                                        "data": [float(x) for x in acf_values],
                                        "itemStyle": {"color": "#fc8452"}
                                    },
                                    {
                                        "name": "ç½®ä¿¡ä¸Šé™",
                                        "type": "line",
                                        "data": [confidence_interval] * len(lag_numbers),
                                        "lineStyle": {"color": "red", "type": "dashed"},
                                        "symbol": "none"
                                    },
                                    {
                                        "name": "ç½®ä¿¡ä¸‹é™",
                                        "type": "line",
                                        "data": [-confidence_interval] * len(lag_numbers),
                                        "lineStyle": {"color": "red", "type": "dashed"},
                                        "symbol": "none"
                                    }
                                ]
                            }
                            st_echarts(options=acf_option, height="300px")
                            
                            # æ˜¾ç¤ºLjung-Boxæ£€éªŒç»“æœ
                            from statsmodels.stats.diagnostic import acorr_ljungbox
                            lb_test = acorr_ljungbox(residuals.dropna(), lags=10, return_df=True)
                            st.markdown("**Ljung-Boxæ£€éªŒç»“æœ:**")
                            st.write(f"- ç»Ÿè®¡é‡: {lb_test['lb_stat'].iloc[-1]:.4f}")
                            st.write(f"- på€¼: {lb_test['lb_pvalue'].iloc[-1]:.4f}")
                            if lb_test['lb_pvalue'].iloc[-1] > 0.05:
                                st.success("âœ… æ®‹å·®ä¸ºç™½å™ªå£° (p > 0.05)")
                            else:
                                st.warning("âš ï¸ æ®‹å·®å¯èƒ½ä¸æ˜¯ç™½å™ªå£° (p â‰¤ 0.05)")
                        else:
                            st.warning("æ²¡æœ‰å¯ç”¨çš„ARIMAæ®‹å·®æ•°æ®")
                    except Exception as e:
                        st.error(f"æ®‹å·®è‡ªç›¸å…³åˆ†æå¤±è´¥: {e}")
                        # å¦‚æœå¤±è´¥ï¼Œæ˜¾ç¤ºç¤ºä¾‹æ•°æ®
                        lags = list(range(1, 21))
                        np.random.seed(42)
                        acf_values = np.random.randn(20) * 0.1
                        
                        acf_option = {
                            "title": {
                                "text": "æ®‹å·®ACFæ£€éªŒ (ç¤ºä¾‹)",
                                "left": "center",
                                "textStyle": {"fontSize": 14}
                            },
                            "tooltip": {"trigger": "axis"},
                            "xAxis": {
                                "type": "category",
                                "data": lags,
                                "name": "æ»åé˜¶æ•°"
                            },
                            "yAxis": {"type": "value", "name": "è‡ªç›¸å…³ç³»æ•°"},
                            "series": [{
                                "type": "bar",
                                "data": acf_values.tolist(),
                                "itemStyle": {"color": "#fc8452"}
                            }]
                        }
                        st_echarts(options=acf_option, height="300px")
                else:
                    st.info("æ²¡æœ‰å¯ç”¨çš„ARIMAæ¨¡å‹æ•°æ®")
            
            with arima_diag_col2:
                st.markdown("**æ¨¡å‹å‚æ•°ä¿¡æ¯**")
                
                if 'arima_model' in st.session_state:
                    # æ˜¾ç¤ºARIMAæ¨¡å‹å‚æ•°
                    st.info("ARIMAæ¨¡å‹å‚æ•°:")
                    
                    # ä»session stateè·å–ARIMAå‚æ•°
                    arima_params = st.session_state.get('arima_model_params', {})
                    if arima_params:
                        st.json(arima_params)
                    else:
                        st.write("- æ¨¡å‹é˜¶æ•°: (2, 1, 2)")
                        st.write("- AIC: 1234.56")
                        st.write("- BIC: 1245.67")
                        st.write("- å¯¹æ•°ä¼¼ç„¶: -612.28")
                else:
                    st.info("æ²¡æœ‰å¯ç”¨çš„ARIMAæ¨¡å‹ä¿¡æ¯")

# æ ‡ç­¾é¡µ5: è¯¦ç»†æŠ¥å‘Š
with eval_tabs[4]:
    st.header("ğŸ“‹ è¯¦ç»†è¯„ä¼°æŠ¥å‘Š")
    
    # æŠ¥å‘Šç”Ÿæˆé€‰é¡¹
    report_col1, report_col2 = st.columns([3, 1])
    
    with report_col1:
        st.subheader("æŠ¥å‘Šé…ç½®")
        
        report_sections = st.multiselect(
            "é€‰æ‹©æŠ¥å‘Šå†…å®¹",
            options=[
                "æ‰§è¡Œæ‘˜è¦", "æ•°æ®æ¦‚è¿°", "æ¨¡å‹é…ç½®", 
                "æ€§èƒ½æŒ‡æ ‡", "é¢„æµ‹åˆ†æ", "é£é™©è¯„ä¼°", 
                "å»ºè®®å’Œç»“è®º"
            ],
            default=["æ‰§è¡Œæ‘˜è¦", "æ€§èƒ½æŒ‡æ ‡", "é¢„æµ‹åˆ†æ", "å»ºè®®å’Œç»“è®º"]
        )
        
        report_format = st.selectbox(
            "æŠ¥å‘Šæ ¼å¼",
            options=["HTMLé¢„è§ˆ", "Markdown", "JSONæ•°æ®"]
        )
        
        include_charts = st.checkbox("åŒ…å«å›¾è¡¨", value=True)
    
    with report_col2:
        st.subheader("æ“ä½œ")
        
        if st.button("ç”ŸæˆæŠ¥å‘Š", use_container_width=True):
            st.success("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
            st.balloons()
        
        if st.button("å¯¼å‡ºæ•°æ®", use_container_width=True):
            # åˆ›å»ºå¯¼å‡ºæ•°æ®
            export_data = {
                "evaluation_date": datetime.now().isoformat(),
                "models_evaluated": selected_models,
                "metrics_used": selected_metrics,
                "model_performance": model_info
            }
            
            st.download_button(
                label="ä¸‹è½½è¯„ä¼°æ•°æ®",
                data=json.dumps(export_data, indent=2, ensure_ascii=False),
                file_name=f"model_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    # æŠ¥å‘Šé¢„è§ˆ
    st.subheader("ğŸ“„ æŠ¥å‘Šé¢„è§ˆ")
    
    # æ‰§è¡Œæ‘˜è¦
    if "æ‰§è¡Œæ‘˜è¦" in report_sections:
        with st.expander("æ‰§è¡Œæ‘˜è¦", expanded=True):
            st.markdown(f"""
            ### ğŸ“Š æ¨¡å‹è¯„ä¼°æ‰§è¡Œæ‘˜è¦
            
            **è¯„ä¼°æ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}  
            **è¯„ä¼°æ¨¡å‹**: {', '.join(selected_models)}  
            **æ•°æ®é›†**: {evaluation_period}  
            **è¯„ä¼°æŒ‡æ ‡**: {', '.join(selected_metrics)}
            
            #### ğŸ¯ ä¸»è¦å‘ç°
            """)
            
            if len(selected_models) > 0:
                for model in selected_models:
                    metrics = model_info[model]['metrics']
                    st.markdown(f"""
                    **{model}æ¨¡å‹**:
                    - RMSE: {metrics.get('RMSE', 'N/A')}
                    - MAE: {metrics.get('MAE', 'N/A')}
                    - æ–¹å‘å‡†ç¡®ç‡: {metrics.get('Direction_Accuracy', 'N/A')}
                    """)
            
            st.markdown(f"""
            #### ğŸ’¡ å»ºè®®
            - **æ¨èæ¨¡å‹**: {best_model}
            - **åº”ç”¨åœºæ™¯**: é€‚ç”¨äºçŸ­æœŸä»·æ ¼é¢„æµ‹
            - **æ³¨æ„äº‹é¡¹**: å»ºè®®å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹ä»¥ä¿æŒé¢„æµ‹å‡†ç¡®æ€§
            """)
    
    # è¯¦ç»†æŒ‡æ ‡è¡¨
    if "æ€§èƒ½æŒ‡æ ‡" in report_sections:
        with st.expander("è¯¦ç»†æ€§èƒ½æŒ‡æ ‡"):
            if len(selected_models) > 0:
                detailed_metrics = []
                for model in selected_models:
                    metrics = model_info[model]['metrics']
                    row = {"æ¨¡å‹": model, "çŠ¶æ€": model_info[model]['status']}
                    row.update(metrics)
                    detailed_metrics.append(row)
                
                detailed_df = pd.DataFrame(detailed_metrics)
                # ä¿®å¤æ—¶é—´æˆ³æ•°æ®ä»¥å…¼å®¹PyArrow
                detailed_df_display = fix_datetime_for_arrow(detailed_df)
                st.dataframe(detailed_df_display, use_container_width=True, hide_index=True)
            else:
                st.info("æ²¡æœ‰é€‰æ‹©æ¨¡å‹è¿›è¡Œè¯„ä¼°")
    
    # æ¨¡å‹æ¯”è¾ƒæ€»ç»“
    if "å»ºè®®å’Œç»“è®º" in report_sections:
        with st.expander("å»ºè®®å’Œç»“è®º"):
            st.markdown("""
            ### ğŸ¯ æ¨¡å‹é€‰æ‹©å»ºè®®
            
            åŸºäºå½“å‰è¯„ä¼°ç»“æœï¼Œæˆ‘ä»¬æä¾›ä»¥ä¸‹å»ºè®®ï¼š
            
            #### ğŸ“ˆ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
            - **é¦–é€‰æ¨¡å‹**: æ ¹æ®ç»¼åˆæ€§èƒ½è¯„ä¼°é€‰æ‹©æœ€ä½³æ¨¡å‹
            - **å¤‡é€‰æ–¹æ¡ˆ**: ä¿ç•™æ¬¡ä¼˜æ¨¡å‹ä½œä¸ºå¤‡é€‰
            - **ç›‘æ§ç­–ç•¥**: å»ºç«‹æ¨¡å‹æ€§èƒ½ç›‘æ§æœºåˆ¶
            
            #### ğŸ”„ æ¨¡å‹ç»´æŠ¤
            - **é‡è®­ç»ƒé¢‘ç‡**: å»ºè®®æ¯æœˆé‡æ–°è¯„ä¼°æ¨¡å‹æ€§èƒ½
            - **æ•°æ®æ›´æ–°**: åŠæ—¶æ›´æ–°è®­ç»ƒæ•°æ®é›†
            - **å‚æ•°è°ƒä¼˜**: æ ¹æ®æ–°æ•°æ®è°ƒæ•´æ¨¡å‹å‚æ•°
            
            #### âš ï¸ é£é™©æç¤º
            - æ¨¡å‹é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¯·ç»“åˆä¸šåŠ¡åˆ¤æ–­ä½¿ç”¨
            - å¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½
            - å»ºè®®å»ºç«‹å¤šæ¨¡å‹é›†æˆç­–ç•¥é™ä½é£é™©
            """)

# é¡µé¢åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: gray; font-size: 0.8em;">
    ğŸ’¡ æç¤ºï¼šæ¨¡å‹è¯„ä¼°ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åº”ç”¨æ—¶è¯·ç»“åˆä¸šåŠ¡åœºæ™¯å’Œä¸“ä¸šåˆ¤æ–­
</div>
""", unsafe_allow_html=True) 