"""
æ¨¡å‹è®­ç»ƒé¡µé¢
ç”¨äºé…ç½®å’Œè®­ç»ƒé¢„æµ‹æ¨¡å‹

ä¿®å¤è®°å½•ï¼š
1. ä¿®æ­£äº†LSTMè®­ç»ƒè¿‡ç¨‹ä¸­çš„çŠ¶æ€ç®¡ç†é—®é¢˜ï¼Œç¡®ä¿è®­ç»ƒçŠ¶æ€æ­£ç¡®ä¿å­˜å’Œæ›´æ–°
2. ä¼˜åŒ–äº†æŸå¤±æ›²çº¿ç»˜åˆ¶é€»è¾‘ï¼Œæ”¯æŒå¤šè½®è®­ç»ƒå’Œè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
3. ä¿®å¤äº†æ¨¡å‹ä¿¡æ¯åŒºåŸŸçŠ¶æ€æ›´æ–°é—®é¢˜
4. å¢åŠ äº†è°ƒè¯•ä¿¡æ¯æ˜¾ç¤ºå’Œè®­ç»ƒçŠ¶æ€é‡ç½®åŠŸèƒ½
5. ä¿®å¤æŒ‰é’®ç‚¹å‡»åæ— æ³•æ­£å¸¸å¼€å§‹è®­ç»ƒçš„é—®é¢˜
6. æ·»åŠ äº†å¯¹è®­ç»ƒçŠ¶æ€çš„ç²¾ç¡®æ§åˆ¶å’Œåé¦ˆ
7. å¢å¼ºäº†é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ•è·
8. ä¼˜åŒ–äº†UIå¸ƒå±€å’Œç”¨æˆ·ä½“éªŒ
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import f_regression
from statsmodels.stats.outliers_influence import variance_inflation_factor
from streamlit_echarts import st_echarts
import statsmodels.api as sm
from sklearn.feature_selection import SelectKBest
import seaborn as sns
import os
import json
from datetime import datetime
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = str(Path(__file__).parent.parent.parent)
if project_root not in sys.path:
    sys.path.append(project_root)

# æ·»åŠ arimaå‡½æ•°
from web.utils.arima_utils import (
    check_stationarity,
    diff_series,
    check_white_noise,
    analyze_acf_pacf,
    find_best_arima_params,
    fit_arima_model,
    check_residuals,
    forecast_arima,
    evaluate_arima_model,
    inverse_diff,
    generate_descriptive_statistics
)

from web.utils.session import get_state, set_state, update_states

# ä¿®å¤PyTorchä¸Streamlitçš„å…¼å®¹æ€§é—®é¢˜
torch.classes.__path__ = []

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨¡å‹è®­ç»ƒ",
    page_icon="ğŸ§ ",
    layout="wide"
)

# æ ‡é¢˜å’Œç®€ä»‹
st.title("æ¨¡å‹è®­ç»ƒ")
st.markdown("æœ¬é¡µé¢ç”¨äºé…ç½®å’Œè®­ç»ƒæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ã€‚é€‰æ‹©åˆé€‚çš„å‚æ•°å¹¶å¼€å§‹è®­ç»ƒè¿‡ç¨‹ã€‚")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
if 'training_complete' not in st.session_state:
    st.session_state['training_complete'] = False

if 'model_metrics' not in st.session_state:
    st.session_state['model_metrics'] = None

if 'start_training' not in st.session_state:
    st.session_state['start_training'] = False

# åˆ›å»ºä¾§è¾¹æ ç”¨äºè°ƒè¯•å’Œé‡ç½®åŠŸèƒ½
with st.sidebar:
    st.header("è°ƒè¯•ä¸æ§åˆ¶é¢æ¿")
    
    # æ˜¾ç¤ºå½“å‰è®­ç»ƒçŠ¶æ€
    st.write("å½“å‰çŠ¶æ€:")
    st.json({
        "è®­ç»ƒçŠ¶æ€": "å·²å®Œæˆ" if st.session_state.get('training_complete', False) else "æœªå®Œæˆ",
        "è®­ç»ƒè¿›è¡Œä¸­": "æ˜¯" if st.session_state.get('start_training', False) else "å¦",
        "æŠ€æœ¯æŒ‡æ ‡æ•°æ®": "å·²åŠ è½½" if 'tech_indicators' in st.session_state and st.session_state['tech_indicators'] is not None else "æœªåŠ è½½",
        "ç‰¹å¾å·²é€‰æ‹©": "æ˜¯" if 'selected_features' in st.session_state and st.session_state['selected_features'] else "å¦"
    })
    
    # æ·»åŠ é‡ç½®æŒ‰é’®
    if st.button("é‡ç½®æ‰€æœ‰è®­ç»ƒçŠ¶æ€", key="reset_all"):
        st.session_state['start_training'] = False
        st.session_state['training_complete'] = False
        if 'trained_model' in st.session_state:
            del st.session_state['trained_model']
        if 'model_metrics' in st.session_state:
            st.session_state['model_metrics'] = None
        st.success("å·²é‡ç½®æ‰€æœ‰è®­ç»ƒçŠ¶æ€ï¼")
        st.rerun()

# æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºæ–°åŠ è½½çš„æ•°æ®
if 'raw_data' in st.session_state:
    # æ£€æŸ¥ä¹‹å‰çš„æ•°æ®åŠ è½½æ—¶é—´æˆ³æ˜¯å¦å­˜åœ¨
    if 'data_load_timestamp' not in st.session_state:
        # é¦–æ¬¡åŠ è½½æ•°æ®ï¼Œè®°å½•æ—¶é—´æˆ³å¹¶é‡ç½®è®­ç»ƒçŠ¶æ€
        st.session_state['data_load_timestamp'] = datetime.now()
        st.session_state['training_complete'] = False
        st.session_state['start_training'] = False
    else:
        # å¦‚æœæœ‰æ–°çš„åŸå§‹æ•°æ®åŠ è½½ï¼Œé‡ç½®è®­ç»ƒçŠ¶æ€
        if 'last_trained_data_timestamp' not in st.session_state or st.session_state.get('data_load_timestamp') != st.session_state.get('last_trained_data_timestamp'):
            st.session_state['training_complete'] = False
            st.session_state['start_training'] = False

# è·å–åŠ è½½çš„æ•°æ®
if 'raw_data' not in st.session_state:
    st.warning("è¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æ•°æ®")
    st.stop()

df = st.session_state['raw_data']
if df is None:
    st.warning("æ•°æ®ä¸ºç©ºï¼Œè¯·åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æœ‰æ•ˆæ•°æ®")
    st.stop()

# ç‰¹å¾é€‰æ‹©å‡½æ•°
def select_features(df, target_col='Close', correlation_threshold=0.5, vif_threshold=10, p_value_threshold=0.05):
    """
    åŸºäºç›¸å…³æ€§ã€å¤šé‡å…±çº¿æ€§å’Œç»Ÿè®¡æ˜¾è‘—æ€§è¿›è¡Œç‰¹å¾é€‰æ‹©
    
    å‚æ•°:
    df: åŒ…å«ç‰¹å¾çš„DataFrame
    target_col: ç›®æ ‡å˜é‡åˆ—åï¼Œé»˜è®¤ä¸º'Close'(æ”¶ç›˜ä»·)
    correlation_threshold: ç›¸å…³æ€§é˜ˆå€¼ï¼Œé»˜è®¤ä¸º0.5
    vif_threshold: VIFé˜ˆå€¼ï¼Œé»˜è®¤ä¸º10
    p_value_threshold: på€¼é˜ˆå€¼ï¼Œé»˜è®¤ä¸º0.05
    
    è¿”å›:
    selected_features: é€‰æ‹©çš„ç‰¹å¾åˆ—è¡¨
    """
    try:
        # ç¡®ä¿ç›®æ ‡å˜é‡å­˜åœ¨äºæ•°æ®é›†ä¸­
        if target_col not in df.columns:
            st.warning(f"ç›®æ ‡å˜é‡ '{target_col}' ä¸åœ¨æ•°æ®é›†ä¸­ã€‚å°†ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºç›®æ ‡å˜é‡ã€‚")
            target_col = df.columns[0]
            
        # ä½¿ç”¨æ•°å€¼å‹åˆ—è¿›è¡Œåˆ†æ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if target_col not in numeric_cols:
            st.warning(f"ç›®æ ‡å˜é‡ '{target_col}' ä¸æ˜¯æ•°å€¼ç±»å‹ã€‚ç‰¹å¾é€‰æ‹©å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚")
        
        selected_features = []
        
        # æ­¥éª¤1: åŸºäºç›¸å…³æ€§çš„ç‰¹å¾é€‰æ‹©
        # è®¡ç®—ä¸ç›®æ ‡å˜é‡(Close)çš„ç›¸å…³æ€§
        correlation_matrix = df[numeric_cols].corr(numeric_only=True)
        target_correlations = correlation_matrix[target_col].sort_values(ascending=False)
        
        # æ˜¾ç¤ºç›¸å…³æ€§æ’å
        with st.expander("**ç›¸å…³æ€§ç­›é€‰**", expanded=False):
            corr_df = pd.DataFrame({
                'ç‰¹å¾': target_correlations.index,
                'ç›¸å…³æ€§': target_correlations.values
            })
            st.dataframe(corr_df)
                # é€‰æ‹©ç›¸å…³æ€§é«˜äºé˜ˆå€¼çš„ç‰¹å¾
            high_correlation_features = target_correlations[target_correlations > correlation_threshold].index.tolist()
            st.write(f"ç›¸å…³æ€§é«˜äº{correlation_threshold}çš„ç‰¹å¾: {high_correlation_features}")
        
        # æ­¥éª¤2: å¤šé‡å…±çº¿æ€§åˆ†æ - è®¡ç®—VIF (Variance Inflation Factor)
        # åˆ›å»ºä¸€ä¸ªæ²¡æœ‰ç›®æ ‡å˜é‡çš„ç‰¹å¾å­é›†
        with st.expander("**VIFç­›é€‰**", expanded=False):
            if len(high_correlation_features) > 1:  # ç¡®ä¿è‡³å°‘æœ‰ä¸¤ä¸ªç‰¹å¾
                X = df[high_correlation_features].copy()
                # ä»VIFè®¡ç®—ä¸­ç§»é™¤ç›®æ ‡å˜é‡
                if target_col in X.columns:
                    X = X.drop(target_col, axis=1)
                    
                if not X.empty and X.shape[1] > 0:
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²çŸ¥çš„é«˜åº¦ç›¸å…³ç‰¹å¾
                    # å¸ƒæ—å¸¦çš„Upper_Bandå’ŒLower_BandåŸºäºMA20è®¡ç®—ï¼Œå®ƒä»¬æœ‰å®Œå…¨å…±çº¿æ€§
                    if 'MA20' in X.columns and 'Upper_Band' in X.columns and 'Lower_Band' in X.columns:
                        st.warning("æ£€æµ‹åˆ°å¸ƒæ—å¸¦æŒ‡æ ‡ï¼ˆUpper_Bandã€Lower_Bandï¼‰ä¸MA20å­˜åœ¨å®Œå…¨å…±çº¿æ€§å…³ç³»ã€‚å¯¹è¿™äº›ç‰¹å¾å•ç‹¬å¤„ç†ï¼Œä»¥é¿å…VIFè®¡ç®—é—®é¢˜")
                        X = X.drop(['Upper_Band', 'Lower_Band'], axis=1, errors='ignore')
                    
                    # æ·»åŠ å¸¸æ•°é¡¹
                    X_with_const = sm.add_constant(X)
                    
                    # è®¡ç®—VIFï¼Œæ·»åŠ é”™è¯¯å¤„ç†
                    vif_data = pd.DataFrame()
                    vif_data["Feature"] = X_with_const.columns
                    vif_values = []
                    
                    for i in range(X_with_const.shape[1]):
                        try:
                            vif_value = variance_inflation_factor(X_with_const.values, i)
                            if not np.isfinite(vif_value):
                                vif_value = float('inf')  # å¤„ç†æ— ç©·å¤§å€¼
                                st.warning(f"ç‰¹å¾ '{X_with_const.columns[i]}' çš„VIFå€¼ä¸ºæ— ç©·å¤§ï¼Œè¡¨ç¤ºå­˜åœ¨å®Œå…¨å…±çº¿æ€§")
                        except Exception as e:
                            st.warning(f"è®¡ç®—ç‰¹å¾ '{X_with_const.columns[i]}' çš„VIFå€¼æ—¶å‡ºé”™: {str(e)}")
                            vif_value = float('inf')  # å‡ºé”™æ—¶è®¾ä¸ºæ— ç©·å¤§
                        
                        vif_values.append(vif_value)
                    
                    vif_data["VIF"] = vif_values
                    vif_data = vif_data.sort_values("VIF", ascending=False)
                    
                    st.write("**VIF > 10è¡¨ç¤ºå­˜åœ¨ä¸¥é‡çš„å¤šé‡å…±çº¿æ€§:**")
                    st.dataframe(vif_data)
                    
                    # ç§»é™¤VIFè¿‡é«˜çš„ç‰¹å¾(é€šå¸¸VIF>10è¡¨ç¤ºä¸¥é‡çš„å¤šé‡å…±çº¿æ€§)
                    high_vif_features = vif_data[vif_data["VIF"] > vif_threshold]["Feature"].tolist()
                    if 'const' in high_vif_features:
                        high_vif_features.remove('const')  # ç§»é™¤å¸¸æ•°é¡¹
                    
                    st.write(f"å¤šé‡å…±çº¿æ€§ä¸¥é‡çš„ç‰¹å¾ (VIF > {vif_threshold}): {high_vif_features}")
                else:
                    high_vif_features = []
                    st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡ŒVIFè®¡ç®—")
            else:
                high_vif_features = []
                st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç›¸å…³ç‰¹å¾è¿›è¡Œå¤šé‡å…±çº¿æ€§åˆ†æ")
        
        # æ­¥éª¤3: åŸºäºç»Ÿè®¡æ˜¾è‘—æ€§çš„ç‰¹å¾é€‰æ‹©
        # ä½¿ç”¨f_regressionè¯„ä¼°ç‰¹å¾çš„ç»Ÿè®¡æ˜¾è‘—æ€§
        with st.expander("**ç»Ÿè®¡æ˜¾è‘—æ€§ç­›é€‰**", expanded=False):
            features_to_test = [f for f in high_correlation_features if f != target_col]
            if features_to_test:
                X = df[features_to_test].values
                y = df[target_col].values
                
                f_selector = SelectKBest(f_regression, k='all')
                f_selector.fit(X, y)
                
                # è·å–æ¯ä¸ªç‰¹å¾çš„på€¼å’ŒFå€¼
                f_scores = pd.DataFrame()
                f_scores["Feature"] = features_to_test
                f_scores["F Score"] = f_selector.scores_
                f_scores["P Value"] = f_selector.pvalues_
                f_scores = f_scores.sort_values("F Score", ascending=False)
                
                st.write("**ç‰¹å¾çš„Fæ£€éªŒç»“æœ:**")
                st.dataframe(f_scores)
                
                # é€‰æ‹©ç»Ÿè®¡æ˜¾è‘—çš„ç‰¹å¾(på€¼<0.05)
                significant_features = f_scores[f_scores["P Value"] < p_value_threshold]["Feature"].tolist()
                st.write(f"ç»Ÿè®¡æ˜¾è‘—çš„ç‰¹å¾ (P < {p_value_threshold}): {significant_features}")
            else:
                significant_features = []
                st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•")
        
        # 4. ç»¼åˆä»¥ä¸Šåˆ†æï¼Œé€‰æ‹©æœ€ç»ˆçš„ç‰¹å¾é›†
        # ä»é«˜ç›¸å…³æ€§ç‰¹å¾ä¸­ç§»é™¤å¤šé‡å…±çº¿æ€§ä¸¥é‡çš„ç‰¹å¾
        selected_features = [f for f in high_correlation_features if f not in high_vif_features]
        
        # ç¡®ä¿æ‰€æœ‰ç»Ÿè®¡æ˜¾è‘—çš„ç‰¹å¾éƒ½è¢«åŒ…å«
        for feature in significant_features:
            if feature not in selected_features and feature != target_col:
                selected_features.append(feature)
                
        # ç¡®ä¿ç›®æ ‡å˜é‡åœ¨ç‰¹å¾é›†ä¸­
        if target_col not in selected_features:
            selected_features.append(target_col)
        
        return selected_features
    
    except Exception as e:
        st.error(f"ç‰¹å¾é€‰æ‹©è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        if target_col in df.columns:
            return [target_col] + [col for col in df.columns if col != target_col][:5]  # è¿”å›ç›®æ ‡å˜é‡å’Œå…¶ä»–5ä¸ªç‰¹å¾ä½œä¸ºå›é€€
        else:
            return df.columns.tolist()[:6]  # è¿”å›å‰6ä¸ªç‰¹å¾ä½œä¸ºå›é€€

# åˆ›å»ºä¸‰æ å¸ƒå±€
left_column, middle_column = st.columns([1, 2])

# ä¸­é—´æ  - æ¨¡å‹å‚æ•°è®¾ç½®ä¸è®­ç»ƒæ§åˆ¶
with middle_column:
    st.subheader("æ¨¡å‹å‚æ•°é…ç½®")
    
    # æ¨¡å‹ç±»å‹é€‰æ‹©æ ‡ç­¾é¡µ
    model_tabs = st.tabs(["LSTM", "ARIMA", "Prophet"])
    
    # LSTMå‚æ•°è®¾ç½®
    with model_tabs[0]:
        st.markdown("### LSTMæ¨¡å‹")
        
        # ç‰¹å¾é€‰æ‹©éƒ¨åˆ† - ç§»åŠ¨åˆ°LSTMæ ‡ç­¾é¡µå†…
        st.markdown("### ç‰¹å¾é€‰æ‹©")
        if 'raw_data' in st.session_state and 'tech_indicators' in st.session_state:
            df = st.session_state['tech_indicators']  # ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®è€Œä¸æ˜¯åŸå§‹æ•°æ®
            
            # ç¡®ä¿ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®ä¸­å®é™…å­˜åœ¨çš„åˆ—ä½œä¸ºç‰¹å¾åˆ—è¡¨
            all_features = df.columns.tolist()
                       
            # åˆå§‹åŒ–selected_featuresçš„session state
            if 'selected_features' not in st.session_state:
                st.session_state['selected_features'] = all_features
            
            # ç‰¹å¾é€‰æ‹©å¤šé€‰æ¡†ï¼Œä½¿ç”¨session stateä¸­çš„ç‰¹å¾ä½œä¸ºé»˜è®¤å€¼
            selected_features = st.multiselect(
                "é€‰æ‹©ç”¨äºè®­ç»ƒçš„ç‰¹å¾",
                options=all_features,
                default=st.session_state['selected_features']
            )
            
            # æ›´æ–°selected_featuresçš„session state
            st.session_state['selected_features'] = selected_features
        
        # ç‰¹å¾ç­›é€‰å‚æ•°
        col1, col2, col3 = st.columns(3)
        with col1:
            correlation_threshold = st.slider(
                "ç›¸å…³æ€§é˜ˆå€¼",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.05,
                help="ä¸ç›®æ ‡å˜é‡çš„æœ€å°ç›¸å…³ç³»æ•°"
            )
        with col2:
            vif_threshold = st.slider(
                "VIFé˜ˆå€¼",
                min_value=1.0,
                max_value=20.0,
                value=10.0,
                step=0.5,
                help="æ–¹å·®è†¨èƒ€å› å­çš„æœ€å¤§å…è®¸å€¼"
            )
        with col3:
            p_value_threshold = st.slider(
                "På€¼é˜ˆå€¼",
                min_value=0.0,
                max_value=0.1,
                value=0.05,
                step=0.01,
                help="ç»Ÿè®¡æ˜¾è‘—æ€§çš„æœ€å¤§å…è®¸på€¼"
            )

        # æ·»åŠ ç‰¹å¾ç­›é€‰æŒ‰é’®
        if st.button("ç­›é€‰ç‰¹å¾"):
            with st.spinner("æ­£åœ¨ç­›é€‰ç‰¹å¾..."):
                # åˆ›å»ºç»“æœå®¹å™¨
                filter_result = st.container()
                
                with filter_result:
                    filtered_features = select_features(
                        df,
                        correlation_threshold=correlation_threshold,
                        vif_threshold=vif_threshold,
                        p_value_threshold=p_value_threshold
                    )
                    
                    # æ›´æ–°session stateä¸­çš„ç­›é€‰ç‰¹å¾
                    if filtered_features and len(filtered_features) > 0:
                        st.session_state['filtered_features'] = filtered_features
                        # åŒæ—¶æ›´æ–°é€‰æ‹©çš„ç‰¹å¾ï¼Œä½¿ç•Œé¢ä¸Šçš„å¤šé€‰æ¡†ä¹Ÿæ›´æ–°
                        st.session_state['selected_features'] = filtered_features
                        st.success(f"ç‰¹å¾ç­›é€‰å®Œæˆï¼Œä» {df.shape[1]} ä¸ªç‰¹å¾ä¸­é€‰å‡º {len(filtered_features)} ä¸ªç‰¹å¾: {filtered_features}")
                    else:
                        st.error("ç‰¹å¾ç­›é€‰å¤±è´¥ï¼Œå°†ä½¿ç”¨æ‰€æœ‰ç‰¹å¾")
                        st.session_state['filtered_features'] = all_features
                        st.session_state['selected_features'] = all_features
                        
                # ç¡®ä¿ä¸ä¼šå› ç­›é€‰ç‰¹å¾è€Œè¯¯è®¤ä¸ºè®­ç»ƒå·²å®Œæˆ
                if 'training_complete' in st.session_state:
                    st.session_state['training_complete'] = False
                    
                # # åˆ·æ–°é¡µé¢ä»¥æ›´æ–°å¤šé€‰æ¡†çš„æ˜¾ç¤º
                # st.rerun()
        
        # æ˜¾ç¤ºç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
        if st.checkbox("æ˜¾ç¤ºç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼ˆè‹¥ä¸æ˜¾ç¤ºï¼Œå¯é‡æ–°ç‚¹å‡»å¤é€‰æ¡†åˆ·æ–°ï¼‰"):
            # ç¡®ä¿é€‰æ‹©çš„ç‰¹å¾ä¸ä¸ºç©º
            if not selected_features:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ä»¥æ˜¾ç¤ºç›¸å…³æ€§çƒ­åŠ›å›¾")
            else:
                # åªä½¿ç”¨å·²é€‰æ‹©çš„ç‰¹å¾ï¼ˆselected_featuresï¼‰è®¡ç®—ç›¸å…³æ€§
                # ç¡®ä¿æ‰€æœ‰é€‰å®šçš„ç‰¹å¾éƒ½æ˜¯æ•°å€¼ç±»å‹
                numeric_selected_features = [f for f in selected_features if np.issubdtype(df[f].dtype, np.number)]
                
                if len(numeric_selected_features) < 2:
                    st.warning("éœ€è¦è‡³å°‘ä¸¤ä¸ªæ•°å€¼ç±»å‹çš„ç‰¹å¾æ¥ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾")
                else:
                    # åŸºäºå·²é€‰æ‹©çš„æ•°å€¼ç‰¹å¾è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
                    selected_corr_matrix = df[numeric_selected_features].corr(numeric_only=True).round(2)
                    
                    # è®¡ç®—å·²é€‰æ‹©ç‰¹å¾çš„ç›¸å…³æ€§çŸ©é˜µçš„æœ€å°å€¼å’Œæœ€å¤§å€¼
                    corr_min = selected_corr_matrix.min().min()
                    corr_max = selected_corr_matrix.max().max()
                    
                    # æ ¹æ®ä¸Closeçš„ç›¸å…³æ€§æ’åºç‰¹å¾ï¼ˆå¦‚æœCloseåœ¨å·²é€‰æ‹©çš„ç‰¹å¾ä¸­ï¼‰
                    if 'Close' in numeric_selected_features:
                        close_correlations = selected_corr_matrix['Close']  # ä¸ä½¿ç”¨abs()ï¼Œä¿ç•™æ­£è´Ÿå·
                        sorted_features = close_correlations.sort_values(ascending=False).index  # ä»é«˜åˆ°ä½æ’åº
                        selected_corr_matrix = selected_corr_matrix.loc[sorted_features, sorted_features]
                    
                    # è·å–ç‰¹å¾åç§°å’Œç›¸å…³æ€§æ•°æ®
                    sorted_selected_features = list(selected_corr_matrix.columns)
                    corr_data = []
                    
                    # æ„å»ºçƒ­åŠ›å›¾æ•°æ®
                    for i in range(len(sorted_selected_features)):
                        for j in range(len(sorted_selected_features)):
                            corr_data.append([i, j, round(float(selected_corr_matrix.iloc[i, j]), 2)])
                    
                    # é…ç½®echartsé€‰é¡¹
                    options = {
                        "tooltip": {
                            "position": "top",
                            },
                        "grid": {
                            "height": "80%",
                            "top": "0%",
                            "left": "150px"
                        },
                        "xAxis": {
                            "type": "category",
                            "data": sorted_selected_features,
                            "splitArea": {
                                "show": True
                            },
                            "axisLabel": {
                                "rotate": 45,
                                "interval": 0
                            }
                        },
                        "yAxis": {
                            "type": "category",
                            "data": sorted_selected_features,
                            "splitArea": {
                                "show": True
                            }
                        },
                        "visualMap": {
                            "min": float(corr_min),
                            "max": float(corr_max),
                            "calculable": True,
                            "orient": "vertical",
                            "left": "0",
                            "top": "middle",
                            "inRange": {
                                "color": ["#313695", "#FFFFFF", "#A50026"]
                            },
                            "formatter": "{value}"  # ç¡®ä¿æ˜¾ç¤ºæ­£ç¡®çš„å€¼
                        },
                        "series": [{
                            "name": "ç›¸å…³æ€§ç³»æ•°",
                            "type": "heatmap",
                            "data": corr_data,
                            "label": {
                                "show": True,     # æ˜¾ç¤ºæ•°å€¼æ ‡ç­¾
                                "formatter": {    # æ ¼å¼åŒ–æ ‡ç­¾ï¼Œä¿ç•™ä¸¤ä½å°æ•°
                                    "type": "function",
                                    "function": "function(params) { return params.data[2].toFixed(2); }"
                                }
                            },
                            "emphasis": {
                                "itemStyle": {
                                    "shadowBlur": 10,
                                    "shadowColor": "rgba(0, 0, 0, 0.5)"
                                }
                            }
                        }]
                    }
                    
                    # ä½¿ç”¨streamlit_echartsæ˜¾ç¤ºçƒ­åŠ›å›¾
                    st.markdown("#### ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾")
                    st_echarts(options=options, height="400px")
        
        # LSTMæ¨¡å‹å‚æ•°è®¾ç½®
        st.markdown("### LSTMæ¨¡å‹å‚æ•°")
        
        col1, col2 = st.columns(2)
        with col1:
            hidden_size = st.number_input(
                "éšè—å±‚å¤§å°",
                min_value=1,
                max_value=512,
                value=32
            )
            
            num_layers = st.number_input(
                "LSTMå±‚æ•°",
                min_value=1,
                max_value=5,
                value=1
            )
            
            dropout = st.slider(
                "Dropoutæ¯”ä¾‹",
                min_value=0.0,
                max_value=0.9,
                value=0.3,
                step=0.1
            )
        
        with col2:
            learning_rate = st.number_input(
                "å­¦ä¹ ç‡",
                min_value=0.0001,
                max_value=0.1,
                value=0.01,
                format="%.4f"
            )
            
            batch_size = st.number_input(
                "æ‰¹æ¬¡å¤§å°",
                min_value=1,
                max_value=1024,
                value=512
            )
            
            epochs = st.number_input(
                "è®­ç»ƒè½®æ•°",
                min_value=1,
                max_value=1000,
                value=100
            )
        
        # ä¿å­˜LSTMè¶…å‚æ•°åˆ°ä¼šè¯çŠ¶æ€
        st.session_state['hidden_size'] = hidden_size
        st.session_state['num_layers'] = num_layers
        st.session_state['dropout'] = dropout
        st.session_state['learning_rate'] = learning_rate
        st.session_state['batch_size'] = batch_size
        st.session_state['epochs'] = epochs
        
        # è®­ç»ƒæ§åˆ¶
        st.markdown("### LSTMæ¨¡å‹è®­ç»ƒæ§åˆ¶")
        
        train_col1, train_col2 = st.columns([3, 1])
        with train_col1:
            # ç®€åŒ–æŒ‰é’®é€»è¾‘ï¼Œé‡‡ç”¨æ›´ç›´æ¥çš„å®ç°
            start_button = st.button(
                "å¼€å§‹è®­ç»ƒLSTMæ¨¡å‹",
                use_container_width=True,
                key="lstm_train_button"
            )
            
        with train_col2:
            enable_early_stopping = st.checkbox(
                "å¯ç”¨æ—©åœ",
                value=True
            )
        
        # è®­ç»ƒè¿›åº¦å’ŒæŸå¤±å¯è§†åŒ–çš„å ä½åŒºåŸŸ
        progress_placeholder = st.empty()
        loss_chart_placeholder = st.empty()
        
        # å¦‚æœä¼šè¯ä¸­å·²æœ‰è®­ç»ƒå†å²ä½†ç•Œé¢åˆšåˆšåŠ è½½ï¼Œæ˜¾ç¤ºä¹‹å‰çš„è®­ç»ƒå†å²
        if ('training_history' in st.session_state 
            and 'training_complete' in st.session_state 
            and st.session_state['training_complete'] 
            and not st.session_state.get('start_training', False)):
            
            st.success("æ£€æµ‹åˆ°å·²è®­ç»ƒå®Œæˆçš„æ¨¡å‹")
            
            history = st.session_state['training_history']
            if history and 'train_loss' in history and 'val_loss' in history and len(history['train_loss']) > 0:
                with loss_chart_placeholder:
                    # ç»˜åˆ¶å·²æœ‰çš„æŸå¤±æ›²çº¿
                    history_df = pd.DataFrame({
                        'è®­ç»ƒæŸå¤±': history['train_loss'],
                        'éªŒè¯æŸå¤±': history['val_loss']
                    })
                    st.line_chart(history_df)
                    st.info(f"ä¸Šæ¬¡è®­ç»ƒå®Œæˆï¼Œå…±è®­ç»ƒ {len(history['train_loss'])} è½®ï¼Œ"
                           f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {history['train_loss'][-1]:.6f}ï¼Œ"
                           f"éªŒè¯æŸå¤±: {history['val_loss'][-1]:.6f}")
                    
                    # æ·»åŠ æ˜¾ç¤ºæ¨¡å‹å‚æ•°ä¿¡æ¯
                    if 'model_params' in st.session_state:
                        model_params = st.session_state['model_params']
                        st.write("**æ¨¡å‹å‚æ•°:**")
                        st.json(model_params)
                    
                    # æ·»åŠ æ˜¾ç¤ºè®­ç»ƒå‚æ•°ä¿¡æ¯
                    if 'training_params' in st.session_state:
                        training_params = st.session_state['training_params']
                        st.write("**è®­ç»ƒå‚æ•°:**")
                        st.json(training_params)
                        
                    # æ·»åŠ ä¸‹è½½æ¨¡å‹æŒ‰é’®
                    if 'trained_model' in st.session_state:
                        st.download_button(
                            label="ä¸‹è½½æ¨¡å‹å‚æ•°JSON",
                            data=json.dumps({
                                'model_params': st.session_state['model_params'],
                                'training_params': st.session_state['training_params'],
                                'model_metrics': st.session_state.get('model_metrics', {})
                            }, ensure_ascii=False, indent=2),
                            file_name="model_params.json",
                            mime="application/json"
                        )
        
        # å¦‚æœç‚¹å‡»äº†å¼€å§‹è®­ç»ƒæŒ‰é’®ï¼Œæ›´æ–°ä¼šè¯çŠ¶æ€
        if start_button:
            # ä¿å­˜å½“å‰çš„ç‰¹å¾é€‰æ‹©
            st.session_state['selected_features'] = selected_features
            # è®¾ç½®å¼€å§‹è®­ç»ƒæ ‡å¿—
            st.session_state['start_training'] = True
            # é‡ç½®è®­ç»ƒå®ŒæˆçŠ¶æ€
            st.session_state['training_complete'] = False
            # é‡æ–°è¿è¡Œè„šæœ¬ä»¥åº”ç”¨æ–°çŠ¶æ€
            st.rerun()
    
    # ARIMAå‚æ•°è®¾ç½®
    with model_tabs[1]:
        st.markdown("### ARIMAæ¨¡å‹å‚æ•°ä¸åˆ†æ")

        # åˆ›å»ºARIMAå­é€‰é¡¹å¡
        arima_tabs = st.tabs(["æ•°æ®æ£€éªŒ", "æ¨¡å‹å»ºç«‹", "æ¨¡å‹é¢„æµ‹å¯¹æ¯”"])
        
        # æ•°æ®æ£€éªŒé€‰é¡¹å¡
        with arima_tabs[0]:
            # ç¡®ä¿ç›®æ ‡å˜é‡é€‰æ‹©æ­£ç¡®
            if 'Close' not in df.columns:
                st.warning("æ•°æ®ä¸­æ²¡æœ‰'Close'åˆ—ï¼Œå°†ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºç›®æ ‡å˜é‡")
                target_col = df.columns[0]
            else:
                target_col = 'Close'
            
            # è·å–ç›®æ ‡æ—¶é—´åºåˆ—
            target_series = df[target_col].copy()
            target_series.name = target_col
            
            # è½¬æ¢ä¸ºæ—¶é—´åºåˆ—
            if not isinstance(target_series.index, pd.DatetimeIndex):
                if 'Date' in df.columns:
                    target_series.index = pd.to_datetime(df['Date'])
                else:
                    target_series.index = pd.date_range(
                        start='2000-01-01', 
                        periods=len(target_series), 
                        freq='D'
                    )
            
            # 0. ç»Ÿè®¡ç‰¹å¾åˆ†æ
            st.subheader("ç»Ÿè®¡ç‰¹å¾åˆ†æ")
            stats_df, normality_test = generate_descriptive_statistics(target_series)
            
            # æ˜¾ç¤ºç»Ÿè®¡ç‰¹å¾è¡¨
            st.write("æè¿°æ€§ç»Ÿè®¡è¡¨:")
            st.dataframe(stats_df, hide_index=True)
            
            # æ˜¾ç¤ºæ­£æ€æ€§æ£€éªŒç»“æœ
            st.write("Jarque-Beraæ­£æ€æ€§æ£€éªŒ:")
            st.write(f"ç»Ÿè®¡é‡: {normality_test['statistic']:.4f}")
            st.write(f"på€¼: {normality_test['p_value']:.4f}")
            st.write(f"æ•°æ®æ˜¯å¦æœä»æ­£æ€åˆ†å¸ƒ: {'æ˜¯' if normality_test['is_normal'] else 'å¦'}")
            
            # 1. å¹³ç¨³æ€§æ£€éªŒ
            st.subheader("å¹³ç¨³æ€§æ£€éªŒ")
            stationarity_results, is_stationary, stationarity_df = check_stationarity(target_series)
            
            # æ˜¾ç¤ºå¹³ç¨³æ€§æ£€éªŒç»“æœ
            col1, col2 = st.columns(2)
            with col1:
                st.write("**ADFç»Ÿè®¡é‡:**", round(stationarity_results['ADFç»Ÿè®¡é‡'], 4))
                st.write("**på€¼:**", round(stationarity_results['på€¼'], 4))
                st.write("**æ˜¯å¦å¹³ç¨³:**", "æ˜¯" if is_stationary else "å¦")
            
            with col2:
                st.write("**ä¸´ç•Œå€¼:**")
                for key, value in stationarity_results['ä¸´ç•Œå€¼'].items():
                    st.write(f"  {key}: {round(value, 4)}")
            
            # æ˜¾ç¤ºå¹³ç¨³æ€§å›¾è¡¨ - ä½¿ç”¨EChartsä»£æ›¿åŸç”ŸæŠ˜çº¿å›¾
            try:
                # ç¡®ä¿ç´¢å¼•å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if isinstance(stationarity_df.index, pd.DatetimeIndex):
                    dates = stationarity_df.index.strftime('%Y-%m-%d').tolist()
                else:
                    dates = stationarity_df.index.astype(str).tolist()
                
                # ç¡®ä¿æ•°æ®å¯ä»¥è½¬æ¢ä¸ºåˆ—è¡¨
                values = stationarity_df['åŸå§‹æ•°æ®'].fillna(method='ffill').tolist()
                
                # é…ç½®echartsé€‰é¡¹
                options = {
                    "title": {
                        "text": "åŸå§‹æ—¶é—´åºåˆ—æ•°æ®",
                        "textStyle": {
                            "fontSize": 16
                        }
                    },
                    "tooltip": {
                        "trigger": "axis"
                    },
                    "grid": {
                        "left": "5%",
                        "right": "5%",
                        "bottom": "10%",
                        "containLabel": True
                    },
                    "xAxis": {
                        "type": "category",
                        "boundaryGap": False,
                        "data": dates,
                        "axisLabel": {
                            "rotate": 45,
                            "interval": max(1, int(len(dates)/20))  # ç¡®ä¿è‡³å°‘æ˜¾ç¤ºä¸€äº›æ ‡ç­¾
                        }
                    },
                    "yAxis": {
                        "type": "value",
                        "scale": True,
                        "name": "å€¼",
                        "nameLocation": "middle",
                        "nameGap": 40
                    },
                    "series": [
                        {
                            "name": "åŸå§‹æ•°æ®",
                            "type": "line",
                            "showSymbol": False,  # ä¸æ˜¾ç¤ºæ•°æ®ç‚¹ç¬¦å·ï¼Œæå‡æ€§èƒ½
                            "smooth": True,       # å¹³æ»‘æ›²çº¿
                            "itemStyle": {
                                "color": "#1890ff"
                            },
                            "areaStyle": {
                                "color": {
                                    "type": "linear",
                                    "x": 0,
                                    "y": 0,
                                    "x2": 0,
                                    "y2": 1,
                                    "colorStops": [
                                        {
                                            "offset": 0,
                                            "color": "rgba(24, 144, 255, 0.5)"
                                        },
                                        {
                                            "offset": 1,
                                            "color": "rgba(24, 144, 255, 0)"
                                        }
                                    ]
                                }
                            },
                            "data": [float(x) if not pd.isna(x) else 0 for x in values],
                            "markLine": {
                                "data": [
                                    {"type": "average", "name": "å¹³å‡å€¼"}
                                ]
                            }
                        }
                    ]
                }
                
                # æ˜¾ç¤ºechartså›¾è¡¨
                st_echarts(options=options, height="400px", key=f"original_timeseries_echarts_{datetime.now().strftime('%H%M%S')}")
                
            except Exception as e:
                st.error(f"ç»˜åˆ¶å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
            
            # å¦‚æœåºåˆ—ä¸å¹³ç¨³ï¼Œæä¾›å·®åˆ†é€‰é¡¹
            if not is_stationary:
                st.warning("åºåˆ—ä¸å¹³ç¨³ï¼Œå»ºè®®è¿›è¡Œå·®åˆ†å¤„ç†")
                
                # å·®åˆ†å¤„ç†é€‰é¡¹
                diff_col1, diff_col2 = st.columns(2)
                
                with diff_col1:
                    diff_order = st.slider("å·®åˆ†é˜¶æ•°", min_value=1, max_value=2, value=1)
                
                with diff_col2:
                    log_diff = st.checkbox("ä½¿ç”¨å¯¹æ•°å·®åˆ†", value=False)
                
                diff_data, diff_df = diff_series(target_series, diff_order, log_diff)
                
                # æ˜¾ç¤ºå·®åˆ†åçš„åºåˆ—
                st.subheader(f"å·®åˆ†å¤„ç†åçš„æ—¶é—´åºåˆ—")
                
                # ä½¿ç”¨EChartsæ˜¾ç¤ºå·®åˆ†åçš„æ—¶é—´åºåˆ—
                try:
                    # ç¡®ä¿ç´¢å¼•å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    if isinstance(diff_df.index, pd.DatetimeIndex):
                        diff_dates = diff_df.index.strftime('%Y-%m-%d').tolist()
                    else:
                        diff_dates = diff_df.index.astype(str).tolist()
                    
                    # è·å–å·®åˆ†åºåˆ—åç§°
                    diff_cols = [col for col in diff_df.columns if col != 'åŸå§‹åºåˆ—']
                    if diff_cols:
                        diff_col = diff_cols[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·®åˆ†åˆ—
                        
                        # ç¡®ä¿æ•°æ®å¯ä»¥è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œå¹¶å¤„ç†NaNå€¼
                        diff_values = diff_df[diff_col].fillna(0).tolist()  # ä½¿ç”¨0æ›¿ä»£NaN
                        # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                        diff_values = [0 if pd.isna(x) else float(x) for x in diff_values]
                        
                        # é…ç½®echartsé€‰é¡¹
                        diff_options = {
                            "title": {
                                "text": "å·®åˆ†å¤„ç†åçš„æ—¶é—´åºåˆ—",
                                "textStyle": {
                                    "fontSize": 16
                                }
                            },
                            "tooltip": {
                                "trigger": "axis"
                            },
                            "grid": {
                                "left": "5%",
                                "right": "5%",
                                "bottom": "10%",
                                "containLabel": True
                            },
                            "xAxis": {
                                "type": "category",
                                "boundaryGap": False,
                                "data": diff_dates,
                                "axisLabel": {
                                    "rotate": 45,
                                    "interval": max(1, int(len(diff_dates)/20))  # ç¡®ä¿è‡³å°‘æ˜¾ç¤ºä¸€äº›æ ‡ç­¾
                                }
                            },
                            "yAxis": {
                                "type": "value",
                                "scale": True,
                                "name": "å·®åˆ†å€¼",
                                "nameLocation": "middle",
                                "nameGap": 40
                            },
                            "series": [
                                {
                                    "name": diff_col,
                                    "type": "line",
                                    "showSymbol": False,  # ä¸æ˜¾ç¤ºæ•°æ®ç‚¹ç¬¦å·ï¼Œæå‡æ€§èƒ½
                                    "smooth": True,       # å¹³æ»‘æ›²çº¿
                                    "itemStyle": {
                                        "color": "#19A7CE"  # ä½¿ç”¨ä¸åŒçš„é¢œè‰²åŒºåˆ†åŸå§‹åºåˆ—
                                    },
                                    "areaStyle": {
                                        "color": {
                                            "type": "linear",
                                            "x": 0,
                                            "y": 0,
                                            "x2": 0,
                                            "y2": 1,
                                            "colorStops": [
                                                {
                                                    "offset": 0,
                                                    "color": "rgba(25, 167, 206, 0.5)"
                                                },
                                                {
                                                    "offset": 1,
                                                    "color": "rgba(25, 167, 206, 0)"
                                                }
                                            ]
                                        }
                                    },
                                    "data": diff_values,
                                    "markLine": {
                                        "data": [
                                            {"type": "average", "name": "å¹³å‡å€¼"}
                                        ]
                                    }
                                }
                            ]
                        }
                        
                        # æ˜¾ç¤ºechartså›¾è¡¨ - ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆå”¯ä¸€key
                        st_echarts(options=diff_options, height="400px", key=f"diff_timeseries_echarts_{datetime.now().strftime('%H%M%S')}")
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å·®åˆ†åˆ—ï¼Œå›é€€åˆ°åŸå§‹çš„line_chart
                        st.line_chart(diff_df, use_container_width=True)
                        
                except Exception as e:
                    st.error(f"ç»˜åˆ¶å·®åˆ†å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
                    # å¦‚æœEChartså‡ºé”™ï¼Œå›é€€åˆ°åŸå§‹st.line_chart
                    st.line_chart(diff_df, use_container_width=True)
                
                # å¯¹å·®åˆ†åºåˆ—è¿›è¡Œå¹³ç¨³æ€§æ£€éªŒ
                st.subheader("å·®åˆ†åçš„å¹³ç¨³æ€§æ£€éªŒ")
                diff_results, diff_is_stationary, diff_stationarity_df = check_stationarity(diff_data)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**ADFç»Ÿè®¡é‡:**", round(diff_results['ADFç»Ÿè®¡é‡'], 4))
                    st.write("**på€¼:**", round(diff_results['på€¼'], 4))
                    st.write("**æ˜¯å¦å¹³ç¨³:**", "æ˜¯" if diff_is_stationary else "å¦")
                
                with col2:
                    st.write("**ä¸´ç•Œå€¼:**")
                    for key, value in diff_results['ä¸´ç•Œå€¼'].items():
                        st.write(f"  {key}: {round(value, 4)}")
                
                # å·®åˆ†åçš„ç»Ÿè®¡ç‰¹å¾åˆ†æ
                st.subheader("å·®åˆ†åçš„ç»Ÿè®¡ç‰¹å¾åˆ†æ")
                diff_stats_df, diff_normality_test = generate_descriptive_statistics(diff_data)
                
                # æ˜¾ç¤ºå·®åˆ†åçš„ç»Ÿè®¡ç‰¹å¾è¡¨
                st.write("å·®åˆ†åçš„æè¿°æ€§ç»Ÿè®¡è¡¨:")
                st.dataframe(diff_stats_df)
                
                # æ˜¾ç¤ºå·®åˆ†åçš„æ­£æ€æ€§æ£€éªŒç»“æœ
                st.write("å·®åˆ†åçš„Jarque-Beraæ­£æ€æ€§æ£€éªŒ:")
                st.write(f"ç»Ÿè®¡é‡: {diff_normality_test['statistic']:.4f}")
                st.write(f"på€¼: {diff_normality_test['p_value']:.4f}")
                st.write(f"æ•°æ®æ˜¯å¦æœä»æ­£æ€åˆ†å¸ƒ: {'æ˜¯' if diff_normality_test['is_normal'] else 'å¦'}")
                
                # æ›´æ–°ç›®æ ‡åºåˆ—ä¸ºå·®åˆ†åºåˆ—
                target_series = diff_data
            
            # 2. ç™½å™ªå£°æ£€éªŒ
            st.subheader("ç™½å™ªå£°æ£€éªŒ (Ljung-Boxæ£€éªŒ)")
            lb_result, is_white_noise = check_white_noise(target_series)
            
            # æ˜¾ç¤ºLjung-Boxæ£€éªŒç»“æœ
            st.write("Ljung-Boxæ£€éªŒç»“æœ (Portmanteau Qç»Ÿè®¡é‡):")
            st.dataframe(lb_result)
            
            if is_white_noise:
                st.warning("åºåˆ—ä¸ºç™½å™ªå£°ï¼Œä¸é€‚åˆå»ºç«‹æ—¶é—´åºåˆ—æ¨¡å‹")
            else:
                st.success("åºåˆ—ä¸æ˜¯ç™½å™ªå£°ï¼Œé€‚åˆå»ºç«‹æ—¶é—´åºåˆ—æ¨¡å‹")
            
            # 3. è‡ªç›¸å…³å’Œåè‡ªç›¸å…³åˆ†æ
            st.subheader("è‡ªç›¸å…³ä¸åè‡ªç›¸å…³åˆ†æ")
            acf_values, pacf_values, acf_pacf_data = analyze_acf_pacf(target_series)

            col1, col2 = st.columns(2)

            with col1:
                st.subheader("è‡ªç›¸å…³å‡½æ•°(ACF)")
                
                # è·å–ACFæ•°æ®
                acf_chart = acf_pacf_data['acf']
                
                # ç¡®ä¿æ•°æ®ä¸å«NaNå€¼
                acf_values_clean = [float(x) if not pd.isna(x) else 0 for x in acf_chart['ACF'].tolist()]
                upper_values_clean = [float(x) if not pd.isna(x) else 0 for x in acf_chart['ä¸Šé™'].tolist()]
                lower_values_clean = [float(x) if not pd.isna(x) else 0 for x in acf_chart['ä¸‹é™'].tolist()]
                
                acf_options = {
                    "title": {
                        "text": "è‡ªç›¸å…³å‡½æ•°(ACF)",
                        "textStyle": {
                            "fontSize": 16
                        }
                    },
                    "tooltip": {
                        "trigger": "axis",
                        "axisPointer": {
                            "type": "shadow"
                        }
                    },
                    "grid": {
                        "left": "10%",
                        "right": "5%",
                        "bottom": "10%",
                        "containLabel": True
                    },
                    "xAxis": {
                        "type": "category",
                        "data": list(range(len(acf_values_clean))),
                        "name": "æ»åé˜¶æ•°",
                        "nameLocation": "middle",
                        "nameGap": 25,
                    },
                    "yAxis": {
                        "type": "value",
                        "name": "è‡ªç›¸å…³ç³»æ•°",
                        "nameLocation": "middle",
                        "nameGap": 40
                    },
                    "series": [
                        {
                            "name": "è‡ªç›¸å…³ç³»æ•°",
                            "type": "bar",
                            "data": acf_values_clean,
                            "itemStyle": {
                                "color": "#1890ff"
                            }
                        },
                        {
                            "name": "95%ç½®ä¿¡åŒºé—´ä¸Šé™",
                            "type": "line",
                            "data": upper_values_clean,
                            "lineStyle": {
                                "type": "dashed",
                                "color": "#FF4560"
                            },
                            "symbol": "none"
                        },
                        {
                            "name": "95%ç½®ä¿¡åŒºé—´ä¸‹é™",
                            "type": "line",
                            "data": lower_values_clean,
                            "lineStyle": {
                                "type": "dashed",
                                "color": "#FF4560"
                            },
                            "symbol": "none"
                        }
                    ]
                }
                
                # æ˜¾ç¤ºACFå›¾è¡¨ - ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆå”¯ä¸€key
                st_echarts(options=acf_options, height="400px", key=f"acf_chart_{datetime.now().strftime('%H%M%S')}")
            
            with col2:
                st.subheader("åè‡ªç›¸å…³å‡½æ•°(PACF)")
                
                # è·å–PACFæ•°æ®
                pacf_chart = acf_pacf_data['pacf']
                
                # ç¡®ä¿æ•°æ®ä¸å«NaNå€¼
                pacf_values_clean = [float(x) if not pd.isna(x) else 0 for x in pacf_chart['PACF'].tolist()]
                upper_values_clean = [float(x) if not pd.isna(x) else 0 for x in pacf_chart['ä¸Šé™'].tolist()]
                lower_values_clean = [float(x) if not pd.isna(x) else 0 for x in pacf_chart['ä¸‹é™'].tolist()]
                
                pacf_options = {
                    "title": {
                        "text": "åè‡ªç›¸å…³å‡½æ•°(PACF)",
                        "textStyle": {
                            "fontSize": 16
                        }
                    },
                    "tooltip": {
                        "trigger": "axis",
                        "axisPointer": {
                            "type": "shadow"
                        }
                    },
                    "grid": {
                        "left": "10%",
                        "right": "5%",
                        "bottom": "10%",
                        "containLabel": True
                    },
                    "xAxis": {
                        "type": "category",
                        "data": list(range(len(pacf_values_clean))),
                        "name": "æ»åé˜¶æ•°",
                        "nameLocation": "middle",
                        "nameGap": 25,
                    },
                    "yAxis": {
                        "type": "value",
                        "name": "åè‡ªç›¸å…³ç³»æ•°",
                        "nameLocation": "middle",
                        "nameGap": 40
                    },
                    "series": [
                        {
                            "name": "åè‡ªç›¸å…³ç³»æ•°",
                            "type": "bar",
                            "data": pacf_values_clean,
                            "itemStyle": {
                                "color": "#19A7CE"
                            }
                        },
                        {
                            "name": "95%ç½®ä¿¡åŒºé—´ä¸Šé™",
                            "type": "line",
                            "data": upper_values_clean,
                            "lineStyle": {
                                "type": "dashed",
                                "color": "#FF4560"
                            },
                            "symbol": "none"
                        },
                        {
                            "name": "95%ç½®ä¿¡åŒºé—´ä¸‹é™",
                            "type": "line",
                            "data": lower_values_clean,
                            "lineStyle": {
                                "type": "dashed",
                                "color": "#FF4560"
                            },
                            "symbol": "none"
                        }
                    ]
                }
                
                # æ˜¾ç¤ºPACFå›¾è¡¨ - ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆå”¯ä¸€key
                st_echarts(options=pacf_options, height="400px", key=f"pacf_chart_{datetime.now().strftime('%H%M%S')}")
            
            # ä¿å­˜æ£€éªŒç»“æœåˆ°ä¼šè¯çŠ¶æ€
            st.session_state['arima_check_results'] = {
                'target_series': target_series,
                'original_series': df[target_col].copy() if target_col in df.columns else None,  # ä¿å­˜åŸå§‹åºåˆ—
                'is_stationary': is_stationary,
                'diff_data': diff_data if not is_stationary else None,
                'diff_is_stationary': diff_is_stationary if not is_stationary else None,
                'is_white_noise': is_white_noise,
                'suggested_d': diff_order if not is_stationary and diff_is_stationary else 0,
                'log_diff': log_diff if not is_stationary else False
            }
        
        # æ¨¡å‹å»ºç«‹é€‰é¡¹å¡
        with arima_tabs[1]:
            st.markdown("#### ARIMAæ¨¡å‹å»ºç«‹")
            
            # æ£€æŸ¥ä¹‹å‰çš„æ£€éªŒç»“æœ
            if 'arima_check_results' not in st.session_state:
                st.warning("è¯·å…ˆå®Œæˆæ•°æ®æ£€éªŒ")
                st.stop()
            
            # ä»ä¼šè¯çŠ¶æ€è·å–æ£€éªŒç»“æœ
            check_results = st.session_state['arima_check_results']
            target_series = check_results['target_series']
            suggested_d = check_results['suggested_d']
            log_diff = check_results.get('log_diff', False)  # æ·»åŠ å¯¹æ•°å·®åˆ†é€‰é¡¹æ”¯æŒ
            
            # 1. æ¨¡å‹è¯†åˆ« - ARIMAå‚æ•°é€‰æ‹©
            st.subheader("æ¨¡å‹è¯†åˆ« - ARIMAå‚æ•°é€‰æ‹©")
            
            # æä¾›è‡ªåŠ¨å’Œæ‰‹åŠ¨ä¸¤ç§å‚æ•°é€‰æ‹©æ–¹å¼
            param_selection = st.radio("å‚æ•°é€‰æ‹©æ–¹å¼", ["è‡ªåŠ¨é€‰æ‹©", "æ‰‹åŠ¨è®¾ç½®"])
            
            if param_selection == "è‡ªåŠ¨é€‰æ‹©":
                # æ¨¡å‹è‡ªåŠ¨é€‰æ‹©çš„èŒƒå›´è®¾ç½®
                st.write("è®¾ç½®å‚æ•°æœç´¢èŒƒå›´:")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    p_max = st.slider("pæœ€å¤§å€¼", min_value=0, max_value=5, value=2)
                
                with col2:
                    d_value = st.slider("då€¼", min_value=0, max_value=2, value=suggested_d)
                
                with col3:
                    q_max = st.slider("qæœ€å¤§å€¼", min_value=0, max_value=5, value=2)
                
                # æ·»åŠ å­£èŠ‚æ€§å‚æ•°é€‰é¡¹
                st.write("å­£èŠ‚æ€§å‚æ•° (å¯é€‰):")
                seasonal = st.checkbox("æ·»åŠ å­£èŠ‚æ€§ç»„ä»¶", value=False)
                
                if seasonal:
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        P_max = st.slider("Pæœ€å¤§å€¼", min_value=0, max_value=2, value=1)
                    
                    with col2:
                        D_max = st.slider("Dæœ€å¤§å€¼", min_value=0, max_value=1, value=1)
                    
                    with col3:
                        Q_max = st.slider("Qæœ€å¤§å€¼", min_value=0, max_value=2, value=1)
                    
                    with col4:
                        s = st.slider("å­£èŠ‚å‘¨æœŸ (s)", min_value=4, max_value=52, value=12)
                
                # æ¨¡å‹é€‰æ‹©æ ‡å‡†
                criterion = st.radio("æ¨¡å‹é€‰æ‹©æ ‡å‡†", ["aic", "bic"])
                
                # è‡ªåŠ¨å¯»æ‰¾æœ€ä½³å‚æ•°
                if st.button("ç¡®å®š - æŸ¥æ‰¾æœ€ä½³å‚æ•°"):
                    with st.spinner("æ­£åœ¨æŸ¥æ‰¾æœ€ä½³ARIMAå‚æ•°..."):
                        if seasonal:
                            st.write("æ­£åœ¨è®­ç»ƒSARIMAæ¨¡å‹...")
                            # æ„å»ºå­£èŠ‚æ€§å‚æ•°æœç´¢èŒƒå›´
                            p_range = range(0, p_max + 1)
                            d_range = [d_value]
                            q_range = range(0, q_max + 1)
                            P_range = range(0, P_max + 1)
                            D_range = range(0, D_max + 1)
                            Q_range = range(0, Q_max + 1)
                            s_value = s
                            
                            best_params = find_best_arima_params(
                                target_series, 
                                p_range, d_range, q_range,
                                P_range, D_range, Q_range, s_value,
                                criterion
                            )
                        else:
                            st.write("æ­£åœ¨è®­ç»ƒARIMAæ¨¡å‹...")
                            # æ„å»ºéå­£èŠ‚æ€§å‚æ•°æœç´¢èŒƒå›´
                            p_range = range(0, p_max + 1)
                            d_range = [d_value]
                            q_range = range(0, q_max + 1)
                            
                            best_params = find_best_arima_params(
                                target_series, 
                                p_range, d_range, q_range,
                                criterion=criterion
                            )
                        
                        st.write("æœ€ä½³ARIMAå‚æ•°:", best_params)
                        # ä¿å­˜æœ€ä½³å‚æ•°åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state['arima_best_params'] = best_params
            else:
                # æ‰‹åŠ¨è®¾ç½®ARIMAå‚æ•°
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    p = st.slider("p (ARé˜¶æ•°)", min_value=0, max_value=5, value=1)
                
                with col2:
                    d = st.slider("d (å·®åˆ†é˜¶æ•°)", min_value=0, max_value=2, value=suggested_d)
                
                with col3:
                    q = st.slider("q (MAé˜¶æ•°)", min_value=0, max_value=5, value=1)
                
                # æ·»åŠ å­£èŠ‚æ€§å‚æ•°é€‰é¡¹
                seasonal = st.checkbox("æ·»åŠ å­£èŠ‚æ€§ç»„ä»¶", value=False)
                
                if seasonal:
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        P = st.slider("P (å­£èŠ‚ARé˜¶æ•°)", min_value=0, max_value=2, value=0)
                    
                    with col2:
                        D = st.slider("D (å­£èŠ‚å·®åˆ†é˜¶æ•°)", min_value=0, max_value=1, value=0)
                    
                    with col3:
                        Q = st.slider("Q (å­£èŠ‚MAé˜¶æ•°)", min_value=0, max_value=2, value=0)
                    
                    with col4:
                        s = st.slider("s (å­£èŠ‚å‘¨æœŸ)", min_value=4, max_value=52, value=12)
                    
                    # æ‰‹åŠ¨SARIMAå‚æ•°
                    params = (p, d, q, P, D, Q, s)
                    st.write(f"å·²é€‰æ‹©SARIMAæ¨¡å‹: ({p},{d},{q})({P},{D},{Q},{s})")
                else:
                    # æ‰‹åŠ¨ARIMAå‚æ•°
                    params = (p, d, q)
                    st.write(f"å·²é€‰æ‹©ARIMAæ¨¡å‹: ({p},{d},{q})")
                
                # ä¿å­˜æ‰‹åŠ¨å‚æ•°åˆ°ä¼šè¯çŠ¶æ€
                if st.button("ç¡®è®¤å‚æ•°"):
                    st.session_state['arima_best_params'] = params
                    st.write("å‚æ•°å·²ç¡®è®¤")
            
            # 2. æ¨¡å‹ä¼°è®¡ - ARIMAæ¨¡å‹æ‹Ÿåˆ
            st.subheader("æ¨¡å‹ä¼°è®¡ - ARIMAæ¨¡å‹æ‹Ÿåˆ")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¡®è®¤çš„å‚æ•°
            if 'arima_best_params' not in st.session_state:
                st.warning("è¯·å…ˆé€‰æ‹©ARIMAå‚æ•°")
                st.stop()
            
            best_params = st.session_state['arima_best_params']
            
            # åˆ†å‰²æ•°æ®
            st.write("è®¾ç½®è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ¯”ä¾‹:")
            train_ratio = st.slider("è®­ç»ƒé›†æ¯”ä¾‹", min_value=0.5, max_value=0.95, value=0.8, step=0.05)
            
            # è®¡ç®—åˆ†å‰²ç‚¹
            split_point = int(len(target_series) * train_ratio)
            
            # è®­ç»ƒARIMAæ¨¡å‹
            if st.button("è®­ç»ƒARIMAæ¨¡å‹"):
                with st.spinner("æ­£åœ¨è®­ç»ƒARIMAæ¨¡å‹..."):
                    # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
                    train_data = target_series.iloc[:split_point]
                    test_data = target_series.iloc[split_point:]
                    
                    # æ‹Ÿåˆæ¨¡å‹
                    model, train_results = fit_arima_model(train_data, best_params)
                    
                    # æ®‹å·®è¯Šæ–­
                    st.subheader("æ®‹å·®è¯Šæ–­")
                    residual_results, residuals_df = check_residuals(model)
                    
                    # æ˜¾ç¤ºLjung-Boxç»Ÿè®¡é‡å’Œpå€¼
                    st.write(f"Ljung-Boxæ£€éªŒç»“æœ: Q={residual_results['ljung_box_stat']:.4f}, på€¼={residual_results['ljung_box_pvalue']:.4f}")
                    st.write(f"æ®‹å·®æ˜¯å¦ä¸ºç™½å™ªå£°: {'æ˜¯' if residual_results['is_white_noise'] else 'å¦'}")
                    
                    # æ˜¾ç¤ºæ®‹å·®ç»Ÿè®¡é‡
                    st.write("æ®‹å·®ç»Ÿè®¡é‡:")
                    st.write(f"å‡å€¼: {residual_results['mean']:.4f}")
                    st.write(f"æ ‡å‡†å·®: {residual_results['std']:.4f}")
                    
                    # æ®‹å·®æ—¶é—´åºåˆ—å›¾è¡¨
                    st.write("æ®‹å·®æ—¶é—´åºåˆ—:")
                    st.line_chart(residuals_df['residuals'], use_container_width=True)
                    
                    # æ®‹å·®ACFå›¾è¡¨
                    st.write("æ®‹å·®è‡ªç›¸å…³å‡½æ•°:")
                    st.bar_chart(residuals_df['acf'], use_container_width=True)
                    
                    # æ®‹å·®QQå›¾
                    st.write("æ®‹å·®QQå›¾:")
                    qq_data = pd.DataFrame({
                        'QQæ ·æœ¬å€¼': residuals_df['qq_points'],
                        'QQç†è®ºå€¼': residuals_df['qq_line']
                    })
                    st.line_chart(qq_data, use_container_width=True)
                    
                    # æ®‹å·®ç›´æ–¹å›¾
                    st.write("æ®‹å·®ç›´æ–¹å›¾:")
                    hist_data = pd.DataFrame({
                        'é¢‘ç‡': residuals_df['hist_values']
                    })
                    st.bar_chart(hist_data, use_container_width=True)
                    
                    # å¦‚æœä½¿ç”¨äº†å¯¹æ•°å·®åˆ†ï¼Œè®°å½•è¿™ä¸€ä¿¡æ¯
                    if log_diff:
                        st.info("æ³¨æ„ï¼šä½¿ç”¨äº†å¯¹æ•°å·®åˆ†ï¼Œé¢„æµ‹ç»“æœå°†ä¼šè‡ªåŠ¨è¿›è¡Œé€†å˜æ¢")
                    
                    # æ¨¡å‹é¢„æµ‹
                    st.subheader("æ¨¡å‹é¢„æµ‹ä¸è¯„ä¼°")
                    
                    # é¢„æµ‹å’Œè¯„ä¼°
                    forecast_steps = len(test_data)
                    forecast_results, forecast_df = forecast_arima(model, train_data, forecast_steps)
                    
                    # å¦‚æœä½¿ç”¨äº†å·®åˆ†ï¼Œéœ€è¦é€†å˜æ¢
                    if suggested_d > 0 or log_diff:
                        # è·å–åŸå§‹æ•°æ®
                        if 'diff_data' in check_results and check_results['diff_data'] is not None:
                            # å¦‚æœå­˜åœ¨å·®åˆ†æ•°æ®
                            original_data = check_results.get('original_series', None)
                            if original_data is None:
                                # å°è¯•ä»ä¼šè¯çŠ¶æ€è·å–
                                if 'arima_original_data' in st.session_state:
                                    original_data = st.session_state['arima_original_data']
                                else:
                                    # å¦‚æœæœªæ‰¾åˆ°åŸå§‹æ•°æ®ï¼Œå‘å‡ºè­¦å‘Š
                                    st.warning("æœªæ‰¾åˆ°åŸå§‹æ•°æ®ï¼Œæ— æ³•æ‰§è¡Œé€†å·®åˆ†æ“ä½œ")
                            
                            if original_data is not None:
                                # æ‰§è¡Œé€†å·®åˆ†
                                forecast_df = inverse_diff(
                                    original_data, 
                                    forecast_df, 
                                    d=suggested_d,
                                    log_diff=log_diff
                                )
                                st.info("å·²æ‰§è¡Œé€†å·®åˆ†å˜æ¢")
                    
                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                    st.write("é¢„æµ‹ç»“æœ:")
                    st.line_chart(forecast_df, use_container_width=True)
                    
                    # æ¨¡å‹è¯„ä¼°
                    evaluation_metrics = evaluate_arima_model(
                        test_data,
                        forecast_results['forecast_mean'].iloc[-len(test_data):],
                        train_data
                    )
                    
                    # æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡
                    st.write("æ¨¡å‹è¯„ä¼°æŒ‡æ ‡:")
                    metrics_df = pd.DataFrame(
                        [evaluation_metrics],
                        index=["ARIMAæ¨¡å‹"],
                        columns=["MSE", "RMSE", "MAE", "MAPE", "AIC", "BIC"]
                    )
                    st.dataframe(metrics_df)
                    
                    # ä¿å­˜æ¨¡å‹å’Œç»“æœåˆ°ä¼šè¯çŠ¶æ€
                    st.session_state['arima_model'] = model
                    st.session_state['arima_train_results'] = train_results
                    st.session_state['arima_forecast_results'] = forecast_results
                    st.session_state['arima_evaluation_metrics'] = evaluation_metrics
                    st.session_state['arima_original_data'] = check_results.get('original_series', train_data)
                    st.session_state['arima_log_diff'] = log_diff
                    
                    st.success("ARIMAæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ!")
        
        # æ¨¡å‹é¢„æµ‹å¯¹æ¯”é€‰é¡¹å¡
        with arima_tabs[2]:
            st.markdown("#### æ¨¡å‹é¢„æµ‹å¯¹æ¯”")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
            if 'arima_model' in st.session_state:
                arima_model_data = st.session_state['arima_model']
                fitted_model = arima_model_data['fitted_model']
                model_order = arima_model_data['order']
                
                # æ˜¾ç¤ºå½“å‰æ¨¡å‹ä¿¡æ¯
                st.info(f"å½“å‰æ¨¡å‹: ARIMA{model_order}")
                
                # é¢„æµ‹è®¾ç½®
                forecast_steps = st.number_input(
                    "é¢„æµ‹æ­¥æ•°",
                    min_value=1,
                    max_value=30,
                    value=10,
                    help="éœ€è¦è¿›è¡Œé¢„æµ‹çš„æœªæ¥æ—¶é—´ç‚¹æ•°é‡"
                )
                
                # é¢„æµ‹æŒ‰é’®
                if st.button("æ‰§è¡Œé¢„æµ‹"):
                    # é¢„æµ‹æœªæ¥å€¼
                    st.subheader(f"æœªæ¥ {forecast_steps} æ­¥é¢„æµ‹")
                    forecast_results, forecast_df = forecast_arima(fitted_model, steps=forecast_steps)
                    
                    if forecast_results:
                        # ä½¿ç”¨StreamlitåŸç”Ÿå›¾è¡¨æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                        st.subheader("é¢„æµ‹ç»“æœå›¾è¡¨")
                        st.line_chart(forecast_df, use_container_width=True)
                        
                        # æ˜¾ç¤ºé¢„æµ‹ç»“æœè¡¨æ ¼
                        forecast_table = pd.DataFrame({
                            'é¢„æµ‹å€¼': list(forecast_results['mean'].values()),
                            '95%ç½®ä¿¡åŒºé—´ä¸‹é™': list(forecast_results['lower_ci'].values()),
                            '95%ç½®ä¿¡åŒºé—´ä¸Šé™': list(forecast_results['upper_ci'].values())
                        }, index=list(forecast_results['mean'].keys()))
                        
                        st.subheader("é¢„æµ‹ç»“æœè¡¨æ ¼")
                        st.dataframe(forecast_table)
                        
                        # ä¿å­˜é¢„æµ‹ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                        st.session_state['arima_forecast'] = {
                            'results': forecast_results,
                            'steps': forecast_steps
                        }
                    else:
                        st.error("é¢„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹")
                
                # æ¨¡å‹è¯„ä¼°éƒ¨åˆ†
                if df is not None and len(df) > 0:
                    st.subheader("æ¨¡å‹è¯„ä¼°")
                    
                    # è®¾ç½®è®­ç»ƒé›†å’Œæµ‹è¯•é›†åˆ’åˆ†
                    test_size = st.slider(
                        "æµ‹è¯•é›†æ¯”ä¾‹", 
                        min_value=0.1, 
                        max_value=0.5, 
                        value=0.2, 
                        step=0.05
                    )
                    
                    if st.button("è¯„ä¼°æ¨¡å‹æ€§èƒ½"):
                        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
                        train_size = int(len(target_series) * (1 - test_size))
                        train_data = target_series.iloc[:train_size]
                        test_data = target_series.iloc[train_size:]
                        
                        st.write(f"è®­ç»ƒé›†å¤§å°: {len(train_data)}, æµ‹è¯•é›†å¤§å°: {len(test_data)}")
                        
                        # ç”¨è®­ç»ƒé›†é‡æ–°æ‹Ÿåˆæ¨¡å‹
                        st.info("ä½¿ç”¨è®­ç»ƒé›†æ•°æ®é‡æ–°æ‹Ÿåˆæ¨¡å‹...")
                        train_model, _ = fit_arima_model(train_data, order=model_order)
                        
                        if train_model:
                            # è¯„ä¼°æ¨¡å‹æ€§èƒ½
                            metrics = evaluate_arima_model(train_model, test_data)
                            
                            if metrics:
                                st.subheader("æ¨¡å‹è¯„ä¼°æŒ‡æ ‡")
                                metrics_df = pd.DataFrame({
                                    'æŒ‡æ ‡': list(metrics.keys()),
                                    'å€¼': list(metrics.values())
                                })
                                st.dataframe(metrics_df)
                                
                                # ç»˜åˆ¶é¢„æµ‹ç»“æœä¸å®é™…å€¼å¯¹æ¯”
                                forecast = train_model.forecast(steps=len(test_data))
                                
                                # å‡†å¤‡ç”¨äºStreamlitå›¾è¡¨çš„æ•°æ®
                                eval_chart_data = pd.DataFrame({
                                    'å®é™…å€¼': test_data.values,
                                    'é¢„æµ‹å€¼': forecast.values
                                }, index=test_data.index)
                                
                                # ä½¿ç”¨StreamlitåŸç”Ÿå›¾è¡¨æ˜¾ç¤º
                                st.subheader("æµ‹è¯•é›†é¢„æµ‹ç»“æœå¯¹æ¯”")
                                st.line_chart(eval_chart_data, use_container_width=True)
                            else:
                                st.error("æ¨¡å‹è¯„ä¼°å¤±è´¥")
                        else:
                            st.error("ç”¨è®­ç»ƒé›†é‡æ–°æ‹Ÿåˆæ¨¡å‹å¤±è´¥")
            else:
                st.warning("è¯·å…ˆåœ¨'æ¨¡å‹å»ºç«‹'é€‰é¡¹å¡ä¸­è®­ç»ƒARIMAæ¨¡å‹")

# å·¦ä¾§æ  - æ•°æ®ä¿¡æ¯å’Œæ•°æ®åˆ’åˆ†
with left_column:
    st.subheader("æ¨¡å‹å’Œæ•°æ®ä¿¡æ¯")
    
    # æ¨¡å‹çŠ¶æ€ä¿¡æ¯
    with st.expander("è®­ç»ƒçŠ¶æ€", expanded=True):
        if st.session_state.get('training_complete', False):
            st.success("æ¨¡å‹è®­ç»ƒå·²å®Œæˆ")
        elif st.session_state.get('start_training', False):
            st.info("æ¨¡å‹è®­ç»ƒè¿›è¡Œä¸­...")
            # æ·»åŠ ç´§æ€¥é‡ç½®æŒ‰é’®
            if st.button("ç´§æ€¥é‡ç½®è®­ç»ƒ", key="emergency_reset"):
                st.session_state['start_training'] = False
                st.session_state['training_complete'] = False
                st.rerun()
        else:
            st.info("ç­‰å¾…å¼€å§‹è®­ç»ƒ...")
    
    # æ¨¡å‹ä¿å­˜é€‰é¡¹
    with st.expander("æ¨¡å‹ä¿å­˜", expanded=True):
        model_name = st.text_input(
            "æ¨¡å‹åç§°",
            value="my_model_v1"
        )
        
        save_model_button = st.button(
            "ä¿å­˜æ¨¡å‹",
            disabled=not st.session_state.get('training_complete', False)
        )
        
        if save_model_button and 'trained_model' in st.session_state:
            model_path = save_model(
                st.session_state['trained_model'],
                st.session_state['model_params'],
                st.session_state['training_params'],
                st.session_state['training_history'],
                path=f"models/{model_name}"
            )
            st.success(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # æ•°æ®åˆ’åˆ†é€‰é¡¹
    with st.expander("æ•°æ®åˆ’åˆ†", expanded=True):
        sequence_length = st.number_input(
            "åºåˆ—é•¿åº¦",
            min_value=1,
            max_value=100,
            value=60,
            help="ç”¨äºæ„å»ºæ—¶é—´åºåˆ—æ ·æœ¬çš„æ­¥é•¿"
        )
        
        train_test_ratio = st.slider(
            "è®­ç»ƒé›†æ¯”ä¾‹",
            min_value=0.5,
            max_value=0.9,
            value=0.7,
            step=0.05,
            help="ç”¨äºè®­ç»ƒçš„æ•°æ®æ¯”ä¾‹"
        )
        
        # ä¿å­˜è¿™äº›å‚æ•°åˆ°ä¼šè¯çŠ¶æ€ä»¥ä¾¿è®­ç»ƒæ—¶ä½¿ç”¨
        st.session_state['sequence_length'] = sequence_length
        st.session_state['train_test_ratio'] = train_test_ratio
    
    # æ¨¡å‹è¯„ä¼°ç®€æŠ¥
    with st.expander("æ¨¡å‹è¯„ä¼°ç®€æŠ¥", expanded=True):
        if 'model_metrics' in st.session_state and st.session_state.get('model_metrics') is not None:
            metrics = st.session_state['model_metrics']
            st.metric(
                label="MSE",
                value=f"{metrics.get('MSE', 0):.4f}"
            )
            
            st.metric(
                label="RMSE",
                value=f"{metrics.get('RMSE', 0):.4f}"
            )
            
            st.metric(
                label="MAE",
                value=f"{metrics.get('MAE', 0):.4f}"
            )
        elif 'start_training' in st.session_state and st.session_state.get('start_training'):
            st.info("æ¨¡å‹è¯„ä¼°ä¸­...")
        else:
            st.info("è®­ç»ƒæ¨¡å‹åå°†æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡")
    st.subheader("æ•°æ®ä¿¡æ¯")
    
    # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
    with st.expander("æ•°æ®åŸºæœ¬ä¿¡æ¯", expanded=True):
        if 'raw_data' in st.session_state:
            df = st.session_state['raw_data']
            if df is not None:
                st.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
                st.write(f"æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
            else:
                st.warning("æ•°æ®ä¸ºç©ºï¼Œè¯·åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æœ‰æ•ˆæ•°æ®")
    
    # æ•°æ®åˆ’åˆ†è®¾ç½®        
    with st.expander("æ•°æ®åˆ’åˆ†è®¾ç½®", expanded=True):
        train_test_ratio = st.slider(
            "è®­ç»ƒé›†æ¯”ä¾‹", 
            min_value=0.5, 
            max_value=0.9, 
            value=0.8,  # é»˜è®¤å€¼0.8ï¼Œä¸å‘½ä»¤è¡Œç‰ˆæœ¬ä¸€è‡´
            step=0.05,
            help="è®­ç»ƒé›†å æ€»æ•°æ®çš„æ¯”ä¾‹"
        )
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œä½¿åºåˆ—é•¿åº¦è¾“å…¥æ¡†æ¨ªæ’æ˜¾ç¤º
        seq_col1, seq_col2 = st.columns(2)
        
        with seq_col1:
            sequence_length = st.number_input(
                "è¾“å…¥åºåˆ—é•¿åº¦",
                min_value=1,
                max_value=100,
                value=20,  # é»˜è®¤å€¼ä»10æ”¹ä¸º20ï¼Œä¸å‘½ä»¤è¡Œç‰ˆæœ¬ä¸€è‡´
                help="ç”¨äºé¢„æµ‹çš„å†å²æ•°æ®ç‚¹æ•°é‡"
            )
        
        with seq_col2:
            prediction_length = st.number_input(
                "é¢„æµ‹åºåˆ—é•¿åº¦",
                min_value=1,
                max_value=30,
                value=1,  # é»˜è®¤å€¼1ï¼Œä¸å‘½ä»¤è¡Œç‰ˆæœ¬ä¸€è‡´
                help="éœ€è¦é¢„æµ‹çš„æœªæ¥æ•°æ®ç‚¹æ•°é‡"
            )


# å®šä¹‰LSTMæ¨¡å‹
class LSTMModel(nn.Module):
    """
    LSTMæ¨¡å‹å®šä¹‰
    
    Args:
        input_dim: è¾“å…¥ç‰¹å¾ç»´åº¦
        hidden_dim: éšè—å±‚ç»´åº¦
        num_layers: LSTMå±‚æ•°
        output_dim: è¾“å‡ºç»´åº¦
        dropout: Dropoutæ¯”ç‡
    """
    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.3):
        super(LSTMModel, self).__init__()
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        
        # LSTMå±‚
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True
        )
        
        # Dropoutå±‚å’Œå…¨è¿æ¥å±‚
        self.dropout = nn.Dropout(dropout)  # å•ç‹¬å®šä¹‰dropoutå±‚
        self.fc = nn.Linear(hidden_dim, output_dim)
        
    def forward(self, x):
        # åˆå§‹åŒ–éšè—çŠ¶æ€
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)
        
        # å‰å‘ä¼ æ’­LSTM
        out, (hn, cn) = self.lstm(x, (h0, c0))
        
        # åº”ç”¨dropoutåˆ°æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        out = self.dropout(out[:, -1, :])
        
        # å…¨è¿æ¥å±‚
        out = self.fc(out)
        return out

def create_sequences(data, seq_length):
    """
    åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
    
    Args:
        data: è¾“å…¥æ•°æ®
        seq_length: åºåˆ—é•¿åº¦
        
    Returns:
        X: ç‰¹å¾åºåˆ—
        y: ç›®æ ‡å€¼
    """
    xs, ys = [], []
    for i in range(len(data) - seq_length):
        x = data[i:(i + seq_length)]
        y = data[i + seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

# è®­ç»ƒLSTMæ¨¡å‹
def train_lstm_model(X_train, y_train, X_val, y_val, model_params, training_params, progress_bar=None, status_text=None, loss_chart=None):
    """
    è®­ç»ƒLSTMæ¨¡å‹
    
    Args:
        X_train: è®­ç»ƒç‰¹å¾æ•°æ®
        y_train: è®­ç»ƒç›®æ ‡æ•°æ®
        X_val: éªŒè¯ç‰¹å¾æ•°æ®
        y_val: éªŒè¯ç›®æ ‡æ•°æ®
        model_params: æ¨¡å‹å‚æ•°å­—å…¸
        training_params: è®­ç»ƒå‚æ•°å­—å…¸
        progress_bar: streamlitè¿›åº¦æ¡
        status_text: streamlitçŠ¶æ€æ–‡æœ¬
        loss_chart: æŸå¤±æ›²çº¿å›¾è¡¨å ä½ç¬¦
        
    Returns:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        history: è®­ç»ƒå†å²
    """
    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    X_train_tensor = torch.FloatTensor(X_train)
    y_train_tensor = torch.FloatTensor(y_train)
    X_val_tensor = torch.FloatTensor(X_val)
    y_val_tensor = torch.FloatTensor(y_val)
    
    # åˆ›å»ºæ¨¡å‹
    model = LSTMModel(
        input_dim=model_params['input_dim'],
        hidden_dim=model_params['hidden_dim'],
        num_layers=model_params['num_layers'],
        output_dim=model_params['output_dim'],
        dropout=model_params.get('dropout', 0.3)
    )
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=training_params['learning_rate'])
    
    # è®­ç»ƒå‚æ•°
    epochs = training_params['epochs']
    batch_size = training_params['batch_size']
    
    # è®­ç»ƒå†å²è®°å½•
    history = {
        'train_loss': [],
        'val_loss': []
    }
    
    # ä½¿ç”¨ä¼ å…¥çš„è¿›åº¦æ¡æˆ–åˆ›å»ºæ–°çš„
    if progress_bar is None:
        progress_bar = st.progress(0)
    if status_text is None:
        status_text = st.empty()
        
    # åˆ›å»ºæŸå¤±å›¾è¡¨çš„DataFrame
    loss_df = pd.DataFrame(columns=['è®­ç»ƒæŸå¤±', 'éªŒè¯æŸå¤±'])
    
    # åˆå§‹åŒ–æŸå¤±å›¾è¡¨
    if loss_chart is not None:
        with loss_chart.container():
            st.info("è®­ç»ƒå¼€å§‹ï¼ŒæŸå¤±æ›²çº¿å°†åœ¨æ­¤å¤„æ˜¾ç¤º...")
            chart_placeholder = st.empty()
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(epochs):
        model.train()
        train_losses = []
        
        # å°æ‰¹é‡è®­ç»ƒ
        for i in range(0, len(X_train_tensor), batch_size):
            batch_X = X_train_tensor[i:i+batch_size]
            batch_y = y_train_tensor[i:i+batch_size]
            
            # å‰å‘ä¼ æ’­
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            
            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            train_losses.append(loss.item())
        
        # éªŒè¯
        model.eval()
        with torch.no_grad():
            val_outputs = model(X_val_tensor)
            val_loss = criterion(val_outputs, y_val_tensor)
            
        # è®°å½•è®­ç»ƒå’ŒéªŒè¯æŸå¤±
        avg_train_loss = sum(train_losses) / len(train_losses)
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(val_loss.item())
        
        # æ›´æ–°æŸå¤±å›¾è¡¨
        loss_df.loc[epoch] = [avg_train_loss, val_loss.item()]
        
        # æ›´æ–°å›¾è¡¨
        if loss_chart is not None:
            with loss_chart.container():
                with chart_placeholder:
                    st.line_chart(loss_df)
        
        # æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
        progress = (epoch + 1) / epochs
        progress_bar.progress(progress)
        status_text.text(f"Epoch {epoch+1}/{epochs}, è®­ç»ƒæŸå¤±: {avg_train_loss:.6f}, éªŒè¯æŸå¤±: {val_loss.item():.6f}")
    
    progress_bar.empty()
    status_text.text("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    
    return model, history

# ç»˜åˆ¶è®­ç»ƒå†å²
def plot_training_history(history, chart_placeholder=None):
    """
    ç»˜åˆ¶è®­ç»ƒå†å²
    
    Args:
        history: è®­ç»ƒå†å²å­—å…¸
        chart_placeholder: å›¾è¡¨å ä½ç¬¦
    """
    # åˆ›å»ºDataFrameç”¨äºç»˜å›¾
    history_df = pd.DataFrame({
        'è®­ç»ƒæŸå¤±': history['train_loss'],
        'éªŒè¯æŸå¤±': history['val_loss']
    })
    
    if chart_placeholder is not None:
        with chart_placeholder:
            st.line_chart(history_df)
    else:
        st.line_chart(history_df)

# ä¿å­˜æ¨¡å‹
def save_model(model, model_params, training_params, history, path="models"):
    """
    ä¿å­˜æ¨¡å‹å’Œè®­ç»ƒå‚æ•°
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        model_params: æ¨¡å‹å‚æ•°
        training_params: è®­ç»ƒå‚æ•°
        history: è®­ç»ƒå†å²
        path: ä¿å­˜è·¯å¾„
    
    Returns:
        model_path: æ¨¡å‹ä¿å­˜è·¯å¾„
    """
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(path, exist_ok=True)
    
    # ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜æ¨¡å‹
    model_filename = f"lstm_model_{timestamp}.pth"
    model_path = os.path.join(path, model_filename)
    torch.save(model.state_dict(), model_path)
    
    # ä¿å­˜æ¨¡å‹å‚æ•°å’Œè®­ç»ƒå†å²
    params_filename = f"model_params_{timestamp}.json"
    params_path = os.path.join(path, params_filename)
    
    params_dict = {
        'model_params': model_params,
        'training_params': training_params,
        'training_history': {
            'train_loss': [float(loss) for loss in history['train_loss']],
            'val_loss': [float(loss) for loss in history['val_loss']]
        },
        'timestamp': timestamp
    }
    
    with open(params_path, 'w') as f:
        json.dump(params_dict, f, indent=2)
    
    return model_path

# ç”¨äºåœ¨ä¼šè¯é—´ä¿å­˜æ¨¡å‹è®­ç»ƒçŠ¶æ€
if 'trained_models' not in st.session_state:
    st.session_state['trained_models'] = {}

# ç”¨äºä¿å­˜æ¨¡å‹è®­ç»ƒå†å²è®°å½•
if 'training_history' not in st.session_state:
    st.session_state['training_history'] = {}

# é¡µé¢åº•éƒ¨ - å¸®åŠ©ä¿¡æ¯
with st.expander("ä½¿ç”¨å¸®åŠ©"):
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜
    
    1. **æ•°æ®å‡†å¤‡**: åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢ä¸Šä¼ å¹¶å¤„ç†æ‚¨çš„æ•°æ®
    2. **ç‰¹å¾é€‰æ‹©**: é€‰æ‹©ç”¨äºè®­ç»ƒæ¨¡å‹çš„ç‰¹å¾
    3. **æ¨¡å‹å‚æ•°**: é…ç½®æ¨¡å‹çš„è¶…å‚æ•°
    4. **å¼€å§‹è®­ç»ƒ**: ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"æŒ‰é’®å¯åŠ¨è®­ç»ƒè¿‡ç¨‹
    5. **ä¿å­˜æ¨¡å‹**: è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä¿å­˜æ¨¡å‹ä»¥ä¾¿åç»­ä½¿ç”¨
    
    ### å‚æ•°è§£é‡Š
    
    #### LSTMå‚æ•°
    - **éšè—å±‚å¤§å°**: ç¥ç»ç½‘ç»œéšè—å±‚çš„èŠ‚ç‚¹æ•°é‡
    - **LSTMå±‚æ•°**: æ¨¡å‹ä¸­LSTMå±‚çš„æ•°é‡
    - **Dropoutæ¯”ä¾‹**: é˜²æ­¢è¿‡æ‹Ÿåˆçš„éšæœºä¸¢å¼ƒæ¯”ä¾‹
    - **å­¦ä¹ ç‡**: æ¢¯åº¦ä¸‹é™çš„æ­¥é•¿
    - **æ‰¹æ¬¡å¤§å°**: æ¯æ¬¡æ›´æ–°æƒé‡ä½¿ç”¨çš„æ ·æœ¬æ•°é‡
    - **è®­ç»ƒè½®æ•°**: å®Œæ•´æ•°æ®é›†çš„è®­ç»ƒæ¬¡æ•°
    
    #### ARIMAå‚æ•°
    - **p (ARé˜¶æ•°)**: è‡ªå›å½’é¡¹çš„é˜¶æ•°
    - **d (å·®åˆ†é˜¶æ•°)**: å·®åˆ†é˜¶æ•°ï¼Œä½¿åºåˆ—å¹³ç¨³
    - **q (MAé˜¶æ•°)**: ç§»åŠ¨å¹³å‡é¡¹çš„é˜¶æ•°
    """)

# å®é™…æ‰§è¡Œè®­ç»ƒçš„é€»è¾‘
if st.session_state.get('start_training', False) and not st.session_state.get('training_complete', False):
    # æ·»åŠ ç®€å•çš„çŠ¶æ€ä¿¡æ¯
    st.info("ğŸš€ æ­£åœ¨è®­ç»ƒLSTMæ¨¡å‹...")
    
    try:
        # å‡†å¤‡ç‰¹å¾æ•°æ®
        if 'selected_features' not in st.session_state or not st.session_state['selected_features']:
            st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ç”¨äºè®­ç»ƒ")
            st.session_state['start_training'] = False
            st.stop()
        
        # è·å–å½“å‰é€‰æ‹©çš„ç‰¹å¾
        selected_features = st.session_state['selected_features']
        
        # åˆ›å»ºUIå ä½ç¬¦
        progress_placeholder = st.empty()
        loss_chart_placeholder = st.empty()
        
        # å±•ç¤ºè®­ç»ƒè¿›åº¦UI
        with progress_placeholder.container():
            st.info("å‡†å¤‡è®­ç»ƒæ•°æ®...")
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        # ç¡®ä¿ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        if 'tech_indicators' in st.session_state and st.session_state['tech_indicators'] is not None:
            train_df = st.session_state['tech_indicators']
        else:
            st.error("æœªæ‰¾åˆ°æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œè¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡")
            st.session_state['start_training'] = False
            st.stop()
        
        # ç¡®ä¿æ‰€æœ‰é€‰å®šçš„ç‰¹å¾éƒ½åœ¨æ•°æ®ä¸­
        missing_features = [f for f in selected_features if f not in train_df.columns]
        if missing_features:
            st.error(f"ä»¥ä¸‹ç‰¹å¾åœ¨æ•°æ®ä¸­ä¸å­˜åœ¨: {missing_features}")
            st.session_state['start_training'] = False
            st.stop()
        
        # æå–é€‰å®šçš„ç‰¹å¾
        feature_data = train_df[selected_features].values
        
        # ç¡®ä¿Closeåˆ—å­˜åœ¨
        if 'Close' in train_df.columns:
            target_col = 'Close'
        else:
            target_col = train_df.columns[0]
            st.warning(f"æ•°æ®ä¸­æ²¡æœ‰'Close'åˆ—ï¼Œå°†ä½¿ç”¨'{target_col}'ä½œä¸ºç›®æ ‡å˜é‡")
        
        target_data = train_df[target_col].values.reshape(-1, 1)
        
        # æ•°æ®å½’ä¸€åŒ–
        feature_scaler = MinMaxScaler()
        target_scaler = MinMaxScaler()
        
        feature_data = feature_scaler.fit_transform(feature_data)
        target_data = target_scaler.fit_transform(target_data)
        
        # ä¿å­˜å½’ä¸€åŒ–å™¨ä»¥ä¾›åç»­é¢„æµ‹ä½¿ç”¨
        st.session_state['feature_scaler'] = feature_scaler
        st.session_state['target_scaler'] = target_scaler
        
        # è·å–è®­ç»ƒå‚æ•°
        sequence_length = st.session_state.get('sequence_length', 60)
        train_test_ratio = st.session_state.get('train_test_ratio', 0.7)
        
        # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
        combined_data = np.column_stack((feature_data, target_data))
        X, y = create_sequences(combined_data, int(sequence_length))
        
        # åˆ†ç¦»ç›®æ ‡å˜é‡
        X = X[:, :, :-1]  # ç§»é™¤æœ€åä¸€åˆ—ï¼ˆç›®æ ‡å˜é‡ï¼‰
        y = y[:, -1:]     # åªå–æœ€åä¸€åˆ—ï¼ˆç›®æ ‡å˜é‡ï¼‰
        
        # åˆ’åˆ†è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†
        total_samples = len(X)
        train_size = int(total_samples * train_test_ratio)
        val_size = int(total_samples * 0.15)  # å›ºå®š15%çš„éªŒè¯é›†
        
        X_train, y_train = X[:train_size], y[:train_size]
        X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]
        X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]
        
        status_text.text(f"æ•°æ®å‡†å¤‡å®Œæˆ! è®­ç»ƒé›†: {X_train.shape[0]}, éªŒè¯é›†: {X_val.shape[0]}, æµ‹è¯•é›†: {X_test.shape[0]}")
        
        # è·å–æ¨¡å‹è¶…å‚æ•°
        hidden_size = st.session_state.get('hidden_size', 32)
        num_layers = st.session_state.get('num_layers', 1)
        dropout = st.session_state.get('dropout', 0.3)
        learning_rate = st.session_state.get('learning_rate', 0.01)
        batch_size = st.session_state.get('batch_size', 512)
        epochs = st.session_state.get('epochs', 100)
        
        # è®¾ç½®æ¨¡å‹å‚æ•°
        model_params = {
            'input_dim': X_train.shape[2],  # ç‰¹å¾ç»´åº¦
            'hidden_dim': hidden_size,
            'num_layers': num_layers,
            'output_dim': y_train.shape[1],  # è¾“å‡ºç»´åº¦
            'dropout': dropout
        }
        
        # è®¾ç½®è®­ç»ƒå‚æ•°
        training_params = {
            'learning_rate': learning_rate,
            'batch_size': batch_size,
            'epochs': epochs
        }
        
        # è®­ç»ƒæ¨¡å‹
        status_text.text("å¼€å§‹è®­ç»ƒLSTMæ¨¡å‹...")
        
        # åˆ›å»ºæŸå¤±å›¾è¡¨çš„DataFrame
        loss_df = pd.DataFrame(columns=['è®­ç»ƒæŸå¤±', 'éªŒè¯æŸå¤±'])
        chart_area = loss_chart_placeholder.empty()
        
        # åˆ›å»ºæ¨¡å‹
        model = LSTMModel(
            input_dim=model_params['input_dim'],
            hidden_dim=model_params['hidden_dim'],
            num_layers=model_params['num_layers'],
            output_dim=model_params['output_dim'],
            dropout=model_params.get('dropout', 0.3)
        )
        
        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.MSELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=training_params['learning_rate'])
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        X_train_tensor = torch.FloatTensor(X_train)
        y_train_tensor = torch.FloatTensor(y_train)
        X_val_tensor = torch.FloatTensor(X_val)
        y_val_tensor = torch.FloatTensor(y_val)
        
        # è®­ç»ƒå†å²è®°å½•
        history = {
            'train_loss': [],
            'val_loss': []
        }
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            model.train()
            train_losses = []
            
            # å°æ‰¹é‡è®­ç»ƒ
            for i in range(0, len(X_train_tensor), batch_size):
                batch_X = X_train_tensor[i:i+batch_size]
                batch_y = y_train_tensor[i:i+batch_size]
                
                # å‰å‘ä¼ æ’­
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                
                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                train_losses.append(loss.item())
            
            # éªŒè¯
            model.eval()
            with torch.no_grad():
                val_outputs = model(X_val_tensor)
                val_loss = criterion(val_outputs, y_val_tensor)
                
            # è®°å½•è®­ç»ƒå’ŒéªŒè¯æŸå¤±
            avg_train_loss = sum(train_losses) / len(train_losses)
            history['train_loss'].append(avg_train_loss)
            history['val_loss'].append(val_loss.item())
            
            # æ›´æ–°æŸå¤±å›¾è¡¨
            loss_df.loc[epoch] = [avg_train_loss, val_loss.item()]
            with chart_area:
                st.line_chart(loss_df)
            
            # æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
            progress = (epoch + 1) / epochs
            progress_bar.progress(progress)
            status_text.text(f"Epoch {epoch+1}/{epochs}, è®­ç»ƒæŸå¤±: {avg_train_loss:.6f}, éªŒè¯æŸå¤±: {val_loss.item():.6f}")
        
        # è®­ç»ƒå®Œæˆ
        progress_bar.empty()
        status_text.text("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        
        # æµ‹è¯•é›†è¯„ä¼°
        model.eval()
        with torch.no_grad():
            X_test_tensor = torch.FloatTensor(X_test)
            y_test_tensor = torch.FloatTensor(y_test)
            
            test_outputs = model(X_test_tensor)
            test_loss = nn.MSELoss()(test_outputs, y_test_tensor)
            
            # åå½’ä¸€åŒ–é¢„æµ‹ç»“æœç”¨äºå±•ç¤º
            test_predictions = target_scaler.inverse_transform(test_outputs.numpy())
            test_actual = target_scaler.inverse_transform(y_test)
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            mse = np.mean((test_predictions - test_actual) ** 2)
            rmse = np.sqrt(mse)
            mae = np.mean(np.abs(test_predictions - test_actual))
            
            # æ›´æ–°è¯„ä¼°æŒ‡æ ‡
            st.session_state['model_metrics'] = {
                'MSE': float(mse),
                'RMSE': float(rmse),
                'MAE': float(mae)
            }
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        st.session_state['trained_model'] = model
        st.session_state['model_params'] = model_params
        st.session_state['training_params'] = training_params
        st.session_state['training_history'] = history
        st.session_state['X_test'] = X_test
        st.session_state['y_test'] = y_test
        st.session_state['seq_length'] = sequence_length
        
        # æ›´æ–°è®­ç»ƒçŠ¶æ€
        st.session_state['training_complete'] = True
        st.session_state['start_training'] = False
        
        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
        with st.container():
            st.success("ğŸ‰ æ¨¡å‹è®­ç»ƒå·²å®Œæˆ!")
            st.subheader("æ¨¡å‹è¯„ä¼°ç»“æœ")
            metrics = st.session_state['model_metrics']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric(label="MSE", value=f"{metrics['MSE']:.4f}")
            with col2:
                st.metric(label="RMSE", value=f"{metrics['RMSE']:.4f}")
            with col3:
                st.metric(label="MAE", value=f"{metrics['MAE']:.4f}")
        
        # åˆ·æ–°é¡µé¢ä»¥æ›´æ–°UIçŠ¶æ€
        st.rerun()
        
    except Exception as e:
        st.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        st.session_state['start_training'] = False