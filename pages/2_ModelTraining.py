"""
æ¨¡å‹è®­ç»ƒé¡µé¢
ç”¨äºé…ç½®å’Œè®­ç»ƒé¢„æµ‹æ¨¡å‹
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import seaborn as sns
import os
import json
from datetime import datetime
from pathlib import Path
import sys
import time
from streamlit_echarts import st_echarts
from statsmodels.tsa.arima.model import ARIMA
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = str(Path(__file__).parent.parent.parent)
if project_root not in sys.path:
    sys.path.append(project_root)

# æ·»åŠ arima
from src.models.arima_model import (
    check_stationarity,
    diff_series,
    check_white_noise,
    analyze_acf_pacf,
    find_best_arima_params,
    fit_arima_model,
    check_residuals,
    forecast_arima,
    evaluate_arima_model,
    inverse_diff,
    generate_descriptive_statistics,
    create_timeseries_chart,
    create_histogram_chart,
    create_qq_plot,
    create_acf_pacf_charts,
    check_acf_pacf_pattern,
    dynamic_forecast_arima,
    static_forecast_arima,
    calculate_direction_accuracy,
    run_multiple_arima_models,
    create_metrics_comparison_chart,
    create_metrics_statistics_table,
    prepare_arima_charts,
    calculate_statistics
)

# å¯¼å…¥LSTMç›¸å…³å‡½æ•°
from src.models.lstm_model import (
    save_model, 
    LSTMModel, 
    train_lstm_model, 
    evaluate_lstm_model, 
    plot_training_history, 
    create_sequences,
    run_lstm_training,
    select_features,
    create_correlation_bar_chart,
    create_significance_charts
)

# å¯¼å…¥å›¾è¡¨å·¥å…·å‡½æ•°
from src.utils.chart_utils import create_correlation_heatmap

# æ·»åŠ sessionç®¡ç†å‡½æ•°
try:
    from src.utils.session import get_state, set_state, update_states
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºç©ºå‡½æ•°
    def get_state(key, default=None):
        return st.session_state.get(key, default)
    
    def set_state(key, value):
        st.session_state[key] = value
        
    def update_states(updates):
        for key, value in updates.items():
            st.session_state[key] = value

# ä¿®å¤PyTorchä¸Streamlitçš„å…¼å®¹æ€§é—®é¢˜
torch.classes.__path__ = []

def create_lstm_prediction_chart(dates, actual_values, predictions, title="LSTMé¢„æµ‹ç»“æœå¯¹æ¯”"):
    """
    åˆ›å»ºLSTMé¢„æµ‹ç»“æœå¯¹æ¯”å›¾è¡¨
    
    å‚æ•°:
    dates: æ—¥æœŸåˆ—è¡¨
    actual_values: å®é™…å€¼
    predictions: é¢„æµ‹å€¼
    title: å›¾è¡¨æ ‡é¢˜
    
    è¿”å›:
    dict: EChartså›¾è¡¨é…ç½®
    """
    # ç¡®ä¿æ•°æ®æ˜¯PythonåŸç”Ÿç±»å‹
    actual_values = [float(x) for x in actual_values]
    predictions = [float(x) for x in predictions]
    
    option = {
        "title": {
            "text": title,
            "left": "center"
        },
        "tooltip": {
            "trigger": "axis",
            "axisPointer": {"type": "shadow"}
        },
        "legend": {
            "data": ["å®é™…å€¼", "LSTMé¢„æµ‹"],
            "top": "30px"
        },
        "grid": {
            "left": "3%",
            "right": "4%",
            "bottom": "3%",
            "containLabel": True
        },
        "toolbox": {
            "feature": {
                "saveAsImage": {}
            }
        },
        "xAxis": {
            "type": "category",
            "boundaryGap": False,
            "data": dates
        },
        "yAxis": {
            "type": "value",
            "scale": True,
            "splitLine": {
                "show": True
            }
        },
        "dataZoom": [
            {
                "type": "inside",
                "start": 0,
                "end": 100
            },
            {
                "start": 0,
                "end": 100
            }
        ],
        "series": [
            {
                "name": "å®é™…å€¼",
                "type": "line",
                "smooth": True,
                "data": actual_values,
                "showSymbol": False,
                "connectNulls": True
            },
            {
                "name": "LSTMé¢„æµ‹",
                "type": "line",
                "smooth": True,
                "data": predictions,
                "showSymbol": False,
                "connectNulls": True
            }
        ]
    }
    return option

def create_lstm_scatter_chart(actual_values, predictions, title="LSTMé¢„æµ‹æ•£ç‚¹å›¾"):
    """
    åˆ›å»ºLSTMé¢„æµ‹æ•£ç‚¹å›¾
    
    å‚æ•°:
    actual_values: å®é™…å€¼
    predictions: é¢„æµ‹å€¼
    title: å›¾è¡¨æ ‡é¢˜
    
    è¿”å›:
    dict: EChartså›¾è¡¨é…ç½®
    """
    # ç¡®ä¿æ•°æ®æ˜¯PythonåŸç”Ÿç±»å‹
    actual_values = [float(x) for x in actual_values]
    predictions = [float(x) for x in predictions]
    
    # è®¡ç®—RÂ²
    from sklearn.metrics import r2_score
    r2 = float(r2_score(actual_values, predictions))
    
    # åˆ›å»ºå¯¹è§’çº¿æ•°æ®ï¼ˆå®Œç¾é¢„æµ‹çº¿ï¼‰
    min_val = float(min(min(actual_values), min(predictions)))
    max_val = float(max(max(actual_values), max(predictions)))
    
    option = {
        "title": {
            "text": f"{title} (RÂ² = {r2:.3f})",
            "left": "center"
        },
        "tooltip": {
            "trigger": "item",
            "formatter": "å®é™…å€¼: {data[0]}<br/>é¢„æµ‹å€¼: {data[1]}"
        },
        "grid": {
            "left": "3%",
            "right": "4%",
            "bottom": "3%",
            "containLabel": True
        },
        "toolbox": {
            "feature": {
                "saveAsImage": {}
            }
        },
        "xAxis": {
            "type": "value",
            "name": "å®é™…å€¼",
            "min": min_val,
            "max": max_val
        },
        "yAxis": {
            "type": "value",
            "name": "é¢„æµ‹å€¼",
            "min": min_val,
            "max": max_val
        },
        "series": [
            {
                "type": "scatter",
                "data": [[float(actual_values[i]), float(predictions[i])] for i in range(len(actual_values))],
                "itemStyle": {"color": "#5470c6", "opacity": 0.6},
                "symbolSize": 6
            },
            {
                "type": "line",
                "data": [[min_val, min_val], [max_val, max_val]],
                "lineStyle": {"color": "#ee6666", "type": "dashed"},
                "symbol": "none",
                "name": "å®Œç¾é¢„æµ‹çº¿"
            }
        ]
    }
    return option

def prepare_lstm_charts(actual_values, predictions, dates):
    """
    å‡†å¤‡LSTMæ¨¡å‹çš„é¢„æµ‹ç»“æœå›¾è¡¨
    
    å‚æ•°:
    actual_values: å®é™…å€¼
    predictions: é¢„æµ‹å€¼
    dates: æ—¥æœŸåˆ—è¡¨
    
    è¿”å›:
    dict: åŒ…å«é¢„æµ‹ç»“æœå›¾è¡¨å’Œæ•£ç‚¹å›¾çš„å­—å…¸
    """
    prediction_chart = create_lstm_prediction_chart(dates, actual_values, predictions)
    scatter_chart = create_lstm_scatter_chart(actual_values, predictions)
    
    return {
        'prediction_chart': prediction_chart,
        'scatter_chart': scatter_chart
    }

def fix_datetime_for_arrow(df):
    """
    ä¿®å¤DataFrameä¸­çš„æ—¶é—´æˆ³æ•°æ®ä»¥å…¼å®¹PyArrow
    
    å‚æ•°:
        df (DataFrame): åŒ…å«æ—¶é—´æˆ³æ•°æ®çš„DataFrame
        
    è¿”å›:
        DataFrame: ä¿®å¤åçš„DataFrame
    """
    df_fixed = df.copy()
    
    # æ£€æŸ¥æ¯ä¸€åˆ—æ˜¯å¦åŒ…å«æ—¶é—´æˆ³æ•°æ®
    for col in df_fixed.columns:
        if df_fixed[col].dtype == 'datetime64[ns]':
            # å°†çº³ç§’ç²¾åº¦çš„æ—¶é—´æˆ³è½¬æ¢ä¸ºå¾®ç§’ç²¾åº¦
            df_fixed[col] = pd.to_datetime(df_fixed[col]).dt.floor('us')
        elif pd.api.types.is_datetime64_any_dtype(df_fixed[col]):
            # å¤„ç†å…¶ä»–æ—¶é—´æˆ³æ ¼å¼
            try:
                df_fixed[col] = pd.to_datetime(df_fixed[col]).dt.floor('us')
            except Exception as e:
                st.warning(f"åˆ— {col} çš„æ—¶é—´æˆ³è½¬æ¢å¤±è´¥: {e}")
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                df_fixed[col] = df_fixed[col].astype(str)
    
    return df_fixed

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨¡å‹è®­ç»ƒ",
    page_icon="ğŸ§ ",
    layout="wide"
)

# å¯¼å…¥PyTorch
import torch

# åˆå§‹åŒ–ARIMAç›¸å…³çš„session stateå˜é‡
if 'arima_model_metrics' not in st.session_state:
    st.session_state['arima_model_metrics'] = None
if 'arima_training_complete' not in st.session_state:
    st.session_state['arima_training_complete'] = False
if 'arima_model' not in st.session_state:
    st.session_state['arima_model'] = None
if 'arima_model_params' not in st.session_state:
    st.session_state['arima_model_params'] = None

# æ ‡é¢˜å’Œç®€ä»‹
st.title("æ¨¡å‹è®­ç»ƒ")
st.markdown("æœ¬é¡µé¢ç”¨äºé…ç½®å’Œè®­ç»ƒæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ã€‚é€‰æ‹©åˆé€‚çš„å‚æ•°å¹¶å¼€å§‹è®­ç»ƒè¿‡ç¨‹ã€‚")

# è·å–åŠ è½½çš„æ•°æ®
if 'raw_data' not in st.session_state:
    st.warning("è¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æ•°æ®")
    st.stop()

df = st.session_state['raw_data']
# æ£€æŸ¥dfæ˜¯å¦ä¸ºNone
if df is None:
    st.warning("æ•°æ®ä¸ºç©ºï¼Œè¯·åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢æ­£ç¡®åŠ è½½æ•°æ®")
    st.stop()
    
tech_indicators = None

# ä¾§è¾¹æ å†…å®¹ - æ•°æ®ç‰¹å¾ã€æ¨¡å‹ä¿¡æ¯
with st.sidebar:
    st.subheader("æ•°æ®å’Œç‰¹å¾")
    
    # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
    with st.expander("æ•°æ®ä¿¡æ¯", expanded=True):
        # å°†è®­ç»ƒé›†æ¯”ä¾‹è®¾ç½®æ”¾åœ¨æ¡ä»¶è¯­å¥å¤–éƒ¨ï¼Œç¡®ä¿å®ƒæ˜¯å…¨å±€å˜é‡
        train_test_ratio = st.slider(
            "è®­ç»ƒé›†æ¯”ä¾‹", 
            min_value=0.5, 
            max_value=0.9, 
            value=0.8, 
            step=0.05,
            help="è®­ç»ƒé›†å æ€»æ•°æ®çš„æ¯”ä¾‹"
        )
        
        if 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
            df = st.session_state['raw_data']
            st.info(f"æ•°æ®å½¢çŠ¶: {df.shape}")
            st.info(f"æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
        else:
            st.warning("æœªåŠ è½½æ•°æ®æˆ–æ•°æ®ä¸ºç©º")
    
    # åˆ é™¤åŸæ•°æ®åˆ’åˆ†è®¾ç½®éƒ¨åˆ†
        
    st.subheader("æ¨¡å‹ä¿¡æ¯")
    
    # æ¨¡å‹çŠ¶æ€ä¿¡æ¯
    with st.expander("è®­ç»ƒçŠ¶æ€", expanded=True):
        if 'training_complete' in st.session_state and st.session_state['training_complete']:
            # æ ¹æ®ä¸åŒçš„æ¨¡å‹ç±»å‹æ˜¾ç¤ºä¸åŒçš„è®­ç»ƒå®Œæˆä¿¡æ¯
            if 'arima_training_complete' in st.session_state and st.session_state['arima_training_complete']:
                if 'lstm_training_complete' in st.session_state and st.session_state['lstm_training_complete']:
                    st.success("LSTMå’ŒARIMAæ¨¡å‹å‡å·²è®­ç»ƒå®Œæˆ")
                else:
                    st.success("ARIMAæ¨¡å‹å·²è®­ç»ƒå®Œæˆ")
            else:
                st.success("LSTMæ¨¡å‹å·²è®­ç»ƒå®Œæˆ")
        elif 'start_training' in st.session_state and st.session_state['start_training']:
            st.info("LSTMæ¨¡å‹è®­ç»ƒä¸­...")
        elif 'arima_start_training' in st.session_state and st.session_state['arima_start_training']:
            st.info("ARIMAæ¨¡å‹è®­ç»ƒä¸­...")
        else:
            st.info("ç­‰å¾…å¼€å§‹è®­ç»ƒ...")
    
    # æ¨¡å‹ä¿å­˜é€‰é¡¹
    with st.expander("æ¨¡å‹ä¿å­˜", expanded=True):
        model_name = st.text_input(
            "æ¨¡å‹åç§°",
            value="my_model_v1"
        )
        
        save_model_button = st.button(
            "ä¿å­˜æ¨¡å‹",
            disabled=not ('training_complete' in st.session_state and st.session_state['training_complete'])
        )
        
        if save_model_button and 'trained_model' in st.session_state:
            model_path = save_model(
                st.session_state['trained_model'],
                st.session_state['model_params'],
                st.session_state['training_params'],
                st.session_state['training_history'],
                path=f"models/{model_name}"
            )
            st.success(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # æ¨¡å‹è¯„ä¼°ç®€æŠ¥
    with st.expander("æ¨¡å‹è¯„ä¼°ç®€æŠ¥", expanded=True):
        if 'model_metrics' in st.session_state and st.session_state.get('model_metrics') is not None:
            metrics = st.session_state['model_metrics']
            st.metric(
                label="MSE",
                value=f"{metrics.get('MSE', 0):.4f}"
            )
            
            st.metric(
                label="RMSE",
                value=f"{metrics.get('RMSE', 0):.4f}"
            )
            
            st.metric(
                label="MAE",
                value=f"{metrics.get('MAE', 0):.4f}"
            )
        elif 'start_training' in st.session_state and st.session_state['start_training']:
            st.info("æ¨¡å‹è¯„ä¼°ä¸­...")
        else:
            st.info("è®­ç»ƒæ¨¡å‹åå°†æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡")

# ä¸»è¦å†…å®¹åŒºåŸŸ

# æ¨¡å‹ç±»å‹é€‰æ‹©æ ‡ç­¾é¡µ
model_tabs = st.tabs(["LSTM", "ARIMA", "Prophet"])

# LSTMå‚æ•°è®¾ç½®
with model_tabs[0]:
    
    # ç‰¹å¾é€‰æ‹©éƒ¨åˆ† - æ·»åŠ åˆ°LSTMæ ‡ç­¾é¡µå†…
    st.markdown("### ç‰¹å¾é€‰æ‹©")
    
    # æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡æ•°æ®æ˜¯å¦å­˜åœ¨
    if 'raw_data' in st.session_state:
        if 'tech_indicators' in st.session_state:
            df = st.session_state['tech_indicators']  # ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        else:
            df = st.session_state['raw_data']  # å¦‚æœæ²¡æœ‰æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
        
        # ç¡®ä¿ä½¿ç”¨æ•°æ®ä¸­å®é™…å­˜åœ¨çš„åˆ—ä½œä¸ºç‰¹å¾åˆ—è¡¨
        all_features = df.columns.tolist()
        
        # åˆå§‹åŒ–selected_featuresçš„session state
        if 'selected_features' not in st.session_state:
            st.session_state['selected_features'] = all_features
        
        # 1. ç‰¹å¾ç­›é€‰å‚æ•°ï¼ˆé˜ˆå€¼é€‰æ‹©ï¼‰
        st.subheader("ç­›é€‰é˜ˆå€¼è®¾ç½®")
        lstm_feat_filter_col1, lstm_feat_filter_col2, lstm_feat_filter_col3 = st.columns(3)
        with lstm_feat_filter_col1:
            correlation_threshold = st.slider(
                "ç›¸å…³æ€§é˜ˆå€¼",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.05,
                help="ä¸ç›®æ ‡å˜é‡çš„æœ€å°ç›¸å…³ç³»æ•°"
            )
        with lstm_feat_filter_col2:
            vif_threshold = st.slider(
                "VIFé˜ˆå€¼",
                min_value=1.0,
                max_value=20.0,
                value=10.0,
                step=0.5,
                help="æ–¹å·®è†¨èƒ€å› å­çš„æœ€å¤§å…è®¸å€¼"
            )
        with lstm_feat_filter_col3:
            p_value_threshold = st.slider(
                "På€¼é˜ˆå€¼",
                min_value=0.0,
                max_value=0.1,
                value=0.05,
                step=0.01,
                help="ç»Ÿè®¡æ˜¾è‘—æ€§çš„æœ€å¤§å…è®¸på€¼"
            )

        # 2. ç‰¹å¾ç­›é€‰æŒ‰é’®å’Œç­›é€‰å®Œæˆæç¤ºæ¡†
        st.subheader("ç‰¹å¾ç­›é€‰")
        filter_col1, filter_col2 = st.columns([1,5])
        with filter_col1:
            if st.button("ç­›é€‰ç‰¹å¾", use_container_width=True):
                with st.spinner("æ­£åœ¨ç­›é€‰ç‰¹å¾..."):
                    # è°ƒç”¨select_featureså‡½æ•°å¹¶è·å–ç»“æœ
                    filter_results = select_features(
                    df,
                    correlation_threshold=correlation_threshold,
                    vif_threshold=vif_threshold,
                    p_value_threshold=p_value_threshold
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                    if 'error' in filter_results:
                        st.error(f"ç‰¹å¾é€‰æ‹©è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {filter_results['error']}")
                        st.code(filter_results['traceback'])
                        filtered_features = filter_results['selected_features']
                    else:
                        # ä»ç»“æœä¸­è·å–ç­›é€‰åçš„ç‰¹å¾åˆ—è¡¨
                        filtered_features = filter_results['selected_features']
                        
                        # ä¿å­˜ç­›é€‰å‚æ•°å’Œè¯¦ç»†ä¿¡æ¯åˆ°session state
                        st.session_state['feature_filter_params'] = {
                            'correlation_threshold': correlation_threshold,
                            'vif_threshold': vif_threshold,
                            'p_value_threshold': p_value_threshold
                        }
                        
                        st.session_state['feature_filter_results'] = filter_results
                        
                        # æ›´æ–°session stateä¸­çš„ç­›é€‰ç‰¹å¾
                        if filtered_features and len(filtered_features) > 0:
                            st.session_state['filtered_features'] = filtered_features
                            # åŒæ—¶æ›´æ–°é€‰æ‹©çš„ç‰¹å¾ï¼Œä½¿ç•Œé¢ä¸Šçš„å¤šé€‰æ¡†ä¹Ÿæ›´æ–°
                            st.session_state['selected_features'] = filtered_features
                            # æ ‡è®°å·²ç»å®Œæˆç­›é€‰
                            st.session_state['filter_applied'] = True
                        else:
                            st.error("ç‰¹å¾ç­›é€‰å¤±è´¥ï¼Œå°†ä½¿ç”¨æ‰€æœ‰ç‰¹å¾")
                            st.session_state['filtered_features'] = all_features
                            st.session_state['selected_features'] = all_features
                            st.session_state['filter_applied'] = False
        
        with filter_col2:
            # åœ¨UIä¸Šæ˜¾ç¤ºæœ€ç»ˆç­›é€‰ç»“æœï¼ˆåœ¨ç­›é€‰å®Œæˆåæ˜¾ç¤ºï¼‰
            if 'filter_applied' in st.session_state and st.session_state['filter_applied'] and 'feature_filter_results' in st.session_state:
                filter_results = st.session_state['feature_filter_results']
                filtered_features = filter_results['selected_features']
                st.success(f"ç‰¹å¾ç­›é€‰å®Œæˆï¼ä» {df.shape[1]} ä¸ªç‰¹å¾ä¸­é€‰å‡º {len(filtered_features)} ä¸ªç‰¹å¾ï¼š{filtered_features}")
        
        # 3. ç‰¹å¾é€‰æ‹©å¤šé€‰æ¡†ï¼Œä½¿ç”¨session stateä¸­çš„ç‰¹å¾ä½œä¸ºé»˜è®¤å€¼
        st.subheader("é€‰æ‹©è®­ç»ƒç‰¹å¾")
        selected_features = st.multiselect(
            "é€‰æ‹©ç”¨äºè®­ç»ƒçš„ç‰¹å¾",
            options=all_features,
            default=st.session_state['selected_features']
        )
        
        # æ›´æ–°selected_featuresçš„session state
        st.session_state['selected_features'] = selected_features
        
        # 4. ä¸‰ä¸ªå±•å¼€æ¡†ï¼Œæ˜¾ç¤ºé€æ­¥ç­›é€‰çš„ç»“æœ
        st.subheader("ç­›é€‰è¯¦ç»†ç»“æœ")
        
        # 1. ç›¸å…³æ€§ç­›é€‰å±•å¼€æ¡†
        with st.expander("**ç›¸å…³æ€§ç­›é€‰**", expanded=False):
            if 'feature_filter_results' not in st.session_state or not st.session_state.get('filter_applied', False):
                st.warning("è¯·å…ˆè¿›è¡Œç­›é€‰")
            else:
                filter_results = st.session_state['feature_filter_results']
                correlation_threshold = st.session_state['feature_filter_params']['correlation_threshold']
                
                # ç›¸å…³æ€§æ•°æ®è¡¨æ ¼
                corr_data = filter_results['correlation']['data']
                high_correlation_features = filter_results['correlation']['features']
                corr_matrix = filter_results['correlation']['matrix']
                
                # æ˜¾ç¤ºç›¸å…³æ€§æ•°æ®è¡¨æ ¼
                st.dataframe(corr_data, hide_index=True)
                
                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œä½¿æŒ‰é’®å’Œæç¤ºä¿¡æ¯å¤„äºåŒä¸€è¡Œ
                btn_col, info_col = st.columns([1, 5])
                
                # æ·»åŠ æ˜¾ç¤º/éšè—çƒ­åŠ›å›¾çš„æŒ‰é’®
                with btn_col:
                    show_corr_heatmap = st.button("æ˜¾ç¤º/éšè—ç›¸å…³æ€§çƒ­åŠ›å›¾", key="toggle_corr_heatmap")
                
                # åœ¨å³ä¾§åˆ—æ˜¾ç¤ºç›¸å…³ä¿¡æ¯
                with info_col:
                    if not high_correlation_features:
                        st.warning("æœªæ‰¾åˆ°ç¬¦åˆç›¸å…³æ€§é˜ˆå€¼çš„ç‰¹å¾ï¼Œå°†æ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾çš„ç›¸å…³æ€§çƒ­åŠ›å›¾")
                    else:
                        st.success(f"ç›¸å…³æ€§ç­›é€‰å‡ºçš„ç‰¹å¾ (|ç›¸å…³æ€§| > {correlation_threshold}): {high_correlation_features}")
                
                # åˆå§‹åŒ–session stateä¸­çš„çƒ­åŠ›å›¾æ˜¾ç¤ºçŠ¶æ€
                if 'show_corr_heatmap' not in st.session_state:
                    st.session_state['show_corr_heatmap'] = False
                
                # åˆ‡æ¢æ˜¾ç¤ºçŠ¶æ€
                if show_corr_heatmap:
                    st.session_state['show_corr_heatmap'] = not st.session_state['show_corr_heatmap']
                
                # æ ¹æ®æ˜¾ç¤ºçŠ¶æ€æ¸²æŸ“çƒ­åŠ›å›¾
                if st.session_state['show_corr_heatmap']:
                    try:
                        # æ˜¾ç¤ºç‰¹å¾é—´ç›¸å…³æ€§çƒ­åŠ›å›¾
                        st.write("ç‰¹å¾é—´ç›¸å…³æ€§çƒ­åŠ›å›¾")
                        
                        # ä½¿ç”¨ç»Ÿä¸€çš„çƒ­åŠ›å›¾å‡½æ•°
                        if not high_correlation_features:
                            # å¦‚æœæ²¡æœ‰ç­›é€‰ç‰¹å¾ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾çš„çƒ­åŠ›å›¾
                            correlation_heatmap_option = create_correlation_heatmap(corr_matrix)
                        else:
                            # æ˜¾ç¤ºç­›é€‰åç‰¹å¾çš„çƒ­åŠ›å›¾
                            correlation_heatmap_option = create_correlation_heatmap(corr_matrix, high_correlation_features)
                        
                        # ç¡®ä¿çƒ­åŠ›å›¾é…ç½®æ˜¯æœ‰æ•ˆçš„dictionary
                        if correlation_heatmap_option is None or not isinstance(correlation_heatmap_option, dict):
                            st.error("ç”Ÿæˆçƒ­åŠ›å›¾é…ç½®å¤±è´¥")
                        else:
                            # æ˜¾ç¤ºçƒ­åŠ›å›¾
                            st_echarts(
                                options=correlation_heatmap_option,
                                height="400px",
                                width="100%",
                                key="corr_heatmap"
                            )
                    except Exception as e:
                        st.error(f"çƒ­åŠ›å›¾æ¸²æŸ“å‡ºé”™: {str(e)}")
                        st.code(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
                
        
        # 2. VIFç­›é€‰å±•å¼€æ¡†
        with st.expander("**VIFç­›é€‰**", expanded=False):
            if 'feature_filter_results' not in st.session_state or not st.session_state.get('filter_applied', False):
                st.warning("è¯·å…ˆè¿›è¡Œç­›é€‰")
            else:
                filter_results = st.session_state['feature_filter_results']
                vif_threshold = st.session_state['feature_filter_params']['vif_threshold']
                
                vif_data = filter_results['vif']['data']
                low_vif_features = filter_results['vif']['features']
                vif_warnings = filter_results['vif']['warnings']
                collinear_features = filter_results['vif']['collinear_features']
                
                # æ”¶é›†æ‰€æœ‰è­¦å‘Šä¿¡æ¯
                warning_messages = []
                if collinear_features:
                    warning_messages.append(f"- ä»¥ä¸‹ç‰¹å¾å­˜åœ¨å®Œå…¨å…±çº¿æ€§æˆ–VIFå€¼å¼‚å¸¸å¤§ï¼š{', '.join(collinear_features)}")
                warning_messages.extend([f"- {warning}" for warning in vif_warnings])
                
                # å¦‚æœæœ‰è­¦å‘Šä¿¡æ¯ï¼Œæ˜¾ç¤ºåœ¨ä¸€ä¸ªwarningæ¡†ä¸­
                if warning_messages:
                    st.warning("VIFåˆ†æè¿‡ç¨‹ä¸­å‘ç°ä»¥ä¸‹é—®é¢˜ï¼š\n" + "\n".join(warning_messages))
                
                # æ£€æŸ¥vif_dataæ˜¯å¦ä¸ºç©º
                if not vif_data.empty:
                    # æ˜¾ç¤ºVIFæ•°æ®è¡¨æ ¼
                    st.dataframe(vif_data, hide_index=True)
                    st.success(f"VIFä½äº{vif_threshold}çš„ç‰¹å¾: {low_vif_features}")

                else:
                    st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡ŒVIFè®¡ç®—æˆ–å¤šé‡å…±çº¿æ€§åˆ†æ")
        
        # 3. ç»Ÿè®¡æ˜¾è‘—æ€§ç­›é€‰å±•å¼€æ¡†
        with st.expander("**ç»Ÿè®¡æ˜¾è‘—æ€§ç­›é€‰**", expanded=False):
            if 'feature_filter_results' not in st.session_state or not st.session_state.get('filter_applied', False):
                st.warning("è¯·å…ˆè¿›è¡Œç­›é€‰")
            else:
                filter_results = st.session_state['feature_filter_results']
                p_value_threshold = st.session_state['feature_filter_params']['p_value_threshold']
                
                sig_data = filter_results['significance']['data']
                significant_features = filter_results['significance']['features']
                
                if not sig_data.empty:
                    # æ˜¾ç¤ºç»Ÿè®¡æ˜¾è‘—æ€§æ•°æ®è¡¨æ ¼
                    st.dataframe(sig_data, hide_index=True)
                    
                    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œä½¿æŒ‰é’®å’Œæç¤ºä¿¡æ¯å¤„äºåŒä¸€è¡Œ
                    p_btn_col, p_info_col = st.columns([1, 7])
                    
                    # æ·»åŠ æ˜¾ç¤º/éšè—På€¼å›¾çš„æŒ‰é’®
                    with p_btn_col:
                        show_p_value_chart = st.button("æ˜¾ç¤º/éšè—På€¼å›¾è¡¨", key="toggle_p_value_chart")
                    
                    # åœ¨å³ä¾§åˆ—æ˜¾ç¤ºç›¸å…³ä¿¡æ¯
                    with p_info_col:
                        if p_value_threshold > 0:
                            st.success(f"På€¼ä½äº{p_value_threshold}çš„ç‰¹å¾: {significant_features}")
                    
                    # åˆå§‹åŒ–session stateä¸­çš„På€¼å›¾æ˜¾ç¤ºçŠ¶æ€
                    if 'show_p_value_chart' not in st.session_state:
                        st.session_state['show_p_value_chart'] = False
                    
                    # åˆ‡æ¢æ˜¾ç¤ºçŠ¶æ€
                    if show_p_value_chart:
                        st.session_state['show_p_value_chart'] = not st.session_state['show_p_value_chart']
                    
                    # æ ¹æ®æ˜¾ç¤ºçŠ¶æ€æ¸²æŸ“På€¼å›¾
                    if st.session_state['show_p_value_chart']:
                        # ä¿®æ”¹ä¸ºåªæ¥æ”¶å’Œæ¸²æŸ“på€¼å›¾è¡¨
                        _, p_value_option = create_significance_charts(sig_data, p_value_threshold)
                        st_echarts(
                            options=p_value_option, 
                            height="200px",
                            width="100%",
                            key="p_value_chart"
                        )
                else:
                    st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ")
        
    # æ¨¡å‹å‚æ•°è®¾ç½®
    st.markdown("### æ¨¡å‹å‚æ•°")
    
    # æ¨¡å‹å‚æ•°è®¾å®šéƒ¨åˆ†
    lstm_params_first_col, lstm_params_second_col, lstm_params_third_col, lstm_params_fourth_col = st.columns(4)
    
    with lstm_params_first_col:
        sequence_length = st.number_input(
            "è¾“å…¥åºåˆ—é•¿åº¦",
            min_value=1,
            max_value=100,
            value=20,
            help="ç”¨äºé¢„æµ‹çš„å†å²æ•°æ®ç‚¹æ•°é‡"
        )
        hidden_size = st.number_input(
            "éšè—å±‚å¤§å°",
            min_value=1,
            max_value=512,
            value=64
        )
        
    with lstm_params_second_col:
        prediction_length = st.number_input(
            "é¢„æµ‹åºåˆ—é•¿åº¦",
            min_value=1,
            max_value=30,
            value=1,
            help="éœ€è¦é¢„æµ‹çš„æœªæ¥æ•°æ®ç‚¹æ•°é‡"
        )
        num_layers = st.number_input(
            "LSTMå±‚æ•°",
            min_value=1,
            max_value=5,
            value=2
        )
        
    with lstm_params_third_col:
        epochs = st.number_input(
            "è®­ç»ƒè½®æ•°",
            min_value=1,
            max_value=1000,
            value=100
        )
        learning_rate = st.number_input(
            "å­¦ä¹ ç‡",
            min_value=0.0001,
            max_value=0.1,
            value=0.001,
            format="%.4f"
        )
        
    with lstm_params_fourth_col:
        batch_size = st.number_input(
            "æ‰¹æ¬¡å¤§å°",
            min_value=1,
            max_value=256,
            value=32
        )
        dropout = st.slider(
            "Dropoutæ¯”ä¾‹",
            min_value=0.0,
            max_value=0.9,
            value=0.2,
            step=0.1
        )
        
    
    # è®­ç»ƒæ§åˆ¶
    st.markdown("### è®­ç»ƒæ§åˆ¶")
    
    lstm_train_btn_col, lstm_early_stop_col = st.columns([3, 1])
    with lstm_train_btn_col:
        if st.button(
            "å¼€å§‹è®­ç»ƒ",
            use_container_width=True
        ):
            st.session_state['start_training'] = True
        else:
            st.session_state['start_training'] = False
        
    with lstm_early_stop_col:
        enable_early_stopping = st.checkbox(
            "å¯ç”¨æ—©åœ",
            value=True
        )
    
    # è®­ç»ƒå†å²ä¸è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    st.markdown("### è®­ç»ƒè¿›åº¦ä¸å†å²")
    
    # è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    progress_placeholder = st.empty()
    
    # è®­ç»ƒå†å²å›¾è¡¨æ˜¾ç¤ºåŒºåŸŸ
    loss_chart_container = st.container()
    with loss_chart_container:
        st.subheader("è®­ç»ƒæŸå¤±æ›²çº¿")
        loss_chart_placeholder = st.empty()
        
        # åªåœ¨éè®­ç»ƒçŠ¶æ€ä¸‹æ˜¾ç¤ºå†å²è®­ç»ƒæ•°æ®
        if not st.session_state.get('start_training', False):
            # å¦‚æœä¼šè¯ä¸­å·²æœ‰è®­ç»ƒå†å²ï¼Œæ˜¾ç¤ºè®­ç»ƒå†å²å›¾è¡¨
            if 'training_history' in st.session_state:
                # æ£€æŸ¥è®­ç»ƒå†å²æ˜¯å¦åŒ…å«å¿…è¦çš„æ•°æ®
                history = st.session_state['training_history']
                if isinstance(history, dict) and 'train_loss' in history and 'val_loss' in history:
                    # ç»˜åˆ¶å·²æœ‰çš„æŸå¤±æ›²çº¿
                    history_df = pd.DataFrame({
                        'è®­ç»ƒæŸå¤±': history['train_loss'],
                        'éªŒè¯æŸå¤±': history['val_loss']
                    })
                    st.line_chart(history_df)
                    st.info(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {history['train_loss'][-1]:.4f}, éªŒè¯æŸå¤±: {history['val_loss'][-1]:.4f}")
                else:
                    st.info("æ²¡æœ‰å¯æ˜¾ç¤ºçš„è®­ç»ƒå†å²æ•°æ®")
    
    # æ·»åŠ LSTMè®­ç»ƒç»“æœæ˜¾ç¤ºåŒºåŸŸçš„å ä½ç¬¦
    lstm_metrics_placeholder = st.empty()
    lstm_prediction_chart_placeholder = st.empty()
    lstm_scatter_chart_placeholder = st.empty()
    
    if 'start_training' in st.session_state and st.session_state['start_training']:
        # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
        with progress_placeholder.container():
            st.info("è®­ç»ƒè¿‡ç¨‹å°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        # æ¸…ç©ºå¹¶åˆå§‹åŒ–æŸå¤±å›¾è¡¨
        with loss_chart_placeholder:
            # ä¸´æ—¶æ•°æ®ç”¨äºç¤ºä¾‹ï¼Œå®é™…è®­ç»ƒä¸­ä¼šè¢«åŠ¨æ€æ›´æ–°
            chart_data = pd.DataFrame(
                np.random.randn(20, 2),
                columns=['è®­ç»ƒæŸå¤±', 'éªŒè¯æŸå¤±']
            )
            st.line_chart(chart_data)
    
    # æ˜¾ç¤ºLSTMè®­ç»ƒç»“æœ
    if 'lstm_training_complete' in st.session_state and st.session_state['lstm_training_complete']:
        st.success("LSTMæ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡
        if 'model_metrics' in st.session_state and st.session_state['model_metrics']:
            metrics = st.session_state['model_metrics']
            
            with lstm_metrics_placeholder.container():
                st.subheader("LSTMæ¨¡å‹è¯„ä¼°æŒ‡æ ‡")
                metric_cols = st.columns(4)
                with metric_cols[0]:
                    st.metric("MSE", f"{metrics.get('MSE', 0):.4f}")
                with metric_cols[1]:
                    st.metric("RMSE", f"{metrics.get('RMSE', 0):.4f}")
                with metric_cols[2]:
                    st.metric("MAE", f"{metrics.get('MAE', 0):.4f}")
                with metric_cols[3]:
                    st.metric("æ–¹å‘å‡†ç¡®ç‡", f"{metrics.get('Direction_Accuracy', 0):.4f}")
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœå›¾è¡¨
        if ('lstm_test_predictions' in st.session_state and 
            'y_test' in st.session_state and 
            'raw_data' in st.session_state):
            
            try:
                # è·å–é¢„æµ‹æ•°æ®å’ŒçœŸå®æ•°æ®
                lstm_pred = st.session_state['lstm_test_predictions']
                
                # å…³é”®ä¿®å¤ï¼šä½¿ç”¨ä¸ARIMAå®Œå…¨ä¸€è‡´çš„æ•°æ®åˆ’åˆ†æ–¹å¼è·å–å®é™…å€¼
                df = st.session_state['raw_data']
                train_test_ratio = st.session_state.get('train_test_ratio', 0.8)
                
                # è·å–ç›®æ ‡åˆ—ï¼ˆé€šå¸¸æ˜¯Closeï¼‰
                target_column = 'Close'  # é»˜è®¤ä½¿ç”¨Closeåˆ—
                if 'selected_features' in st.session_state:
                    selected_features = st.session_state['selected_features']
                    # å¦‚æœCloseåœ¨é€‰æ‹©çš„ç‰¹å¾ä¸­ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾
                    if 'Close' in selected_features:
                        target_column = 'Close'
                    elif selected_features:
                        target_column = selected_features[0]
                
                # ä½¿ç”¨ä¸ARIMAå®Œå…¨ä¸€è‡´çš„æ•°æ®åˆ’åˆ†æ–¹å¼
                train_size = int(len(df) * train_test_ratio)
                test_actual_values = df[target_column].iloc[train_size:].values
                
                # ç¡®ä¿é¢„æµ‹æ•°æ®æ ¼å¼æ­£ç¡®
                if hasattr(lstm_pred, 'flatten'):
                    lstm_pred = lstm_pred.flatten()
                else:
                    lstm_pred = np.array(lstm_pred).flatten()
                
                # ç°åœ¨LSTMæµ‹è¯•é›†åº”è¯¥ä¸ARIMAæµ‹è¯•é›†å¤§å°ä¸€è‡´
                # ä½†ç”±äºåºåˆ—åˆ›å»ºï¼ŒLSTMé¢„æµ‹æ•°é‡å¯èƒ½ä»ç„¶å°‘äºåŸå§‹æµ‹è¯•é›†
                if len(lstm_pred) < len(test_actual_values):
                    # æˆªå–å¯¹åº”é•¿åº¦çš„å®é™…å€¼ï¼Œä»æµ‹è¯•é›†æœ«å°¾å¼€å§‹
                    # è¿™æ ·ç¡®ä¿ä½¿ç”¨çš„æ˜¯æœ€æ–°çš„æ•°æ®ç‚¹
                    test_actual_values = test_actual_values[-len(lstm_pred):]
                    st.info(f"ğŸ“Š LSTMé¢„æµ‹{len(lstm_pred)}ä¸ªç‚¹ï¼Œä½¿ç”¨æµ‹è¯•é›†æœ€å{len(lstm_pred)}ä¸ªå®é™…å€¼è¿›è¡Œå¯¹æ¯”")
                elif len(lstm_pred) > len(test_actual_values):
                    # å¦‚æœLSTMé¢„æµ‹ç‚¹æ•°å¤šäºå®é™…å€¼ï¼Œæˆªå–LSTMé¢„æµ‹
                    lstm_pred = lstm_pred[:len(test_actual_values)]
                    st.info(f"ğŸ“Š æˆªå–LSTMé¢„æµ‹åˆ°{len(test_actual_values)}ä¸ªç‚¹ä»¥åŒ¹é…æµ‹è¯•é›†å¤§å°")
                else:
                    st.info(f"ğŸ“Š LSTMé¢„æµ‹ä¸æµ‹è¯•é›†å¤§å°å®Œå…¨ä¸€è‡´ï¼š{len(lstm_pred)}ä¸ªæ•°æ®ç‚¹")
                
                # ç”Ÿæˆæ—¥æœŸåºåˆ—
                if 'Date' in df.columns:
                    # è·å–å¯¹åº”æµ‹è¯•é›†çš„æ—¥æœŸï¼Œä½¿ç”¨ä¸å®é™…å€¼å¯¹åº”çš„æ—¥æœŸ
                    test_start_idx = train_size + (len(test_actual_values) - len(lstm_pred)) if len(lstm_pred) < len(test_actual_values) else train_size
                    test_dates = df['Date'].iloc[test_start_idx:test_start_idx+len(lstm_pred)].dt.strftime('%Y-%m-%d').tolist()
                    dates = test_dates
                else:
                    dates = [f"Day {i}" for i in range(len(lstm_pred))]
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯å±•å¼€æ¡†
                with st.expander("ğŸ”§ LSTMæ•°æ®å¤„ç†ä¿¡æ¯", expanded=False):
                    st.markdown("**æ•°æ®æ¥æº:**")
                    st.success(f"âœ… å®é™…å€¼: ä½¿ç”¨åŸå§‹æ•°æ®ä¸­çš„{target_column}åˆ—")
                    st.success(f"âœ… é¢„æµ‹å€¼: ä½¿ç”¨è®­ç»ƒåçš„LSTMæ¨¡å‹é¢„æµ‹ç»“æœ")
                    
                    st.markdown("**æ•°æ®ç»Ÿè®¡:**")
                    st.write(f"- åŸå§‹æ•°æ®æ€»é•¿åº¦: {len(df)} ä¸ªæ•°æ®ç‚¹")
                    st.write(f"- è®­ç»ƒé›†å¤§å°: {train_size} ä¸ªæ•°æ®ç‚¹")
                    st.write(f"- æµ‹è¯•é›†å¤§å°: {len(df) - train_size} ä¸ªæ•°æ®ç‚¹")
                    st.write(f"- LSTMé¢„æµ‹æ•°é‡: {len(lstm_pred)} ä¸ªæ•°æ®ç‚¹")
                    st.write(f"- å®é™…å€¼èŒƒå›´: {test_actual_values.min():.2f} - {test_actual_values.max():.2f}")
                    st.write(f"- é¢„æµ‹å€¼èŒƒå›´: {lstm_pred.min():.2f} - {lstm_pred.max():.2f}")
                    st.write(f"- æ—¥æœŸèŒƒå›´: {dates[0]} åˆ° {dates[-1]}")
                    
                    st.markdown("**æ•°æ®å¤„ç†:**")
                    st.success("âœ… ä½¿ç”¨ä¸ARIMAå®Œå…¨ä¸€è‡´çš„æ•°æ®åˆ’åˆ†æ–¹å¼")
                    st.success("âœ… é¢„æµ‹å€¼å·²è¿›è¡Œåå½’ä¸€åŒ–å¤„ç†")
                
                # ä½¿ç”¨ç»Ÿä¸€çš„å›¾è¡¨åˆ›å»ºå‡½æ•°ç”Ÿæˆå›¾è¡¨é…ç½®
                charts = prepare_lstm_charts(test_actual_values, lstm_pred, dates)
                
                # ä¿å­˜å›¾è¡¨é…ç½®åˆ°session stateï¼ˆä¸ARIMAä¿æŒä¸€è‡´ï¼‰
                st.session_state['lstm_prediction_chart'] = charts['prediction_chart']
                st.session_state['lstm_scatter_chart'] = charts['scatter_chart']
                
                # æ˜¾ç¤ºé¢„æµ‹å¯¹æ¯”å›¾è¡¨
                with lstm_prediction_chart_placeholder.container():
                    st.subheader("LSTMé¢„æµ‹ç»“æœå¯¹æ¯”")
                    st_echarts(options=st.session_state['lstm_prediction_chart'], height="500px")
                
                # æ˜¾ç¤ºæ•£ç‚¹å›¾
                with lstm_scatter_chart_placeholder.container():
                    st.subheader("LSTMé¢„æµ‹æ•£ç‚¹å›¾")
                    st_echarts(options=st.session_state['lstm_scatter_chart'], height="400px")
                
                # æ·»åŠ è¯¯å·®åˆ†æå›¾è¡¨
                st.subheader("LSTMè¯¯å·®åˆ†æ")
                error_col1, error_col2 = st.columns(2)
                
                with error_col1:
                    # è¯¯å·®æ—¶é—´åºåˆ—å›¾
                    errors = test_actual_values - lstm_pred
                    
                    error_time_option = {
                        "title": {
                            "text": "é¢„æµ‹è¯¯å·®æ—¶é—´åºåˆ—",
                            "left": "center",
                            "textStyle": {"fontSize": 14}
                        },
                        "tooltip": {"trigger": "axis"},
                        "xAxis": {
                            "type": "category",
                            "data": dates,
                            "axisLabel": {"rotate": 45}
                        },
                        "yAxis": {
                            "type": "value",
                            "name": "è¯¯å·®"
                        },
                        "series": [{
                            "type": "line",
                            "data": [float(x) for x in errors],
                            "lineStyle": {"color": "#ee6666", "width": 1},
                            "symbol": "none"
                        }],
                        "dataZoom": [{
                            "type": "slider",
                            "start": 0,
                            "end": 100
                        }]
                    }
                    
                    st_echarts(options=error_time_option, height="300px")
                
                with error_col2:
                    # è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
                    hist, bin_edges = np.histogram(errors, bins=20)
                    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
                    
                    error_hist_option = {
                        "title": {
                            "text": "é¢„æµ‹è¯¯å·®åˆ†å¸ƒ",
                            "left": "center",
                            "textStyle": {"fontSize": 14}
                        },
                        "tooltip": {"trigger": "axis"},
                        "xAxis": {
                            "type": "category",
                            "data": [f"{float(x):.3f}" for x in bin_centers],
                            "name": "è¯¯å·®å€¼"
                        },
                        "yAxis": {
                            "type": "value",
                            "name": "é¢‘æ¬¡"
                        },
                        "series": [{
                            "type": "bar",
                            "data": [int(x) for x in hist],
                            "itemStyle": {"color": "#73c0de"}
                        }]
                    }
                    
                    st_echarts(options=error_hist_option, height="300px")
                
                # æ·»åŠ è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
                st.subheader("LSTMè¯¦ç»†æ€§èƒ½ç»Ÿè®¡")
                stats_col1, stats_col2, stats_col3 = st.columns(3)
                
                with stats_col1:
                    st.metric("å¹³å‡è¯¯å·®", f"{np.mean(errors):.4f}")
                    st.metric("è¯¯å·®æ ‡å‡†å·®", f"{np.std(errors):.4f}")
                
                with stats_col2:
                    st.metric("æœ€å¤§æ­£è¯¯å·®", f"{np.max(errors):.4f}")
                    st.metric("æœ€å¤§è´Ÿè¯¯å·®", f"{np.min(errors):.4f}")
                
                with stats_col3:
                    # è®¡ç®—MAPE
                    mape = np.mean(np.abs((test_actual_values - lstm_pred) / test_actual_values)) * 100
                    st.metric("MAPE (%)", f"{mape:.2f}")
                    
                    # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡
                    if len(test_actual_values) > 1:
                        actual_direction = np.sign(test_actual_values[1:] - test_actual_values[:-1])
                        pred_direction = np.sign(lstm_pred[1:] - lstm_pred[:-1])
                        direction_accuracy = np.mean(actual_direction == pred_direction) * 100
                        st.metric("æ–¹å‘å‡†ç¡®ç‡ (%)", f"{direction_accuracy:.2f}")
                
                # æ·»åŠ æ¨¡å‹ä¿¡æ¯å±•å¼€æ¡†
                with st.expander("LSTMæ¨¡å‹è¯¦ç»†ä¿¡æ¯", expanded=False):
                    if 'model_params' in st.session_state and st.session_state['model_params']:
                        model_params = st.session_state['model_params']
                        st.markdown("**æ¨¡å‹å‚æ•°:**")
                        for key, value in model_params.items():
                            st.write(f"- {key}: {value}")
                    
                    if 'training_params' in st.session_state and st.session_state['training_params']:
                        training_params = st.session_state['training_params']
                        st.markdown("**è®­ç»ƒå‚æ•°:**")
                        for key, value in training_params.items():
                            st.write(f"- {key}: {value}")
                    
                    if 'selected_features' in st.session_state:
                        selected_features = st.session_state['selected_features']
                        st.markdown("**ä½¿ç”¨çš„ç‰¹å¾:**")
                        st.write(", ".join(selected_features))
                    
                    # æ˜¾ç¤ºè®­ç»ƒå†å²æ‘˜è¦
                    if 'training_history' in st.session_state:
                        history = st.session_state['training_history']
                        if isinstance(history, dict) and 'train_loss' in history:
                            st.markdown("**è®­ç»ƒå†å²æ‘˜è¦:**")
                            st.write(f"- è®­ç»ƒè½®æ•°: {len(history['train_loss'])}")
                            st.write(f"- æœ€ç»ˆè®­ç»ƒæŸå¤±: {history['train_loss'][-1]:.6f}")
                            if 'val_loss' in history:
                                st.write(f"- æœ€ç»ˆéªŒè¯æŸå¤±: {history['val_loss'][-1]:.6f}")
                    
            except Exception as e:
                st.error(f"æ˜¾ç¤ºLSTMé¢„æµ‹å›¾è¡¨æ—¶å‡ºé”™: {e}")
                import traceback
                st.code(traceback.format_exc())

# ARIMAå‚æ•°è®¾ç½®
with model_tabs[1]:       
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–ARIMAç›¸å…³çŠ¶æ€
    if 'arima_processed' not in st.session_state:
        st.session_state['arima_processed'] = True
    
    # æ·»åŠ æ•°æ®é¢„å¤„ç†éƒ¨åˆ†
    st.markdown("#### æ•°æ®é¢„å¤„ç†")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸ºæ§åˆ¶åŒºåŸŸï¼Œå³ä¾§ä¸ºæ•°æ®å›¾è¡¨
    arima_controls_col, arima_charts_col = st.columns([1, 2])
    
    with arima_controls_col:
        # å˜é‡é€‰æ‹©æ¡†
        if 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
            df = st.session_state['raw_data']
            
            # è·å–æ‰€æœ‰åˆ—åï¼Œæ’é™¤æ—¥æœŸç±»å‹çš„åˆ—
            all_columns = []
            date_columns = []
            
            for col in df.columns:
                if pd.api.types.is_datetime64_any_dtype(df[col]):
                    date_columns.append(col)
                else:
                    all_columns.append(col)
            
            # å¦‚æœæ‰€æœ‰åˆ—éƒ½è¢«æ’é™¤ï¼Œç»™å‡ºè­¦å‘Š
            if not all_columns:
                st.error("æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨äºåˆ†æçš„éæ—¥æœŸç±»å‹åˆ—")
                st.stop()
                
            # å°è¯•é»˜è®¤é€‰æ‹©"Close"åˆ—ï¼Œå¦‚æœå­˜åœ¨çš„è¯
            default_index = 0
            if 'Close' in all_columns:
                default_index = all_columns.index('Close')
                
            # å˜é‡é€‰æ‹©æ¡†
            selected_var = st.selectbox(
                "é€‰æ‹©éœ€è¦åˆ†æçš„å˜é‡",
                options=all_columns,
                index=default_index,
                key="arima_selected_var"
            )
            
            # è·å–æ‰€é€‰å˜é‡çš„æ•°æ®
            selected_data = df[selected_var]
            
            # æ£€æŸ¥æ•°æ®ç±»å‹ï¼Œå¤„ç†æ—¥æœŸæ—¶é—´ç±»å‹
            is_datetime = pd.api.types.is_datetime64_any_dtype(selected_data)
            is_numeric = pd.api.types.is_numeric_dtype(selected_data)
            
            if is_datetime:
                st.warning(f"é€‰æ‹©çš„å˜é‡ '{selected_var}' æ˜¯æ—¥æœŸæ—¶é—´ç±»å‹ï¼Œå°†è½¬æ¢ä¸ºæ—¶é—´æˆ³åè¿›è¡Œåˆ†æ")
                # å°†æ—¥æœŸæ—¶é—´è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆæµ®ç‚¹æ•°ï¼‰
                selected_data = (selected_data - pd.Timestamp("1970-01-01")) // pd.Timedelta("1s")
                # æ˜¾ç¤ºè½¬æ¢åçš„æ•°æ®ç±»å‹
                st.info(f"è½¬æ¢åçš„æ•°æ®ç±»å‹: {selected_data.dtype}")
            elif not is_numeric:
                st.error(f"é€‰æ‹©çš„å˜é‡ '{selected_var}' ä¸æ˜¯æ•°å€¼ç±»å‹ï¼Œæ— æ³•è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æ")
                st.stop()
            
            # æ•°æ®å¤„ç†æ–¹æ³•é€‰æ‹©
            transform_method = st.radio(
                "æ•°æ®å¤„ç†æ–¹æ³•",
                options=["åŸå§‹æ•°æ®", "å¯¹æ•°å˜æ¢", "ä¸€é˜¶å·®åˆ†", "ä¸€é˜¶å¯¹æ•°å·®åˆ†"],
                index=0,
                key="arima_transform_method"
            )
            
            # è‡ªåŠ¨è®¾ç½®å¤„ç†æ ‡å¿—
            st.session_state['arima_processed'] = True
            
            # é¦–æ¬¡åŠ è½½é¡µé¢æ—¶ï¼Œç¡®ä¿å·²ç»åˆå§‹åŒ–å¤„ç†æ•°æ®
            if 'arima_processed_data' not in st.session_state:
                # é»˜è®¤ä½¿ç”¨æ‰€é€‰å˜é‡çš„åŸå§‹æ•°æ®
                st.session_state['arima_processed_data'] = selected_data
                st.session_state['arima_transform_title'] = "åŸå§‹æ•°æ®"
            
            # æ•°æ®å¤„ç†å’Œå¯è§†åŒ–åŒºåŸŸ
            if 'arima_processed' in st.session_state and st.session_state['arima_processed']:
                # æ ¹æ®é€‰æ‹©çš„æ–¹æ³•è¿›è¡Œæ•°æ®å¤„ç†
                if transform_method == "åŸå§‹æ•°æ®":
                    processed_data = selected_data
                    transform_title = "åŸå§‹æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                    
                elif transform_method == "å¯¹æ•°å˜æ¢":
                    # æ£€æŸ¥æ˜¯å¦æœ‰éæ­£å€¼
                    if (selected_data <= 0).any():
                        st.warning("æ•°æ®åŒ…å«éæ­£å€¼ï¼Œæ— æ³•è¿›è¡Œå¯¹æ•°å˜æ¢")
                        processed_data = selected_data
                        transform_title = "åŸå§‹æ•°æ®"
                    else:
                        processed_data = np.log(selected_data)
                        transform_title = "å¯¹æ•°å˜æ¢åçš„æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                    
                elif transform_method == "ä¸€é˜¶å·®åˆ†":
                    diff_data, _ = diff_series(selected_data, diff_order=1, log_diff=False)
                    processed_data = diff_data
                    transform_title = "ä¸€é˜¶å·®åˆ†åçš„æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                    
                elif transform_method == "ä¸€é˜¶å¯¹æ•°å·®åˆ†":
                    # æ£€æŸ¥æ˜¯å¦æœ‰éæ­£å€¼
                    if (selected_data <= 0).any():
                        st.warning("æ•°æ®åŒ…å«éæ­£å€¼ï¼Œæ— æ³•è¿›è¡Œå¯¹æ•°å·®åˆ†")
                        processed_data = selected_data
                        transform_title = "åŸå§‹æ•°æ®"
                    else:
                        diff_data, _ = diff_series(selected_data, diff_order=1, log_diff=True)
                        processed_data = diff_data
                        transform_title = "ä¸€é˜¶å¯¹æ•°å·®åˆ†åçš„æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                
                # å¹³ç¨³æ€§æ£€éªŒç»“æœå±•å¼€æ¡†
                with st.expander("ADFå¹³ç¨³æ€§æ£€éªŒç»“æœ", expanded=True):
                    
                    st.metric(
                        label="ADFç»Ÿè®¡é‡",
                        value=f"{stationarity_results['ADFç»Ÿè®¡é‡']:.2f}"
                    )
                    st.metric(
                        label="på€¼",
                        value=f" {stationarity_results['på€¼']:.2f}"
                    )

                    # æ ¹æ®på€¼åˆ¤æ–­æ˜¯å¦å¹³ç¨³
                    if is_stationary:
                        st.success("å¹³ç¨³çš„ (på€¼ < 0.05)")
                    else:
                        st.warning("ä¸å¹³ç¨³ (på€¼ >= 0.05)")
                
                # æ­£æ€æ€§æ£€éªŒç»“æœå±•å¼€æ¡†
                with st.expander("æ­£æ€æ€§æ£€éªŒç»“æœ", expanded=True):
                    # æ‰§è¡Œæ­£æ€æ€§æ£€éªŒ (ä½¿ç”¨scipyçš„statsæ¨¡å—)
                    from scipy import stats
                    
                    # è¿›è¡ŒShapiro-Wilkæ£€éªŒ
                    if len(processed_data) < 5000:  # Shapiro-Wilké€‚ç”¨äºå°æ ·æœ¬
                        stat, p_value = stats.shapiro(processed_data.dropna())
                        test_name = "Shapiro-Wilkæ£€éªŒ"
                    else:  # å¤§æ ·æœ¬ä½¿ç”¨K-Sæ£€éªŒ
                        stat, p_value = stats.kstest(processed_data.dropna(), 'norm')
                        test_name = "Kolmogorov-Smirnovæ£€éªŒ"

                    st.metric(
                        label=f"{test_name}ç»Ÿè®¡é‡",
                        value=f"{stat:.2f}"
                    )
                    st.metric(
                        label="på€¼",
                        value=f"{p_value:.2f}"
                    )

                    # æ ¹æ®på€¼åˆ¤æ–­æ˜¯å¦ç¬¦åˆæ­£æ€åˆ†å¸ƒ
                    if p_value < 0.05:
                        st.warning(f"ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒ (på€¼ < 0.05)")
                    else:
                        st.success(f"ç¬¦åˆæ­£æ€åˆ†å¸ƒ (på€¼ >= 0.05)")
                
                # ç™½å™ªå£°æ£€éªŒç»“æœå±•å¼€æ¡†
                with st.expander("Ljung-Boxç™½å™ªå£°æ£€éªŒç»“æœ", expanded=True):
                    # æ‰§è¡Œç™½å™ªå£°æ£€éªŒ
                    try:
                        lb_df, is_white_noise = check_white_noise(processed_data.dropna())
                        
                        # æ˜¾ç¤ºç»“æœ
                                                
                        # ç¬¬ä¸€ä¸ªæ»åé˜¶æ•°çš„Qç»Ÿè®¡é‡å’Œpå€¼
                        first_lag_q = lb_df.iloc[0]['Qç»Ÿè®¡é‡']
                        first_lag_p = lb_df.iloc[0]['på€¼']
                        
                        st.metric(
                            label="Qç»Ÿè®¡é‡ (æ»åé˜¶æ•°=1)",
                            value=f"{first_lag_q:.2f}"
                        )
                        st.metric(
                            label="på€¼ (æ»åé˜¶æ•°=1)",
                            value=f"{first_lag_p:.2f}"
                        )
                        
                        # æ ¹æ®på€¼åˆ¤æ–­æ˜¯å¦ä¸ºç™½å™ªå£°
                        if is_white_noise:
                            st.success("åºåˆ—ä¸ºç™½å™ªå£° (på€¼ > 0.05)")
                        else:
                            st.warning("åºåˆ—ä¸æ˜¯ç™½å™ªå£° (på€¼ < 0.05)")
                    except Exception as e:
                        st.error(f"æ— æ³•æ‰§è¡Œç™½å™ªå£°æ£€éªŒ: {str(e)}")
                
                # æ·»åŠ è‡ªç›¸å…³æ£€æµ‹ç»“æœå±•å¼€æ¡†
                with st.expander("è‡ªç›¸å…³æ£€æµ‹ç»“æœ", expanded=True):
                    # æ‰§è¡Œè‡ªç›¸å…³æ£€æµ‹
                    try:
                        acf_pacf_pattern = check_acf_pacf_pattern(processed_data.dropna(), lags=30)
                        
                        # æ˜¾ç¤ºACFç»“æœ
                        acf_pattern = acf_pacf_pattern["acf"]["pattern"]
                        acf_cutoff = acf_pacf_pattern["acf"]["cutoff"]
                        
                        if acf_pattern == "æˆªå°¾":
                            st.success(f"ACFå‡½æ•°{acf_cutoff}é˜¶æˆªå°¾")
                        else:
                            st.info("ACFå‡½æ•°æ‹–å°¾")
                        
                        # æ˜¾ç¤ºPACFç»“æœ
                        pacf_pattern = acf_pacf_pattern["pacf"]["pattern"]
                        pacf_cutoff = acf_pacf_pattern["pacf"]["cutoff"]
                        
                        if pacf_pattern == "æˆªå°¾":
                            st.success(f"PACFå‡½æ•°{pacf_cutoff}é˜¶æˆªå°¾")
                        else:
                            st.info("PACFå‡½æ•°æ‹–å°¾")
                        
                        # æ˜¾ç¤ºæ¨¡å‹å»ºè®®
                        st.info(f"æ¨¡å‹å»ºè®®: {acf_pacf_pattern['model_suggestion']}")
                        
                    except Exception as e:
                        st.error(f"æ— æ³•æ‰§è¡Œè‡ªç›¸å…³æ£€æµ‹: {str(e)}")
                
                # ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°ä¼šè¯çŠ¶æ€
                st.session_state['arima_processed_data'] = processed_data
                st.session_state['arima_transform_title'] = transform_title
                st.session_state['arima_processed'] = True

            else:
                st.warning("è¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æ•°æ®")
    
    with arima_charts_col:
        # æ•°æ®å›¾è¡¨æ˜¾ç¤ºåŒºåŸŸ
        if 'arima_processed' in st.session_state and st.session_state['arima_processed']:
            if 'arima_processed_data' in st.session_state:
                # è·å–å¤„ç†åçš„æ•°æ®å’Œæ ‡é¢˜
                processed_data = st.session_state['arima_processed_data']
                transform_title = st.session_state['arima_transform_title']
                
                # åˆ›å»ºæŠ˜çº¿å›¾
                try:
                    # åˆ›å»ºåŒ…å«ç´¢å¼•çš„æ•°æ®æ¡†ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ—¥æœŸ
                    if transform_method in ["ä¸€é˜¶å·®åˆ†", "ä¸€é˜¶å¯¹æ•°å·®åˆ†"]:
                        # å¯¹äºå·®åˆ†æ•°æ®ï¼Œéœ€è¦æ³¨æ„æ—¥æœŸç´¢å¼•çš„å¤„ç†
                        # å·®åˆ†ä¼šå‡å°‘æ•°æ®ç‚¹ï¼Œæ‰€ä»¥éœ€è¦è·³è¿‡åŸå§‹æ•°æ®çš„å‰å‡ ä¸ªç‚¹
                        diff_order = 1  # é»˜è®¤ä¸ºä¸€é˜¶å·®åˆ†
                        
                        # åˆ›å»ºä¸å¤„ç†åæ•°æ®é•¿åº¦ç›¸åŒçš„ç´¢å¼•
                        if isinstance(df.index, pd.DatetimeIndex):
                            # ä¿®å¤ï¼šç¡®ä¿æ•°æ®ä¸æ—¥æœŸæ­£ç¡®åŒ¹é…ï¼Œè€Œä¸æ˜¯åå‘
                            # ä½¿ç”¨æ—¥æœŸç´¢å¼•ï¼Œä½†è¦ç¡®ä¿é¡ºåºä¸€è‡´
                            sorted_df = df.sort_index()
                            # å·®åˆ†åæ•°æ®é•¿åº¦ä¼šå‡å°‘ï¼Œæ‰€ä»¥ä½¿ç”¨åé¢çš„æ—¥æœŸç´¢å¼•å¯¹åº”å·®åˆ†æ•°æ®
                            time_series_df = pd.DataFrame({
                                transform_title: processed_data.values
                            }, index=sorted_df.index[diff_order:diff_order+len(processed_data)])
                        else:
                            # å¦‚æœæ²¡æœ‰æ—¥æœŸç´¢å¼•ï¼Œå°è¯•ä»dfä¸­è·å–æ—¥æœŸåˆ—
                            if 'Date' in df.columns:
                                sorted_df = df.sort_values('Date')
                                time_series_df = pd.DataFrame({
                                    transform_title: processed_data.values
                                }, index=sorted_df['Date'].values[diff_order:diff_order+len(processed_data)])
                            else:
                                # å¦‚æœæ²¡æœ‰Dateåˆ—ï¼Œä½¿ç”¨é»˜è®¤ç´¢å¼•
                                time_series_df = pd.DataFrame({transform_title: processed_data})
                    else:
                        # å¯¹äºåŸå§‹æ•°æ®æˆ–å¯¹æ•°å˜æ¢ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹ç´¢å¼•
                        if isinstance(df.index, pd.DatetimeIndex):
                            # ä¿®å¤ï¼šç¡®ä¿æ•°æ®ä¸æ—¥æœŸæ­£ç¡®åŒ¹é…ï¼Œè€Œä¸æ˜¯åå‘
                            sorted_df = df.sort_index()
                            # ä½¿ç”¨ä¸å¤„ç†åæ•°æ®ç›¸åŒé•¿åº¦çš„ç´¢å¼•
                            time_series_df = pd.DataFrame({
                                transform_title: processed_data.values
                            }, index=sorted_df.index[:len(processed_data)])
                        else:
                            # å¦‚æœæ²¡æœ‰æ—¥æœŸç´¢å¼•ï¼Œå°è¯•ä»dfä¸­è·å–æ—¥æœŸåˆ—
                            if 'Date' in df.columns:
                                sorted_df = df.sort_values('Date')
                                time_series_df = pd.DataFrame({
                                    transform_title: processed_data.values
                                }, index=sorted_df['Date'].values[:len(processed_data)])
                            else:
                                # å¦‚æœæ²¡æœ‰Dateåˆ—ï¼Œä½¿ç”¨é»˜è®¤ç´¢å¼•
                                time_series_df = pd.DataFrame({transform_title: processed_data})
                    
                    # åˆ›å»ºæ—¶é—´åºåˆ—å›¾
                    timeseries_option = create_timeseries_chart(
                        time_series_df,
                        title=f"{selected_var} - {transform_title}"
                    )
                    st_echarts(options=timeseries_option, height="400px", key=f"timeseries_{selected_var}_{transform_method}")
                except Exception as e:
                    st.error(f"æ— æ³•ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾: {str(e)}")
                
                # åˆ›å»ºç›´æ–¹å›¾
                try:
                    histogram_option = create_histogram_chart(
                        processed_data,
                        title=f"{selected_var} - åˆ†å¸ƒç›´æ–¹å›¾"
                    )
                    st_echarts(options=histogram_option, height="400px", key=f"histogram_{selected_var}_{transform_method}")
                except Exception as e:
                    st.error(f"æ— æ³•ç»˜åˆ¶åˆ†å¸ƒç›´æ–¹å›¾: {str(e)}")
                
                # åˆ›å»ºQQå›¾
                try:
                    qq_option = create_qq_plot(
                        processed_data,
                        title=f"{selected_var} - QQå›¾"
                    )
                    st_echarts(options=qq_option, height="450px", key=f"qqplot_{selected_var}_{transform_method}")
                except Exception as e:
                    st.warning(f"æ— æ³•ç»˜åˆ¶QQå›¾: {str(e)}")
                
                # QQå›¾åæ·»åŠ è‡ªç›¸å…³å’Œåè‡ªç›¸å…³å›¾
                try:
                    # åˆ›å»ºè‡ªç›¸å…³å›¾å’Œåè‡ªç›¸å…³å›¾
                    acf_option, pacf_option = create_acf_pacf_charts(
                        processed_data,
                        lags=30,  # è®¾ç½®æœ€å¤§æ»åé˜¶æ•°ä¸º30
                        title_prefix=f"{selected_var}"
                    )
                    
                    # åˆ†ä¸¤åˆ—æ˜¾ç¤ºACFå’ŒPACF
                    acf_col, pacf_col = st.columns(2)
                    
                    with acf_col:
                        st_echarts(options=acf_option, height="200px", key=f"acf_{selected_var}_{transform_method}")
                    
                    with pacf_col:
                        st_echarts(options=pacf_option, height="200px", key=f"pacf_{selected_var}_{transform_method}")
                        
                except Exception as e:
                    st.warning(f"æ— æ³•ç»˜åˆ¶è‡ªç›¸å…³å’Œåè‡ªç›¸å…³å›¾: {str(e)}")
                    

            else:
                st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©å˜é‡å’Œæ•°æ®å¤„ç†æ–¹æ³•")
        else:
            st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©å˜é‡å’Œæ•°æ®å¤„ç†æ–¹æ³•")
    
    # æ·»åŠ æè¿°æ€§ç»Ÿè®¡è¡¨æ ¼
    st.markdown("### æè¿°æ€§ç»Ÿè®¡")
    
    # ä¿å­˜æ‰€æœ‰æ•°æ®åºåˆ—
    series_data = {}
    
    # åŸå§‹æ•°æ®åºåˆ—
    if selected_var in df.columns:
        original_series = df[selected_var]
        original_series.name = f"{selected_var}_åŸå§‹æ•°æ®"
        series_data["åŸå§‹æ•°æ®"] = original_series
        
        # å¯¹æ•°å˜æ¢åºåˆ—
        if (original_series > 0).all():
            log_series = np.log(original_series)
            log_series.name = f"{selected_var}_å¯¹æ•°å˜æ¢"
            series_data["å¯¹æ•°å˜æ¢"] = log_series
        
        # ä¸€é˜¶å·®åˆ†åºåˆ—
        diff_series_data, _ = diff_series(original_series, diff_order=1, log_diff=False)
        diff_series_data.name = f"{selected_var}_ä¸€é˜¶å·®åˆ†"
        series_data["ä¸€é˜¶å·®åˆ†"] = diff_series_data
        
        # ä¸€é˜¶å¯¹æ•°å·®åˆ†åºåˆ—
        if (original_series > 0).all():
            log_diff_series, _ = diff_series(original_series, diff_order=1, log_diff=True)
            log_diff_series.name = f"{selected_var}_ä¸€é˜¶å¯¹æ•°å·®åˆ†"
            series_data["ä¸€é˜¶å¯¹æ•°å·®åˆ†"] = log_diff_series
    
    # ç”Ÿæˆæ‰€æœ‰åºåˆ—çš„æè¿°æ€§ç»Ÿè®¡è¡¨
    all_stats_dfs = []
    jb_stats = {}
    
    for name, series in series_data.items():
        try:
            stats_df, normality_test = generate_descriptive_statistics(series)
            stats_df['VARIABLES'] = [name]  # æ›¿æ¢ä¸ºåºåˆ—åç§°
            all_stats_dfs.append(stats_df)
            jb_stats[name] = {
                'JBç»Ÿè®¡é‡': normality_test['statistic'],
                'på€¼': normality_test['p_value'],
                'æ˜¯å¦æ­£æ€': "æ˜¯" if normality_test['is_normal'] else "å¦"
            }
        except Exception as e:
            st.warning(f"æ— æ³•è®¡ç®— {name} çš„æè¿°æ€§ç»Ÿè®¡: {str(e)}")
    
    # åˆå¹¶æ‰€æœ‰ç»Ÿè®¡è¡¨
    if all_stats_dfs:
        combined_stats_df = pd.concat(all_stats_dfs, ignore_index=True)
        
        # è¡¨æ ¼æ ¼å¼åŒ–: ä¿ç•™å°æ•°ç‚¹ä½æ•°ä¸º3ä½
        format_cols = ['mean', 'p50', 'sd', 'min', 'max', 'skewness', 'kurtosis']
        for col in format_cols:
            if col in combined_stats_df.columns:
                combined_stats_df[col] = combined_stats_df[col].apply(
                    lambda x: f"{x:.3f}" if pd.notnull(x) else "N/A"
                )
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåºä»¥æé«˜å¯è¯»æ€§
        ordered_cols = ['VARIABLES', 'N', 'mean', 'p50', 'sd', 'min', 'max', 'skewness', 'kurtosis']
        ordered_cols = [col for col in ordered_cols if col in combined_stats_df.columns]
        combined_stats_df = combined_stats_df[ordered_cols]
        
        # è®¾ç½®VARIABLESåˆ—ä¸ºç´¢å¼•ï¼Œä½¿è¡¨æ ¼æ›´æ¸…æ™°
        combined_stats_df = combined_stats_df.set_index('VARIABLES')
        
        # ä½¿ç”¨st.tableè€Œä¸æ˜¯st.dataframeï¼Œä»¥è·å¾—æ›´å¥½çš„é™æ€è¡¨æ ¼å±•ç¤º
        st.table(combined_stats_df)
    else:
        st.warning("æ— æ³•ç”Ÿæˆæè¿°æ€§ç»Ÿè®¡è¡¨")
    
    # ç„¶åæ˜¯åŸæ¥çš„ARIMAå‚æ•°è®¾ç½®éƒ¨åˆ†
    st.markdown("### ARIMAæ¨¡å‹å‚æ•°")
    
    # æ·»åŠ æœ€ä¼˜å‚æ•°æ£€æµ‹æ§ä»¶
    st.markdown("#### è‡ªåŠ¨å‚æ•°ä¼˜åŒ–")
    
    # åˆ›å»ºç¬¬ä¸€è¡Œæ§ä»¶ï¼šä¿¡æ¯å‡†åˆ™å’Œæœ€å¤§é˜¶æ•°è®¾ç½®
    criterion_col, max_p_col, max_d_col, max_q_col = st.columns(4)
    
    with criterion_col:
        criterion = st.selectbox(
            "ä¿¡æ¯å‡†åˆ™",
            options=["aic", "bic"],
            index=1,
            help="AICï¼ˆèµ¤æ± ä¿¡æ¯å‡†åˆ™ï¼‰æˆ–BICï¼ˆè´å¶æ–¯ä¿¡æ¯å‡†åˆ™ï¼‰"
        )
    
    with max_p_col:
        max_p = st.number_input(
            "æœ€å¤§ARé˜¶æ•°",
            min_value=0,
            max_value=10,
            value=3,
            help="æœç´¢èŒƒå›´ï¼š0 åˆ°è®¾å®šå€¼"
        )
    
    with max_d_col:
        max_d = st.number_input(
            "æœ€å¤§å·®åˆ†é˜¶æ•°",
            min_value=0,
            max_value=2,
            value=2,
            help="æœç´¢èŒƒå›´ï¼š0 åˆ°è®¾å®šå€¼"
        )
    
    with max_q_col:
        max_q = st.number_input(
            "æœ€å¤§MAé˜¶æ•°",
            min_value=0,
            max_value=10,
            value=3,
            help="æœç´¢èŒƒå›´ï¼š0 åˆ°è®¾å®šå€¼"
        )
    
    # åˆ›å»ºç¬¬äºŒè¡Œï¼šä¼˜åŒ–æŒ‰é’®å’Œç»“æœæ˜¾ç¤º
    opt_btn_col, opt_result_col = st.columns([1, 3])
    
    with opt_btn_col:
        optimize_button = st.button(
            "è‡ªåŠ¨æ£€æµ‹æœ€ä¼˜å‚æ•°",
            help="éå†å¯èƒ½çš„å‚æ•°ç»„åˆæ‰¾åˆ°æœ€ä¼˜ARIMAå‚æ•°",
            use_container_width=True
        )
    
    with opt_result_col:
        if optimize_button:
            try:
                with st.spinner("æ­£åœ¨æœç´¢æœ€ä¼˜å‚æ•°..."):
                    # è·å–å½“å‰å¤„ç†åçš„æ•°æ®
                    if 'arima_processed_data' in st.session_state:
                        processed_data = st.session_state['arima_processed_data']
                        # è°ƒç”¨find_best_arima_paramså‡½æ•°
                        best_params = find_best_arima_params(
                            processed_data,
                            p_range=range(0, max_p + 1),
                            d_range=range(0, max_d + 1),
                            q_range=range(0, max_q + 1),
                            criterion=criterion
                        )
                        
                        # æ›´æ–°session stateä¸­çš„æœ€ä¼˜å‚æ•°
                        st.session_state['best_arima_params'] = best_params
                        
                        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                        st.success(f"æ‰¾åˆ°æœ€ä¼˜å‚æ•°ï¼šp={best_params[0]}, d={best_params[1]}, q={best_params[2]}")
                    else:
                        st.error("è¯·å…ˆé€‰æ‹©æ•°æ®å’Œå¤„ç†æ–¹æ³•")
            except Exception as e:
                st.error(f"å‚æ•°ä¼˜åŒ–å¤±è´¥ï¼š{str(e)}")
    
    st.markdown("#### æ¨¡å‹å‚æ•°è®¾ç½®")
    # æ·»åŠ ä¸€ä¸ªæŒ‰é’®ï¼Œç”¨äºæ˜¾ç¤ºARIMAæ¨¡å‹å‚æ•°çš„è¯´æ˜
    arima_params_forecast_col, arima_params_ar_col, arima_params_d_col, arima_params_ma_col = st.columns([1,1,1,1])
    
    with arima_params_forecast_col:
        forecast_method = st.selectbox(
            "é¢„æµ‹æ–¹æ³•",
            options=["åŠ¨æ€é¢„æµ‹", "é™æ€é¢„æµ‹"],
            index=0,
            help="åŠ¨æ€é¢„æµ‹ï¼šä½¿ç”¨ä¹‹å‰çš„é¢„æµ‹å€¼è¿›è¡Œåç»­é¢„æµ‹\né™æ€é¢„æµ‹ï¼šä½¿ç”¨å®é™…å†å²å€¼è¿›è¡Œé¢„æµ‹"
        )
        # ä¿å­˜é¢„æµ‹æ–¹æ³•åˆ°session_state
        st.session_state['arima_forecast_method'] = forecast_method

        # è¿è¡Œæ¬¡æ•°é€‰æ‹©
        run_count = st.number_input(
            "è¿è¡Œæ¬¡æ•°",
            min_value=1,
            max_value=50,
            value=1,
            help="è®¾ç½®ARIMAæ¨¡å‹è¿è¡Œçš„æ¬¡æ•°ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºç§å­ã€‚è®¾ç½®ä¸º1æ—¶æ‰§è¡Œå•æ¬¡è®­ç»ƒï¼Œå¤§äº1æ—¶å°†æ‰§è¡Œå¤šæ¬¡è®­ç»ƒå¹¶è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹"
        )
    
    with arima_params_ar_col:
        # å¦‚æœæœ‰æœ€ä¼˜å‚æ•°ï¼Œä½¿ç”¨å®ƒä½œä¸ºé»˜è®¤å€¼
        default_p = st.session_state.get('best_arima_params', (2, 1, 2))[0] if 'best_arima_params' in st.session_state else 2
        p_param = st.number_input(
            "p (ARé˜¶æ•°)",
            min_value=0,
            max_value=10,
            value=default_p
        )

        # æ¯”è¾ƒæŒ‡æ ‡é€‰æ‹©ï¼ˆä»…åœ¨è¿è¡Œæ¬¡æ•°>1æ—¶æ˜¾ç¤ºï¼‰
        if run_count > 1:
            comparison_metric = st.selectbox(
                "æ¯”è¾ƒæŒ‡æ ‡",
                options=["MSE", "RMSE", "MAE", "Direction_Accuracy"],
                index=0,
                help="é€‰æ‹©ç”¨äºæ¨¡å‹æ¯”è¾ƒçš„æŒ‡æ ‡ï¼ˆä»…é€‚ç”¨äºå¤šæ¬¡è¿è¡Œï¼‰"
        )
    
    with arima_params_d_col:
        default_d = st.session_state.get('best_arima_params', (2, 1, 2))[1] if 'best_arima_params' in st.session_state else 1
        d_param = st.number_input(
            "d (å·®åˆ†é˜¶æ•°)",
            min_value=0,
            max_value=2,
            value=default_d
        )
        
        # ç»Ÿä¸€çš„è®­ç»ƒæŒ‰é’®
        arima_train_button = st.button(
            "å¼€å§‹è®­ç»ƒARIMAæ¨¡å‹",
            help="è®­ç»ƒARIMAæ¨¡å‹ï¼Œè‡ªåŠ¨å¤„ç†å•æ¬¡æˆ–å¤šæ¬¡è®­ç»ƒ",
            use_container_width=True,
            key="arima_train_button"
        )
    
    with arima_params_ma_col:
        default_q = st.session_state.get('best_arima_params', (2, 1, 2))[2] if 'best_arima_params' in st.session_state else 2
        q_param = st.number_input(
            "q (MAé˜¶æ•°)",
            min_value=0,
            max_value=10,
            value=default_q
        )

    
    # æ·»åŠ é¢„å…ˆåˆ›å»ºçš„å ä½ç¬¦ç”¨äºè®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾ç¤º
    arima_progress_placeholder = st.empty()
    arima_chart_placeholder = st.empty()
    
    # æ·»åŠ å¤šæ¬¡è¿è¡Œç»“æœçš„å ä½ç¬¦
    multi_run_results_placeholder = st.empty()
    multi_run_charts_placeholder = st.empty()
    
    # æ£€æŸ¥æ˜¯å¦ç‚¹å‡»äº†è®­ç»ƒæŒ‰é’®
    if arima_train_button:
        # ä¿å­˜å½“å‰å‚æ•°åˆ°session_stateä»¥ä¾¿åœ¨é¡µé¢åˆ·æ–°åä¿æŒ
        st.session_state['arima_p_param'] = p_param
        st.session_state['arima_d_param'] = d_param
        st.session_state['arima_q_param'] = q_param
        st.session_state['arima_train_test_ratio'] = train_test_ratio
        st.session_state['arima_forecast_method'] = forecast_method
        st.session_state['arima_run_count'] = run_count
        
        # è®¾ç½®è®­ç»ƒæ ‡å¿—
        st.session_state['arima_start_training'] = True
        st.session_state['arima_training_complete'] = False
        st.session_state['training_complete'] = False
        
        # åˆ·æ–°é¡µé¢å¼€å§‹è®­ç»ƒ
        st.rerun()

    # æ·»åŠ ARIMAæ¨¡å‹è®­ç»ƒç»“æœé¢„å…ˆåˆ›å»ºçš„å ä½ç¬¦
    arima_metrics_placeholder = st.empty()
    arima_prediction_chart_placeholder = st.empty()
    arima_residuals_chart_placeholder = st.empty()
    arima_residuals_hist_placeholder = st.empty()

    # ARIMAæ‰§è¡Œè®­ç»ƒçš„ç»Ÿä¸€é€»è¾‘
    if 'arima_start_training' in st.session_state and st.session_state['arima_start_training']:
        # è·å–å¤„ç†åçš„æ•°æ®
        if 'arima_processed_data' not in st.session_state or st.session_state['arima_processed_data'] is None:
            st.error("è¯·å…ˆåœ¨ARIMAæ ‡ç­¾é¡µé€‰æ‹©æ•°æ®å’Œå¤„ç†æ–¹æ³•")
            st.stop()
        
        processed_data = st.session_state['arima_processed_data']
        
        # è·å–è®­ç»ƒå‚æ•°
        p_param = st.session_state.get('arima_p_param', 2)
        d_param = st.session_state.get('arima_d_param', 1)
        q_param = st.session_state.get('arima_q_param', 2)
        forecast_method = st.session_state.get('arima_forecast_method', "åŠ¨æ€é¢„æµ‹")
        run_count = st.session_state.get('arima_run_count', 1)
        
        # ä½¿ç”¨é¢„å…ˆåˆ›å»ºçš„å ä½ç¬¦æ˜¾ç¤ºè®­ç»ƒçŠ¶æ€
        with arima_progress_placeholder.container():
            st.info(f"è®­ç»ƒARIMAæ¨¡å‹ä¸­ (è¿è¡Œ{run_count}æ¬¡)...")
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        try:
            # 1. æ‹†åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            train_size = int(len(processed_data) * train_test_ratio)
            train_data = processed_data[:train_size]
            test_data = processed_data[train_size:]
            
            status_text.info(f"æ•°æ®é›†å·²åˆ’åˆ†: è®­ç»ƒé›†å¤§å° {len(train_data)}, æµ‹è¯•é›†å¤§å° {len(test_data)}")
            progress_bar.progress(0.1)
            
            # 2. é…ç½®æ¨¡å‹é˜¶æ•°
            order = (p_param, d_param, q_param)
            
            # 3. ä½¿ç”¨ç»Ÿä¸€çš„å¤šæ¬¡è®­ç»ƒé€»è¾‘ï¼ˆå³ä½¿run_count=1ï¼‰
            multiple_runs_result = run_multiple_arima_models(
                train_data, 
                test_data, 
                order, 
                forecast_method=forecast_method,
                runs=run_count,
                progress_placeholder=progress_bar
            )
            
            # 4. å¤„ç†è®­ç»ƒç»“æœ
            if multiple_runs_result['status'] == 'success':
                best_model = multiple_runs_result['best_model']
                
                if best_model is not None:
                    # è·å–æœ€ä¼˜æ¨¡å‹ç›¸å…³æ•°æ®
                    arima_model = best_model['model']
                    train_pred = arima_model.fittedvalues
                    test_pred = best_model['predictions']
                    metrics = best_model['metrics']
                    residuals = arima_model.resid
                    
                    # åˆ›å»ºARIMAè®­ç»ƒç»“æœå­—å…¸
                    arima_training_result = {
                        'model': arima_model,
                        'order': order,
                        'train_data': train_data,
                        'test_data': test_data,
                        'train_pred': train_pred,
                        'test_pred': test_pred,
                        'metrics': metrics,
                        'residuals': residuals,
                        'run_info': {
                            'run': best_model['run'],
                            'seed': best_model['seed']
                        } if run_count > 1 else None,
                        'statistics': multiple_runs_result['statistics']
                    }
                    
                    # ç”Ÿæˆå›¾è¡¨é…ç½®
                    charts = prepare_arima_charts(
                        arima_model,
                        train_data,
                        test_data,
                        test_pred
                    )
                    
                    # ä¿å­˜å›¾è¡¨é…ç½®åˆ°session state
                    st.session_state['arima_prediction_chart'] = charts['prediction_chart']
                    st.session_state['arima_residuals_chart'] = charts['residuals_chart']
                    st.session_state['arima_residuals_hist'] = charts['residuals_hist']
                    
                    # ä¿å­˜è®­ç»ƒç»“æœå’Œæ¨¡å‹åˆ°session state
                    st.session_state['arima_model'] = arima_model
                    st.session_state['arima_model_metrics'] = metrics
                    # ä¸è¦è¦†ç›–é€šç”¨çš„model_metricsï¼Œè¿™æ˜¯LSTMä¸“ç”¨çš„
                    # st.session_state['model_metrics'] = metrics
                    st.session_state['arima_training_result'] = arima_training_result
                    
                    # å¦‚æœæ˜¯å¤šæ¬¡è®­ç»ƒï¼Œä¿å­˜æœ€ä¼˜è¿è¡Œä¿¡æ¯
                    if run_count > 1:
                        st.session_state['arima_best_run_info'] = {
                            'run': best_model['run'],
                            'seed': best_model['seed'],
                            'metrics': metrics
                        }
                    
                    # æ›´æ–°è®­ç»ƒçŠ¶æ€
                    st.session_state['arima_training_complete'] = True
                    # ä¸è¦è®¾ç½®é€šç”¨çš„training_completeï¼Œè¿™ä¼šå½±å“LSTMæ£€æµ‹
                    # st.session_state['training_complete'] = True
                    
                    # é‡ç½®è®­ç»ƒçŠ¶æ€æ ‡å¿—
                    st.session_state['arima_start_training'] = False
                    
                    # æ˜¾ç¤ºè®­ç»ƒå®Œæˆæ¶ˆæ¯
                    progress_bar.progress(1.0)
                    status_text.success("ARIMAæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                    
                    # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºç»“æœ
                    st.rerun()
                else:
                    st.error("æœªèƒ½è·å¾—æœ‰æ•ˆçš„ARIMAæ¨¡å‹")
            else:
                st.error(f"ARIMAæ¨¡å‹è®­ç»ƒå¤±è´¥: {multiple_runs_result['message']}")
                
        except Exception as e:
            st.error(f"ARIMAæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            st.code(traceback.format_exc())
            st.session_state['arima_start_training'] = False

    # æ˜¾ç¤ºè®­ç»ƒç»“æœ
    if 'arima_training_complete' in st.session_state and st.session_state['arima_training_complete']:
        training_result = st.session_state.get('arima_training_result')
        
        if training_result:
            # æ˜¾ç¤ºæœ€ä¼˜æ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯å¤šæ¬¡è®­ç»ƒï¼‰
            if training_result.get('run_info'):
                run_info = training_result['run_info']
                st.success(f"å½“å‰ä½¿ç”¨çš„æœ€ä¼˜æ¨¡å‹æ¥è‡ªè¿è¡Œ #{run_info['run']}, éšæœºç§å­: {run_info['seed']}")
            else:
                st.success("ARIMAæ¨¡å‹è®­ç»ƒå®Œæˆ")
                
            # æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡
            metrics = training_result.get('metrics', {})
            
            # åœ¨metrics_placeholderä¸­æ˜¾ç¤ºæŒ‡æ ‡
            with arima_metrics_placeholder.container():
                metric_cols = st.columns(4)
                with metric_cols[0]:
                    st.metric("MSE", f"{metrics.get('MSE', 0):.4f}")
                with metric_cols[1]:
                    st.metric("RMSE", f"{metrics.get('RMSE', 0):.4f}")
                with metric_cols[2]:
                    st.metric("MAE", f"{metrics.get('MAE', 0):.4f}")
                with metric_cols[3]:
                    st.metric("æ–¹å‘å‡†ç¡®ç‡", f"{metrics.get('Direction_Accuracy', 0):.4f}")
            
            # æ˜¾ç¤ºé¢„æµ‹å›¾è¡¨
            if 'arima_prediction_chart' in st.session_state:
                with arima_prediction_chart_placeholder.container():
                    st.subheader("ARIMAé¢„æµ‹ç»“æœ")
                    st_echarts(options=st.session_state['arima_prediction_chart'], height="500px")
            
            # æ˜¾ç¤ºæ®‹å·®å›¾
            if 'arima_residuals_chart' in st.session_state:
                with arima_residuals_chart_placeholder.container():
                    st.subheader("æ¨¡å‹æ®‹å·®")
                    st_echarts(options=st.session_state['arima_residuals_chart'], height="300px")
            
            # æ˜¾ç¤ºæ®‹å·®åˆ†å¸ƒå›¾
            if 'arima_residuals_hist' in st.session_state:
                with arima_residuals_hist_placeholder.container():
                    st.subheader("æ®‹å·®åˆ†å¸ƒ")
                    st_echarts(options=st.session_state['arima_residuals_hist'], height="300px")
                    
            # å¦‚æœæ˜¯å¤šæ¬¡è®­ç»ƒï¼Œæ˜¾ç¤ºè®­ç»ƒç»Ÿè®¡ä¿¡æ¯
            run_count = st.session_state.get('arima_run_count', 1)
            if run_count > 1 and training_result.get('statistics'):
                with st.expander("å¤šæ¬¡è®­ç»ƒç»Ÿè®¡ä¿¡æ¯", expanded=False):
                    # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
                    if 'statistics' in training_result:
                        stats_data = {
                            'æŒ‡æ ‡': ['MSE', 'RMSE', 'MAE', 'æ–¹å‘å‡†ç¡®ç‡'],
                            'å¹³å‡å€¼': [],
                            'æ ‡å‡†å·®': [],
                            'æœ€å°å€¼': [],
                            'æœ€å¤§å€¼': []
                        }
                        
                        for metric in ['MSE', 'RMSE', 'MAE', 'Direction_Accuracy']:
                            if metric in training_result['statistics']:
                                stats = training_result['statistics'][metric]
                                stats_data['å¹³å‡å€¼'].append(f"{stats['mean']:.4f}")
                                stats_data['æ ‡å‡†å·®'].append(f"{stats['std']:.4f}")
                                stats_data['æœ€å°å€¼'].append(f"{stats['min']:.4f}")
                                stats_data['æœ€å¤§å€¼'].append(f"{stats['max']:.4f}")
                            else:
                                stats_data['å¹³å‡å€¼'].append("N/A")
                                stats_data['æ ‡å‡†å·®'].append("N/A")
                                stats_data['æœ€å°å€¼'].append("N/A")
                                stats_data['æœ€å¤§å€¼'].append("N/A")
                        
                        # åˆ›å»ºDataFrameæ˜¾ç¤º
                        stats_df = pd.DataFrame(stats_data)
                        stats_df = stats_df.set_index('æŒ‡æ ‡')
                        st.dataframe(stats_df)
                    else:
                        st.info("æ²¡æœ‰å¯ç”¨çš„å¤šæ¬¡è®­ç»ƒç»Ÿè®¡ä¿¡æ¯")

# Prophetå‚æ•°è®¾ç½®
with model_tabs[2]:
    st.markdown("### Prophetæ¨¡å‹å‚æ•°")
    
    prophet_params_left_col, prophet_params_right_col = st.columns(2)
    with prophet_params_left_col:
        yearly_seasonality = st.selectbox(
            "å¹´åº¦å­£èŠ‚æ€§",
            options=["auto", "True", "False"],
            index=0
        )
        
        weekly_seasonality = st.selectbox(
            "å‘¨åº¦å­£èŠ‚æ€§",
            options=["auto", "True", "False"],
            index=0
        )
    
    with prophet_params_right_col:
        daily_seasonality = st.selectbox(
            "æ—¥åº¦å­£èŠ‚æ€§",
            options=["auto", "True", "False"],
            index=0
        )
        
        changepoint_prior_scale = st.slider(
            "å˜ç‚¹å…ˆéªŒæ¯”ä¾‹",
            min_value=0.001,
            max_value=0.5,
            value=0.05,
            step=0.001,
            format="%.3f"
        )

# ç”¨äºåœ¨ä¼šè¯é—´ä¿å­˜æ¨¡å‹è®­ç»ƒçŠ¶æ€
if 'trained_models' not in st.session_state:
    st.session_state['trained_models'] = {}

# ç”¨äºä¿å­˜æ¨¡å‹è®­ç»ƒå†å²è®°å½•
if 'training_history' not in st.session_state:
    st.session_state['training_history'] = {}

# é¡µé¢åº•éƒ¨ - å¸®åŠ©ä¿¡æ¯
with st.expander("ä½¿ç”¨å¸®åŠ©"):
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜
    
    1. **æ•°æ®å‡†å¤‡**: åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢ä¸Šä¼ å¹¶å¤„ç†æ‚¨çš„æ•°æ®
    2. **ç‰¹å¾é€‰æ‹©**: é€‰æ‹©ç”¨äºè®­ç»ƒæ¨¡å‹çš„ç‰¹å¾
    3. **æ¨¡å‹å‚æ•°**: é…ç½®æ¨¡å‹çš„è¶…å‚æ•°
    4. **å¼€å§‹è®­ç»ƒ**: ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"æŒ‰é’®å¯åŠ¨è®­ç»ƒè¿‡ç¨‹
    5. **ä¿å­˜æ¨¡å‹**: è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä¿å­˜æ¨¡å‹ä»¥ä¾¿åç»­ä½¿ç”¨
    
    ### å‚æ•°è§£é‡Š
    
    #### LSTMå‚æ•°
    - **éšè—å±‚å¤§å°**: ç¥ç»ç½‘ç»œéšè—å±‚çš„èŠ‚ç‚¹æ•°é‡
    - **LSTMå±‚æ•°**: æ¨¡å‹ä¸­LSTMå±‚çš„æ•°é‡
    - **Dropoutæ¯”ä¾‹**: é˜²æ­¢è¿‡æ‹Ÿåˆçš„éšæœºä¸¢å¼ƒæ¯”ä¾‹
    - **å­¦ä¹ ç‡**: æ¢¯åº¦ä¸‹é™çš„æ­¥é•¿
    - **æ‰¹æ¬¡å¤§å°**: æ¯æ¬¡æ›´æ–°æƒé‡ä½¿ç”¨çš„æ ·æœ¬æ•°é‡
    - **è®­ç»ƒè½®æ•°**: å®Œæ•´æ•°æ®é›†çš„è®­ç»ƒæ¬¡æ•°
    
    #### ARIMAå‚æ•°
    - **p (ARé˜¶æ•°)**: è‡ªå›å½’é¡¹çš„é˜¶æ•°
    - **d (å·®åˆ†é˜¶æ•°)**: å·®åˆ†é˜¶æ•°ï¼Œä½¿åºåˆ—å¹³ç¨³
    - **q (MAé˜¶æ•°)**: ç§»åŠ¨å¹³å‡é¡¹çš„é˜¶æ•°
    """)

with st.expander("GPUåŠ é€Ÿä¿¡æ¯",expanded=True):
    CUDA_Version_col1, CUDA_Version_col2, CUDA_Version_col3 = st.columns(3)
    with CUDA_Version_col1:
        st.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")

    with CUDA_Version_col2:
        st.info(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")

    with CUDA_Version_col3:
        st.info(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        CUDA_GPU_col1, CUDA_GPU_col2 = st.columns([5,6])
        with CUDA_GPU_col1:
            st.success(f"å½“å‰CUDAç‰ˆæœ¬: {torch.version.cuda}ï¼›å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
        with CUDA_GPU_col2:
            for i in range(torch.cuda.device_count()):
                st.success(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        st.warning("æœªæ£€æµ‹åˆ°GPUï¼ŒPyTorchå°†ä½¿ç”¨CPUæ¨¡å¼è¿è¡Œ")


# lstmæ‰§è¡Œè®­ç»ƒçš„é€»è¾‘
if 'start_training' in st.session_state and st.session_state['start_training']:
    # å‡†å¤‡ç‰¹å¾æ•°æ®
    # ç¡®ä¿selected_featureså·²å®šä¹‰ä¸”ä¸ä¸ºç©º
    if 'selected_features' not in locals() or not selected_features:
        st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ç”¨äºè®­ç»ƒ")
        st.stop()
    
    # ç¡®å®šä½¿ç”¨å“ªä¸ªæ•°æ®é›†è¿›è¡Œè®­ç»ƒ
    if 'tech_indicators' in st.session_state and st.session_state['tech_indicators'] is not None:
        # ä¼˜å…ˆä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        train_df = st.session_state['tech_indicators']
        st.info("ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®è¿›è¡Œè®­ç»ƒ")
    elif 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
        # å¦‚æœæŠ€æœ¯æŒ‡æ ‡æ•°æ®ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
        train_df = st.session_state['raw_data'] 
        st.warning("æœªæ‰¾åˆ°æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œå°†ä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œè®­ç»ƒã€‚å»ºè®®å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
    else:
        st.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®ã€‚è¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æ•°æ®å¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
        st.stop()
    
    # æ£€æŸ¥é€‰æ‹©çš„ç‰¹å¾æ˜¯å¦åœ¨æ•°æ®é›†ä¸­
    missing_features = [f for f in selected_features if f not in train_df.columns]
    if missing_features:
        st.error(f"ä»¥ä¸‹ç‰¹å¾åœ¨æ•°æ®é›†ä¸­ä¸å­˜åœ¨: {', '.join(missing_features)}")
        st.stop()
    
    # ä½¿ç”¨run_lstm_trainingå‡½æ•°æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹
    training_result = run_lstm_training(
        selected_features=selected_features,
        df=train_df,
        sequence_length=sequence_length,
        train_test_ratio=train_test_ratio,
        hidden_size=hidden_size,
        num_layers=num_layers,
        dropout=dropout,
        learning_rate=learning_rate,
        batch_size=batch_size,
        epochs=epochs,
        progress_placeholder=progress_placeholder,
        loss_chart_placeholder=loss_chart_placeholder
    )
    
    # æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°
    st.subheader("æ¨¡å‹è¯„ä¼°")
    
    # ä¿å­˜å½’ä¸€åŒ–å™¨ä»¥ä¾›åç»­é¢„æµ‹ä½¿ç”¨
    st.session_state['feature_scaler'] = training_result['feature_scaler']
    st.session_state['target_scaler'] = training_result['target_scaler']
    
    # æ›´æ–°å³ä¾§æ ä¸­çš„è¯„ä¼°æŒ‡æ ‡
    st.session_state['model_metrics'] = training_result['metrics']
    
    # æ˜¾ç¤ºä¿å­˜æˆåŠŸä¿¡æ¯
    st.success(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {training_result['model_path']}")
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state['trained_model'] = training_result['model']
    st.session_state['model_params'] = training_result['model_params'] if 'model_params' in training_result else None
    st.session_state['training_params'] = training_result['training_params'] if 'training_params' in training_result else None
    st.session_state['training_history'] = training_result['history']
    st.session_state['X_test'] = training_result['X_test']
    st.session_state['y_test'] = training_result['y_test']
    st.session_state['seq_length'] = training_result['sequence_length']
    
    # ä¿å­˜LSTMé¢„æµ‹ç»“æœä»¥ä¾›æ¨¡å‹è¯„ä¼°é¡µé¢ä½¿ç”¨
    if 'test_predictions' in training_result and training_result['test_predictions'] is not None:
        st.session_state['lstm_test_predictions'] = training_result['test_predictions']
    elif 'X_test' in training_result and 'y_test' in training_result:
        # å¦‚æœæ²¡æœ‰é¢„æµ‹ç»“æœï¼Œä½¿ç”¨æ¨¡å‹ç”Ÿæˆé¢„æµ‹
        try:
            model = training_result['model']
            X_test = training_result['X_test']
            target_scaler = training_result.get('target_scaler')
            
            model.eval()
            with torch.no_grad():
                X_test_tensor = torch.FloatTensor(X_test)
                predictions = model(X_test_tensor)
                lstm_pred = predictions.detach().cpu().numpy().flatten()
                
                # å¦‚æœæœ‰target_scalerï¼Œè¿›è¡Œåå½’ä¸€åŒ–
                if target_scaler is not None:
                    lstm_pred = target_scaler.inverse_transform(lstm_pred.reshape(-1, 1)).flatten()
                
                st.session_state['lstm_test_predictions'] = lstm_pred
        except Exception as e:
            st.warning(f"ç”ŸæˆLSTMé¢„æµ‹ç»“æœæ—¶å‡ºé”™: {e}")
    
    # æ›´æ–°è®­ç»ƒçŠ¶æ€
    st.session_state['training_complete'] = True
    st.session_state['lstm_training_complete'] = True
    
    # æ˜¾ç¤ºè®­ç»ƒå®Œæˆæ¶ˆæ¯
    st.success("LSTMæ¨¡å‹è®­ç»ƒå·²å®Œæˆï¼")
    # é‡ç½®è®­ç»ƒçŠ¶æ€
    st.session_state['start_training'] = False
    # æ›´æ–°è®­ç»ƒå†å²
    st.session_state['training_history'] = training_result['history']
    # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    st.rerun()



