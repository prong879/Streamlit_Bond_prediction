"""
æ¨¡å‹è®­ç»ƒé¡µé¢
ç”¨äºé…ç½®å’Œè®­ç»ƒé¢„æµ‹æ¨¡å‹
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import seaborn as sns
import os
import json
from datetime import datetime
from pathlib import Path
import sys
import time
from streamlit_echarts import st_echarts

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = str(Path(__file__).parent.parent.parent)
if project_root not in sys.path:
    sys.path.append(project_root)

# æ·»åŠ arima
from src.models.arima_model import (
    check_stationarity,
    diff_series,
    check_white_noise,
    analyze_acf_pacf,
    find_best_arima_params,
    fit_arima_model,
    check_residuals,
    forecast_arima,
    evaluate_arima_model,
    inverse_diff,
    generate_descriptive_statistics,
    create_timeseries_chart,
    create_histogram_chart,
    create_qq_plot,
    create_acf_pacf_charts,
    check_acf_pacf_pattern
)

# å¯¼å…¥LSTMç›¸å…³å‡½æ•°
from src.models.lstm_model import (
    save_model, 
    LSTMModel, 
    train_lstm_model, 
    evaluate_lstm_model, 
    plot_training_history, 
    create_sequences,
    run_lstm_training,
    select_features,
    create_correlation_heatmap,
    create_correlation_bar_chart,
    create_significance_charts
)

# æ·»åŠ sessionç®¡ç†å‡½æ•°
try:
    from src.utils.session import get_state, set_state, update_states
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºç©ºå‡½æ•°
    def get_state(key, default=None):
        return st.session_state.get(key, default)
    
    def set_state(key, value):
        st.session_state[key] = value
        
    def update_states(updates):
        for key, value in updates.items():
            st.session_state[key] = value

# ä¿®å¤PyTorchä¸Streamlitçš„å…¼å®¹æ€§é—®é¢˜
torch.classes.__path__ = []

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨¡å‹è®­ç»ƒ",
    page_icon="ğŸ§ ",
    layout="wide"
)

# æ ‡é¢˜å’Œç®€ä»‹
st.title("æ¨¡å‹è®­ç»ƒ")
st.markdown("æœ¬é¡µé¢ç”¨äºé…ç½®å’Œè®­ç»ƒæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ã€‚é€‰æ‹©åˆé€‚çš„å‚æ•°å¹¶å¼€å§‹è®­ç»ƒè¿‡ç¨‹ã€‚")

# è·å–åŠ è½½çš„æ•°æ®
if 'raw_data' not in st.session_state:
    st.warning("è¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æ•°æ®")
    st.stop()

df = st.session_state['raw_data']
# æ£€æŸ¥dfæ˜¯å¦ä¸ºNone
if df is None:
    st.warning("æ•°æ®ä¸ºç©ºï¼Œè¯·åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢æ­£ç¡®åŠ è½½æ•°æ®")
    st.stop()
    
tech_indicators = None

# ä¾§è¾¹æ å†…å®¹ - æ•°æ®ç‰¹å¾ã€æ¨¡å‹ä¿¡æ¯
with st.sidebar:
    st.subheader("æ•°æ®å’Œç‰¹å¾")
    
    # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
    with st.expander("æ•°æ®ä¿¡æ¯", expanded=True):
        if 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
            df = st.session_state['raw_data']
            st.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
            st.write(f"æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
        else:
            st.warning("æœªåŠ è½½æ•°æ®æˆ–æ•°æ®ä¸ºç©º")
    
    # æ•°æ®åˆ’åˆ†è®¾ç½®        
    with st.expander("æ•°æ®åˆ’åˆ†", expanded=True):
        train_test_ratio = st.slider(
            "è®­ç»ƒé›†æ¯”ä¾‹", 
            min_value=0.5, 
            max_value=0.9, 
            value=0.8, 
            step=0.05,
            help="è®­ç»ƒé›†å æ€»æ•°æ®çš„æ¯”ä¾‹"
        )
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œä½¿åºåˆ—é•¿åº¦è¾“å…¥æ¡†æ¨ªæ’æ˜¾ç¤º
        seq_length_col, pred_length_col = st.columns(2)
        
        with seq_length_col:
            sequence_length = st.number_input(
                "è¾“å…¥åºåˆ—é•¿åº¦",
                min_value=1,
                max_value=100,
                value=20,  # é»˜è®¤å€¼ä»10æ”¹ä¸º20ï¼Œä¸å‘½ä»¤è¡Œç‰ˆæœ¬ä¸€è‡´
                help="ç”¨äºé¢„æµ‹çš„å†å²æ•°æ®ç‚¹æ•°é‡"
            )
        
        with pred_length_col:
            prediction_length = st.number_input(
                "é¢„æµ‹åºåˆ—é•¿åº¦",
                min_value=1,
                max_value=30,
                value=1,  # é»˜è®¤å€¼1ï¼Œä¸å‘½ä»¤è¡Œç‰ˆæœ¬ä¸€è‡´
                help="éœ€è¦é¢„æµ‹çš„æœªæ¥æ•°æ®ç‚¹æ•°é‡"
            )
        
    st.subheader("æ¨¡å‹ä¿¡æ¯")
    
    # æ¨¡å‹çŠ¶æ€ä¿¡æ¯
    with st.expander("è®­ç»ƒçŠ¶æ€", expanded=True):
        if 'training_complete' in st.session_state and st.session_state['training_complete']:
            st.success("æ¨¡å‹è®­ç»ƒå·²å®Œæˆ")
        elif 'start_training' in st.session_state and st.session_state['start_training']:
            st.info("æ¨¡å‹è®­ç»ƒä¸­...")
        else:
            st.info("ç­‰å¾…å¼€å§‹è®­ç»ƒ...")
    
    # æ¨¡å‹ä¿å­˜é€‰é¡¹
    with st.expander("æ¨¡å‹ä¿å­˜", expanded=True):
        model_name = st.text_input(
            "æ¨¡å‹åç§°",
            value="my_model_v1"
        )
        
        save_model_button = st.button(
            "ä¿å­˜æ¨¡å‹",
            disabled=not ('training_complete' in st.session_state and st.session_state['training_complete'])
        )
        
        if save_model_button and 'trained_model' in st.session_state:
            model_path = save_model(
                st.session_state['trained_model'],
                st.session_state['model_params'],
                st.session_state['training_params'],
                st.session_state['training_history'],
                path=f"models/{model_name}"
            )
            st.success(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # æ¨¡å‹è¯„ä¼°ç®€æŠ¥
    with st.expander("æ¨¡å‹è¯„ä¼°ç®€æŠ¥", expanded=True):
        if 'model_metrics' in st.session_state and st.session_state.get('model_metrics') is not None:
            metrics = st.session_state['model_metrics']
            st.metric(
                label="MSE",
                value=f"{metrics.get('MSE', 0):.4f}"
            )
            
            st.metric(
                label="RMSE",
                value=f"{metrics.get('RMSE', 0):.4f}"
            )
            
            st.metric(
                label="MAE",
                value=f"{metrics.get('MAE', 0):.4f}"
            )
        elif 'start_training' in st.session_state and st.session_state['start_training']:
            st.info("æ¨¡å‹è¯„ä¼°ä¸­...")
        else:
            st.info("è®­ç»ƒæ¨¡å‹åå°†æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡")

# ä¸»è¦å†…å®¹åŒºåŸŸ

# æ¨¡å‹ç±»å‹é€‰æ‹©æ ‡ç­¾é¡µ
model_tabs = st.tabs(["LSTM", "ARIMA", "Prophet"])

# LSTMå‚æ•°è®¾ç½®
with model_tabs[0]:
    
    # ç‰¹å¾é€‰æ‹©éƒ¨åˆ† - æ·»åŠ åˆ°LSTMæ ‡ç­¾é¡µå†…
    st.markdown("### ç‰¹å¾é€‰æ‹©")
    
    # æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡æ•°æ®æ˜¯å¦å­˜åœ¨
    if 'raw_data' in st.session_state:
        if 'tech_indicators' in st.session_state:
            df = st.session_state['tech_indicators']  # ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        else:
            df = st.session_state['raw_data']  # å¦‚æœæ²¡æœ‰æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
        
        # ç¡®ä¿ä½¿ç”¨æ•°æ®ä¸­å®é™…å­˜åœ¨çš„åˆ—ä½œä¸ºç‰¹å¾åˆ—è¡¨
        all_features = df.columns.tolist()
        
        # åˆå§‹åŒ–selected_featuresçš„session state
        if 'selected_features' not in st.session_state:
            st.session_state['selected_features'] = all_features
        
        # 1. ç‰¹å¾ç­›é€‰å‚æ•°ï¼ˆé˜ˆå€¼é€‰æ‹©ï¼‰
        st.subheader("ç­›é€‰é˜ˆå€¼è®¾ç½®")
        lstm_feat_filter_col1, lstm_feat_filter_col2, lstm_feat_filter_col3 = st.columns(3)
        with lstm_feat_filter_col1:
            correlation_threshold = st.slider(
                "ç›¸å…³æ€§é˜ˆå€¼",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.05,
                help="ä¸ç›®æ ‡å˜é‡çš„æœ€å°ç›¸å…³ç³»æ•°"
            )
        with lstm_feat_filter_col2:
            vif_threshold = st.slider(
                "VIFé˜ˆå€¼",
                min_value=1.0,
                max_value=20.0,
                value=10.0,
                step=0.5,
                help="æ–¹å·®è†¨èƒ€å› å­çš„æœ€å¤§å…è®¸å€¼"
            )
        with lstm_feat_filter_col3:
            p_value_threshold = st.slider(
                "På€¼é˜ˆå€¼",
                min_value=0.0,
                max_value=0.1,
                value=0.05,
                step=0.01,
                help="ç»Ÿè®¡æ˜¾è‘—æ€§çš„æœ€å¤§å…è®¸på€¼"
            )

        # 2. ç‰¹å¾ç­›é€‰æŒ‰é’®å’Œç­›é€‰å®Œæˆæç¤ºæ¡†
        st.subheader("ç‰¹å¾ç­›é€‰")
        filter_col1, filter_col2 = st.columns([1,5])
        with filter_col1:
            if st.button("ç­›é€‰ç‰¹å¾", use_container_width=True):
                with st.spinner("æ­£åœ¨ç­›é€‰ç‰¹å¾..."):
                    # è°ƒç”¨select_featureså‡½æ•°å¹¶è·å–ç»“æœ
                    filter_results = select_features(
                    df,
                    correlation_threshold=correlation_threshold,
                    vif_threshold=vif_threshold,
                    p_value_threshold=p_value_threshold
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                    if 'error' in filter_results:
                        st.error(f"ç‰¹å¾é€‰æ‹©è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {filter_results['error']}")
                        st.code(filter_results['traceback'])
                        filtered_features = filter_results['selected_features']
                    else:
                        # ä»ç»“æœä¸­è·å–ç­›é€‰åçš„ç‰¹å¾åˆ—è¡¨
                        filtered_features = filter_results['selected_features']
                        
                        # ä¿å­˜ç­›é€‰å‚æ•°å’Œè¯¦ç»†ä¿¡æ¯åˆ°session state
                        st.session_state['feature_filter_params'] = {
                            'correlation_threshold': correlation_threshold,
                            'vif_threshold': vif_threshold,
                            'p_value_threshold': p_value_threshold
                        }
                        
                        st.session_state['feature_filter_results'] = filter_results
                        
                        # æ›´æ–°session stateä¸­çš„ç­›é€‰ç‰¹å¾
                        if filtered_features and len(filtered_features) > 0:
                            st.session_state['filtered_features'] = filtered_features
                            # åŒæ—¶æ›´æ–°é€‰æ‹©çš„ç‰¹å¾ï¼Œä½¿ç•Œé¢ä¸Šçš„å¤šé€‰æ¡†ä¹Ÿæ›´æ–°
                            st.session_state['selected_features'] = filtered_features
                            # æ ‡è®°å·²ç»å®Œæˆç­›é€‰
                            st.session_state['filter_applied'] = True
                        else:
                            st.error("ç‰¹å¾ç­›é€‰å¤±è´¥ï¼Œå°†ä½¿ç”¨æ‰€æœ‰ç‰¹å¾")
                            st.session_state['filtered_features'] = all_features
                            st.session_state['selected_features'] = all_features
                            st.session_state['filter_applied'] = False
        
        with filter_col2:
            # åœ¨UIä¸Šæ˜¾ç¤ºæœ€ç»ˆç­›é€‰ç»“æœï¼ˆåœ¨ç­›é€‰å®Œæˆåæ˜¾ç¤ºï¼‰
            if 'filter_applied' in st.session_state and st.session_state['filter_applied'] and 'feature_filter_results' in st.session_state:
                filter_results = st.session_state['feature_filter_results']
                filtered_features = filter_results['selected_features']
                st.success(f"ç‰¹å¾ç­›é€‰å®Œæˆï¼ä» {df.shape[1]} ä¸ªç‰¹å¾ä¸­é€‰å‡º {len(filtered_features)} ä¸ªç‰¹å¾ï¼š{filtered_features}")
        
        # 3. ç‰¹å¾é€‰æ‹©å¤šé€‰æ¡†ï¼Œä½¿ç”¨session stateä¸­çš„ç‰¹å¾ä½œä¸ºé»˜è®¤å€¼
        st.subheader("é€‰æ‹©è®­ç»ƒç‰¹å¾")
        selected_features = st.multiselect(
            "é€‰æ‹©ç”¨äºè®­ç»ƒçš„ç‰¹å¾",
            options=all_features,
            default=st.session_state['selected_features']
        )
        
        # æ›´æ–°selected_featuresçš„session state
        st.session_state['selected_features'] = selected_features
        
        # 4. ä¸‰ä¸ªå±•å¼€æ¡†ï¼Œæ˜¾ç¤ºé€æ­¥ç­›é€‰çš„ç»“æœ
        st.subheader("ç­›é€‰è¯¦ç»†ç»“æœ")
        
        # 1. ç›¸å…³æ€§ç­›é€‰å±•å¼€æ¡†
        with st.expander("**ç›¸å…³æ€§ç­›é€‰**", expanded=False):
            if 'feature_filter_results' not in st.session_state or not st.session_state.get('filter_applied', False):
                st.warning("è¯·å…ˆè¿›è¡Œç­›é€‰")
            else:
                filter_results = st.session_state['feature_filter_results']
                correlation_threshold = st.session_state['feature_filter_params']['correlation_threshold']
                
                # ç›¸å…³æ€§æ•°æ®è¡¨æ ¼
                corr_data = filter_results['correlation']['data']
                high_correlation_features = filter_results['correlation']['features']
                corr_matrix = filter_results['correlation']['matrix']
                
                # æ˜¾ç¤ºç›¸å…³æ€§æ•°æ®è¡¨æ ¼
                st.dataframe(corr_data, hide_index=True)
                
                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œä½¿æŒ‰é’®å’Œæç¤ºä¿¡æ¯å¤„äºåŒä¸€è¡Œ
                btn_col, info_col = st.columns([1, 5])
                
                # æ·»åŠ æ˜¾ç¤º/éšè—çƒ­åŠ›å›¾çš„æŒ‰é’®
                with btn_col:
                    show_corr_heatmap = st.button("æ˜¾ç¤º/éšè—ç›¸å…³æ€§çƒ­åŠ›å›¾", key="toggle_corr_heatmap")
                
                # åœ¨å³ä¾§åˆ—æ˜¾ç¤ºç›¸å…³ä¿¡æ¯
                with info_col:
                    if not high_correlation_features:
                        st.warning("æœªæ‰¾åˆ°ç¬¦åˆç›¸å…³æ€§é˜ˆå€¼çš„ç‰¹å¾ï¼Œå°†æ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾çš„ç›¸å…³æ€§çƒ­åŠ›å›¾")
                    else:
                        st.success(f"ç›¸å…³æ€§ç­›é€‰å‡ºçš„ç‰¹å¾ (|ç›¸å…³æ€§| > {correlation_threshold}): {high_correlation_features}")
                
                # åˆå§‹åŒ–session stateä¸­çš„çƒ­åŠ›å›¾æ˜¾ç¤ºçŠ¶æ€
                if 'show_corr_heatmap' not in st.session_state:
                    st.session_state['show_corr_heatmap'] = False
                
                # åˆ‡æ¢æ˜¾ç¤ºçŠ¶æ€
                if show_corr_heatmap:
                    st.session_state['show_corr_heatmap'] = not st.session_state['show_corr_heatmap']
                
                # æ ¹æ®æ˜¾ç¤ºçŠ¶æ€æ¸²æŸ“çƒ­åŠ›å›¾
                if st.session_state['show_corr_heatmap']:
                    # æ£€æŸ¥high_correlation_featuresæ˜¯å¦ä¸ºç©º
                    if not high_correlation_features:
                        correlation_heatmap_option = create_correlation_heatmap(corr_matrix)
                    else:
                        # æ˜¾ç¤ºç‰¹å¾é—´ç›¸å…³æ€§çƒ­åŠ›å›¾
                        st.write("ç‰¹å¾é—´ç›¸å…³æ€§çƒ­åŠ›å›¾")
                        correlation_heatmap_option = create_correlation_heatmap(corr_matrix, high_correlation_features)
                    
                    # ç¡®ä¿çƒ­åŠ›å›¾é…ç½®æ˜¯æœ‰æ•ˆçš„dictionary
                    if correlation_heatmap_option is None or not isinstance(correlation_heatmap_option, dict):
                        st.error("ç”Ÿæˆçƒ­åŠ›å›¾é…ç½®å¤±è´¥")
                    else:
                        # æ˜¾ç¤ºçƒ­åŠ›å›¾
                        try:
                            st_echarts(
                                options=correlation_heatmap_option,
                                height="300px",
                                width="100%"
                            )
                        except Exception as e:
                            st.error(f"çƒ­åŠ›å›¾æ¸²æŸ“å‡ºé”™: {str(e)}")
                            st.write("é”™è¯¯è¯¦æƒ…:")
                            st.exception(e)
                
        
        # 2. VIFç­›é€‰å±•å¼€æ¡†
        with st.expander("**VIFç­›é€‰**", expanded=False):
            if 'feature_filter_results' not in st.session_state or not st.session_state.get('filter_applied', False):
                st.warning("è¯·å…ˆè¿›è¡Œç­›é€‰")
            else:
                filter_results = st.session_state['feature_filter_results']
                vif_threshold = st.session_state['feature_filter_params']['vif_threshold']
                
                vif_data = filter_results['vif']['data']
                low_vif_features = filter_results['vif']['features']
                vif_warnings = filter_results['vif']['warnings']
                collinear_features = filter_results['vif']['collinear_features']
                
                # æ”¶é›†æ‰€æœ‰è­¦å‘Šä¿¡æ¯
                warning_messages = []
                if collinear_features:
                    warning_messages.append(f"- ä»¥ä¸‹ç‰¹å¾å­˜åœ¨å®Œå…¨å…±çº¿æ€§æˆ–VIFå€¼å¼‚å¸¸å¤§ï¼š{', '.join(collinear_features)}")
                warning_messages.extend([f"- {warning}" for warning in vif_warnings])
                
                # å¦‚æœæœ‰è­¦å‘Šä¿¡æ¯ï¼Œæ˜¾ç¤ºåœ¨ä¸€ä¸ªwarningæ¡†ä¸­
                if warning_messages:
                    st.warning("VIFåˆ†æè¿‡ç¨‹ä¸­å‘ç°ä»¥ä¸‹é—®é¢˜ï¼š\n" + "\n".join(warning_messages))
                
                # æ£€æŸ¥vif_dataæ˜¯å¦ä¸ºç©º
                if not vif_data.empty:
                    # æ˜¾ç¤ºVIFæ•°æ®è¡¨æ ¼
                    st.dataframe(vif_data, hide_index=True)
                    st.success(f"VIFä½äº{vif_threshold}çš„ç‰¹å¾: {low_vif_features}")

                else:
                    st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡ŒVIFè®¡ç®—æˆ–å¤šé‡å…±çº¿æ€§åˆ†æ")
        
        # 3. ç»Ÿè®¡æ˜¾è‘—æ€§ç­›é€‰å±•å¼€æ¡†
        with st.expander("**ç»Ÿè®¡æ˜¾è‘—æ€§ç­›é€‰**", expanded=False):
            if 'feature_filter_results' not in st.session_state or not st.session_state.get('filter_applied', False):
                st.warning("è¯·å…ˆè¿›è¡Œç­›é€‰")
            else:
                filter_results = st.session_state['feature_filter_results']
                p_value_threshold = st.session_state['feature_filter_params']['p_value_threshold']
                
                sig_data = filter_results['significance']['data']
                significant_features = filter_results['significance']['features']
                
                if not sig_data.empty:
                    # æ˜¾ç¤ºç»Ÿè®¡æ˜¾è‘—æ€§æ•°æ®è¡¨æ ¼
                    st.dataframe(sig_data, hide_index=True)
                    
                    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œä½¿æŒ‰é’®å’Œæç¤ºä¿¡æ¯å¤„äºåŒä¸€è¡Œ
                    p_btn_col, p_info_col = st.columns([1, 7])
                    
                    # æ·»åŠ æ˜¾ç¤º/éšè—På€¼å›¾çš„æŒ‰é’®
                    with p_btn_col:
                        show_p_value_chart = st.button("æ˜¾ç¤º/éšè—På€¼å›¾è¡¨", key="toggle_p_value_chart")
                    
                    # åœ¨å³ä¾§åˆ—æ˜¾ç¤ºç›¸å…³ä¿¡æ¯
                    with p_info_col:
                        if p_value_threshold > 0:
                            st.success(f"På€¼ä½äº{p_value_threshold}çš„ç‰¹å¾: {significant_features}")
                    
                    # åˆå§‹åŒ–session stateä¸­çš„På€¼å›¾æ˜¾ç¤ºçŠ¶æ€
                    if 'show_p_value_chart' not in st.session_state:
                        st.session_state['show_p_value_chart'] = False
                    
                    # åˆ‡æ¢æ˜¾ç¤ºçŠ¶æ€
                    if show_p_value_chart:
                        st.session_state['show_p_value_chart'] = not st.session_state['show_p_value_chart']
                    
                    # æ ¹æ®æ˜¾ç¤ºçŠ¶æ€æ¸²æŸ“På€¼å›¾
                    if st.session_state['show_p_value_chart']:
                        # ä¿®æ”¹ä¸ºåªæ¥æ”¶å’Œæ¸²æŸ“på€¼å›¾è¡¨
                        _, p_value_option = create_significance_charts(sig_data, p_value_threshold)
                        st_echarts(
                            options=p_value_option, 
                            height="200px",
                            width="100%"
                        )
                else:
                    st.warning("æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ")
        
    # æ¨¡å‹å‚æ•°è®¾ç½®
    st.markdown("### æ¨¡å‹å‚æ•°")
    
    lstm_params_left_col, lstm_params_right_col = st.columns(2)
    with lstm_params_left_col:
        hidden_size = st.number_input(
            "éšè—å±‚å¤§å°",
            min_value=1,
            max_value=512,
            value=64
        )
        
        num_layers = st.number_input(
            "LSTMå±‚æ•°",
            min_value=1,
            max_value=5,
            value=2
        )
        
        dropout = st.slider(
            "Dropoutæ¯”ä¾‹",
            min_value=0.0,
            max_value=0.9,
            value=0.2,
            step=0.1
        )
    
    with lstm_params_right_col:
        learning_rate = st.number_input(
            "å­¦ä¹ ç‡",
            min_value=0.0001,
            max_value=0.1,
            value=0.001,
            format="%.4f"
        )
        
        batch_size = st.number_input(
            "æ‰¹æ¬¡å¤§å°",
            min_value=1,
            max_value=256,
            value=32
        )
        
        epochs = st.number_input(
            "è®­ç»ƒè½®æ•°",
            min_value=1,
            max_value=1000,
            value=100
        )
    
    # è®­ç»ƒæ§åˆ¶
    st.markdown("### è®­ç»ƒæ§åˆ¶")
    
    lstm_train_btn_col, lstm_early_stop_col = st.columns([3, 1])
    with lstm_train_btn_col:
        if st.button(
            "å¼€å§‹è®­ç»ƒ",
            use_container_width=True
        ):
            st.session_state['start_training'] = True
        else:
            st.session_state['start_training'] = False
        
    with lstm_early_stop_col:
        enable_early_stopping = st.checkbox(
            "å¯ç”¨æ—©åœ",
            value=True
        )
    
    # è®­ç»ƒè¿›åº¦å’ŒæŸå¤±å¯è§†åŒ–çš„å ä½åŒºåŸŸ
    progress_placeholder = st.empty()
    loss_chart_placeholder = st.empty()
    
    # å¦‚æœä¼šè¯ä¸­å·²æœ‰è®­ç»ƒå†å²ä½†ç•Œé¢åˆšåˆšåŠ è½½ï¼Œæ˜¾ç¤ºä¹‹å‰çš„è®­ç»ƒå†å²
    if 'training_history' in st.session_state and 'training_complete' in st.session_state and st.session_state['training_complete'] and not ('start_training' in st.session_state and st.session_state['start_training']):
        history = st.session_state['training_history']
        with loss_chart_placeholder:
            # ç»˜åˆ¶å·²æœ‰çš„æŸå¤±æ›²çº¿
            history_df = pd.DataFrame({
                'è®­ç»ƒæŸå¤±': history['train_loss'],
                'éªŒè¯æŸå¤±': history['val_loss']
            })
            st.line_chart(history_df)
    
    if 'start_training' in st.session_state and st.session_state['start_training']:
        with progress_placeholder.container():
            st.info("è®­ç»ƒè¿‡ç¨‹å°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
        with loss_chart_placeholder.container():
            # ä¸´æ—¶æ•°æ®ç”¨äºç¤ºä¾‹
            chart_data = pd.DataFrame(
                np.random.randn(20, 2),
                columns=['è®­ç»ƒæŸå¤±', 'éªŒè¯æŸå¤±']
            )
            st.line_chart(chart_data)

# ARIMAå‚æ•°è®¾ç½®
with model_tabs[1]:       
    # æ·»åŠ æ•°æ®é¢„å¤„ç†éƒ¨åˆ†
    st.markdown("#### æ•°æ®é¢„å¤„ç†")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§ä¸ºæ§åˆ¶åŒºåŸŸï¼Œå³ä¾§ä¸ºæ•°æ®å›¾è¡¨
    arima_controls_col, arima_charts_col = st.columns([1, 2])
    
    with arima_controls_col:
        # å˜é‡é€‰æ‹©æ¡†
        if 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
            df = st.session_state['raw_data']
            
            # è·å–æ‰€æœ‰åˆ—åï¼Œæ’é™¤æ—¥æœŸç±»å‹çš„åˆ—
            all_columns = []
            date_columns = []
            
            for col in df.columns:
                if pd.api.types.is_datetime64_any_dtype(df[col]):
                    date_columns.append(col)
                else:
                    all_columns.append(col)
            
            # å¦‚æœæ‰€æœ‰åˆ—éƒ½è¢«æ’é™¤ï¼Œç»™å‡ºè­¦å‘Š
            if not all_columns:
                st.error("æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨äºåˆ†æçš„éæ—¥æœŸç±»å‹åˆ—")
                st.stop()
                
            # å˜é‡é€‰æ‹©æ¡†
            selected_var = st.selectbox(
                "é€‰æ‹©éœ€è¦åˆ†æçš„å˜é‡",
                options=all_columns,
                index=0,
                key="arima_selected_var"
            )
            
            # è·å–æ‰€é€‰å˜é‡çš„æ•°æ®
            selected_data = df[selected_var]
            
            # æ£€æŸ¥æ•°æ®ç±»å‹ï¼Œå¤„ç†æ—¥æœŸæ—¶é—´ç±»å‹
            is_datetime = pd.api.types.is_datetime64_any_dtype(selected_data)
            is_numeric = pd.api.types.is_numeric_dtype(selected_data)
            
            if is_datetime:
                st.warning(f"é€‰æ‹©çš„å˜é‡ '{selected_var}' æ˜¯æ—¥æœŸæ—¶é—´ç±»å‹ï¼Œå°†è½¬æ¢ä¸ºæ—¶é—´æˆ³åè¿›è¡Œåˆ†æ")
                # å°†æ—¥æœŸæ—¶é—´è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆæµ®ç‚¹æ•°ï¼‰
                selected_data = (selected_data - pd.Timestamp("1970-01-01")) // pd.Timedelta("1s")
                # æ˜¾ç¤ºè½¬æ¢åçš„æ•°æ®ç±»å‹
                st.info(f"è½¬æ¢åçš„æ•°æ®ç±»å‹: {selected_data.dtype}")
            elif not is_numeric:
                st.error(f"é€‰æ‹©çš„å˜é‡ '{selected_var}' ä¸æ˜¯æ•°å€¼ç±»å‹ï¼Œæ— æ³•è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æ")
                st.stop()
            
            # æ•°æ®å¤„ç†æ–¹æ³•é€‰æ‹©
            transform_method = st.radio(
                "æ•°æ®å¤„ç†æ–¹æ³•",
                options=["åŸå§‹æ•°æ®", "å¯¹æ•°å˜æ¢", "ä¸€é˜¶å·®åˆ†", "ä¸€é˜¶å¯¹æ•°å·®åˆ†"],
                index=0,
                key="arima_transform_method"
            )
            
            # æ·»åŠ æ‰§è¡ŒæŒ‰é’®ï¼Œç‚¹å‡»åæ›´æ–°å›¾è¡¨
            if st.button("æ›´æ–°å›¾è¡¨", key="update_arima_charts"):
                st.session_state['arima_processed'] = True
            
            # å¹³ç¨³æ€§æ£€éªŒç»“æœæ˜¾ç¤ºåŒºåŸŸ
            if 'arima_processed' in st.session_state and st.session_state['arima_processed']:                    
                # æ ¹æ®é€‰æ‹©çš„æ–¹æ³•è¿›è¡Œæ•°æ®å¤„ç†
                if transform_method == "åŸå§‹æ•°æ®":
                    processed_data = selected_data
                    transform_title = "åŸå§‹æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                    
                elif transform_method == "å¯¹æ•°å˜æ¢":
                    # æ£€æŸ¥æ˜¯å¦æœ‰éæ­£å€¼
                    if (selected_data <= 0).any():
                        st.warning("æ•°æ®åŒ…å«éæ­£å€¼ï¼Œæ— æ³•è¿›è¡Œå¯¹æ•°å˜æ¢")
                        processed_data = selected_data
                        transform_title = "åŸå§‹æ•°æ®"
                    else:
                        processed_data = np.log(selected_data)
                        transform_title = "å¯¹æ•°å˜æ¢åçš„æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                    
                elif transform_method == "ä¸€é˜¶å·®åˆ†":
                    diff_data, _ = diff_series(selected_data, diff_order=1, log_diff=False)
                    processed_data = diff_data
                    transform_title = "ä¸€é˜¶å·®åˆ†åçš„æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                    
                elif transform_method == "ä¸€é˜¶å¯¹æ•°å·®åˆ†":
                    # æ£€æŸ¥æ˜¯å¦æœ‰éæ­£å€¼
                    if (selected_data <= 0).any():
                        st.warning("æ•°æ®åŒ…å«éæ­£å€¼ï¼Œæ— æ³•è¿›è¡Œå¯¹æ•°å·®åˆ†")
                        processed_data = selected_data
                        transform_title = "åŸå§‹æ•°æ®"
                    else:
                        diff_data, _ = diff_series(selected_data, diff_order=1, log_diff=True)
                        processed_data = diff_data
                        transform_title = "ä¸€é˜¶å¯¹æ•°å·®åˆ†åçš„æ•°æ®"
                    
                    # æ‰§è¡Œå¹³ç¨³æ€§æ£€éªŒ
                    stationarity_results, is_stationary, _ = check_stationarity(processed_data)
                
                # å¹³ç¨³æ€§æ£€éªŒç»“æœå±•å¼€æ¡†
                with st.expander("ADFå¹³ç¨³æ€§æ£€éªŒç»“æœ", expanded=True):
                    ADF_col1, ADF_col2 = st.columns(2)
                    with ADF_col1:
                        st.metric(
                            label="ADFç»Ÿè®¡é‡",
                            value=f"{stationarity_results['ADFç»Ÿè®¡é‡']:.2f}"
                        )
                    with ADF_col2:
                        st.metric(
                            label="på€¼",
                            value=f" {stationarity_results['på€¼']:.2f}"
                        )

                    # æ ¹æ®på€¼åˆ¤æ–­æ˜¯å¦å¹³ç¨³
                    if is_stationary:
                        st.success("åºåˆ—å¹³ç¨³ (på€¼ < 0.05)")
                    else:
                        st.warning("åºåˆ—ä¸å¹³ç¨³ (på€¼ >= 0.05)")
                
                # æ­£æ€æ€§æ£€éªŒç»“æœå±•å¼€æ¡†
                with st.expander("æ­£æ€æ€§æ£€éªŒç»“æœ", expanded=True):
                    # æ‰§è¡Œæ­£æ€æ€§æ£€éªŒ (ä½¿ç”¨scipyçš„statsæ¨¡å—)
                    from scipy import stats
                    
                    # è¿›è¡ŒShapiro-Wilkæ£€éªŒ
                    if len(processed_data) < 5000:  # Shapiro-Wilké€‚ç”¨äºå°æ ·æœ¬
                        stat, p_value = stats.shapiro(processed_data.dropna())
                        test_name = "Shapiro-Wilkæ£€éªŒ"
                    else:  # å¤§æ ·æœ¬ä½¿ç”¨K-Sæ£€éªŒ
                        stat, p_value = stats.kstest(processed_data.dropna(), 'norm')
                        test_name = "Kolmogorov-Smirnovæ£€éªŒ"

                    # æ˜¾ç¤ºæ­£æ€æ£€éªŒç»“æœ
                    st.metric(
                        label=f"{test_name}ç»Ÿè®¡é‡",
                        value=f"{stat:.2f}"
                    )
                    st.metric(
                        label="på€¼",
                        value=f"{p_value:.2f}"
                    )

                    # æ ¹æ®på€¼åˆ¤æ–­æ˜¯å¦ç¬¦åˆæ­£æ€åˆ†å¸ƒ
                    if p_value < 0.05:
                        st.warning(f"ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒ (på€¼ < 0.05)")
                    else:
                        st.success(f"ç¬¦åˆæ­£æ€åˆ†å¸ƒ (på€¼ >= 0.05)")
                
                # ç™½å™ªå£°æ£€éªŒç»“æœå±•å¼€æ¡†
                with st.expander("Ljung-Boxç™½å™ªå£°æ£€éªŒç»“æœ", expanded=True):
                    # æ‰§è¡Œç™½å™ªå£°æ£€éªŒ
                    try:
                        lb_df, is_white_noise = check_white_noise(processed_data.dropna())
                        
                        # æ˜¾ç¤ºç»“æœ
                                                
                        # ç¬¬ä¸€ä¸ªæ»åé˜¶æ•°çš„Qç»Ÿè®¡é‡å’Œpå€¼
                        first_lag_q = lb_df.iloc[0]['Qç»Ÿè®¡é‡']
                        first_lag_p = lb_df.iloc[0]['på€¼']
                        
                        st.write("æ»åé˜¶æ•°=1")

                        LB_col1, LB_col2 = st.columns(2)
                        with LB_col1:
                            st.metric(
                                label="Qç»Ÿè®¡é‡",
                                value=f"{first_lag_q:.2f}"
                            )
                        with LB_col2:
                            st.metric(
                                label="på€¼",
                                value=f"{first_lag_p:.2f}"
                            )
                        
                        # æ ¹æ®på€¼åˆ¤æ–­æ˜¯å¦ä¸ºç™½å™ªå£°
                        if is_white_noise:
                            st.success("åºåˆ—ä¸ºç™½å™ªå£° (på€¼ > 0.05)")
                        else:
                            st.warning("åºåˆ—ä¸æ˜¯ç™½å™ªå£° (på€¼ < 0.05)")
                    except Exception as e:
                        st.error(f"æ— æ³•æ‰§è¡Œç™½å™ªå£°æ£€éªŒ: {str(e)}")
                
                # æ·»åŠ è‡ªç›¸å…³æ£€æµ‹ç»“æœå±•å¼€æ¡†
                with st.expander("è‡ªç›¸å…³æ£€æµ‹ç»“æœ", expanded=True):
                    # æ‰§è¡Œè‡ªç›¸å…³æ£€æµ‹
                    try:
                        acf_pacf_pattern = check_acf_pacf_pattern(processed_data.dropna(), lags=30)
                        
                        # æ˜¾ç¤ºACFç»“æœ
                        acf_pattern = acf_pacf_pattern["acf"]["pattern"]
                        acf_cutoff = acf_pacf_pattern["acf"]["cutoff"]
                        
                        if acf_pattern == "æˆªå°¾":
                            st.info(f"ACF: {acf_cutoff}é˜¶æˆªå°¾")
                        else:
                            st.info("ACF: æ‹–å°¾")
                    
                        # æ˜¾ç¤ºPACFç»“æœ
                        pacf_pattern = acf_pacf_pattern["pacf"]["pattern"]
                        pacf_cutoff = acf_pacf_pattern["pacf"]["cutoff"]
                        
                        if pacf_pattern == "æˆªå°¾":
                            st.info(f"PACF: {pacf_cutoff}é˜¶æˆªå°¾")
                        else:
                            st.info("PACF: æ‹–å°¾")
                        
                        # æ˜¾ç¤ºæ¨¡å‹å»ºè®®ï¼ˆç®€åŒ–ï¼‰
                        st.success(f"å®šé˜¶å‚æ•°å»ºè®®: {acf_pacf_pattern['model_suggestion']}")
                        
                    except Exception as e:
                        st.error(f"æ— æ³•æ‰§è¡Œè‡ªç›¸å…³æ£€æµ‹: {str(e)}")
                
                # ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°ä¼šè¯çŠ¶æ€
                st.session_state['arima_processed_data'] = processed_data
                st.session_state['arima_transform_title'] = transform_title

        else:
            st.warning("è¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æ•°æ®")
    
    with arima_charts_col:
        # æ•°æ®å›¾è¡¨æ˜¾ç¤ºåŒºåŸŸ
        if 'arima_processed' in st.session_state and st.session_state['arima_processed']:
            if 'arima_processed_data' in st.session_state:
                # è·å–å¤„ç†åçš„æ•°æ®å’Œæ ‡é¢˜
                processed_data = st.session_state['arima_processed_data']
                transform_title = st.session_state['arima_transform_title']
                
                # åˆ›å»ºæŠ˜çº¿å›¾
                try:
                    # åˆ›å»ºåŒ…å«ç´¢å¼•çš„æ•°æ®æ¡†
                    # å¤„ç†å·®åˆ†åæ•°æ®ç´¢å¼•å¯èƒ½ä¸åŸå§‹æ•°æ®ä¸åŒçš„é—®é¢˜
                    if transform_method in ["ä¸€é˜¶å·®åˆ†", "ä¸€é˜¶å¯¹æ•°å·®åˆ†"]:
                        # å¯¹äºå·®åˆ†æ•°æ®ï¼Œä½¿ç”¨å·®åˆ†åçš„ç´¢å¼•
                        time_series_df = pd.DataFrame({transform_title: processed_data})
                    else:
                        # å¯¹äºåŸå§‹æ•°æ®æˆ–å¯¹æ•°å˜æ¢ï¼Œä¿æŒåŸå§‹ç´¢å¼•
                        time_series_df = pd.DataFrame({transform_title: processed_data}, index=df.index)
                    
                    timeseries_option = create_timeseries_chart(
                        time_series_df,
                        title=f"{selected_var} - {transform_title}"
                    )
                    st_echarts(options=timeseries_option, height="400px")
                except Exception as e:
                    st.error(f"æ— æ³•ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾: {str(e)}")
                
                # åˆ›å»ºç›´æ–¹å›¾
                try:
                    histogram_option = create_histogram_chart(
                        processed_data,
                        title=f"{selected_var} - åˆ†å¸ƒç›´æ–¹å›¾"
                    )
                    st_echarts(options=histogram_option, height="350px")
                except Exception as e:
                    st.error(f"æ— æ³•ç»˜åˆ¶åˆ†å¸ƒç›´æ–¹å›¾: {str(e)}")
                
                # åˆ›å»ºQQå›¾
                try:
                    qq_option = create_qq_plot(
                        processed_data,
                        title=f"{selected_var} - QQå›¾"
                    )
                    st_echarts(options=qq_option, height="400px")
                except Exception as e:
                    st.warning(f"æ— æ³•ç»˜åˆ¶QQå›¾: {str(e)}")
                
                # QQå›¾åæ·»åŠ è‡ªç›¸å…³å’Œåè‡ªç›¸å…³å›¾
                try:
                    # åˆ›å»ºè‡ªç›¸å…³å›¾å’Œåè‡ªç›¸å…³å›¾
                    acf_option, pacf_option = create_acf_pacf_charts(
                        processed_data,
                        lags=30,  # è®¾ç½®æœ€å¤§æ»åé˜¶æ•°ä¸º30
                        title_prefix=f"{selected_var}"
                    )
                    
                    # åˆ†ä¸¤åˆ—æ˜¾ç¤ºACFå’ŒPACF
                    acf_col, pacf_col = st.columns(2)
                    
                    with acf_col:
                        st_echarts(options=acf_option, height="200px")
                    
                    with pacf_col:
                        st_echarts(options=pacf_option, height="200px")
                        
                except Exception as e:
                    st.warning(f"æ— æ³•ç»˜åˆ¶è‡ªç›¸å…³å’Œåè‡ªç›¸å…³å›¾: {str(e)}")
                    

            else:
                st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©å˜é‡å’Œæ•°æ®å¤„ç†æ–¹æ³•ï¼Œç„¶åç‚¹å‡»æ›´æ–°å›¾è¡¨")
        else:
            st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©å˜é‡å’Œæ•°æ®å¤„ç†æ–¹æ³•ï¼Œç„¶åç‚¹å‡»æ›´æ–°å›¾è¡¨")
    
    # æ·»åŠ æè¿°æ€§ç»Ÿè®¡è¡¨æ ¼
    st.markdown("### æè¿°æ€§ç»Ÿè®¡")
    
    # ä¿å­˜æ‰€æœ‰æ•°æ®åºåˆ—
    series_data = {}
    
    # åŸå§‹æ•°æ®åºåˆ—
    if selected_var in df.columns:
        original_series = df[selected_var]
        original_series.name = f"{selected_var}_åŸå§‹æ•°æ®"
        series_data["åŸå§‹æ•°æ®"] = original_series
        
        # å¯¹æ•°å˜æ¢åºåˆ—
        if (original_series > 0).all():
            log_series = np.log(original_series)
            log_series.name = f"{selected_var}_å¯¹æ•°å˜æ¢"
            series_data["å¯¹æ•°å˜æ¢"] = log_series
        
        # ä¸€é˜¶å·®åˆ†åºåˆ—
        diff_series_data, _ = diff_series(original_series, diff_order=1, log_diff=False)
        diff_series_data.name = f"{selected_var}_ä¸€é˜¶å·®åˆ†"
        series_data["ä¸€é˜¶å·®åˆ†"] = diff_series_data
        
        # ä¸€é˜¶å¯¹æ•°å·®åˆ†åºåˆ—
        if (original_series > 0).all():
            log_diff_series, _ = diff_series(original_series, diff_order=1, log_diff=True)
            log_diff_series.name = f"{selected_var}_ä¸€é˜¶å¯¹æ•°å·®åˆ†"
            series_data["ä¸€é˜¶å¯¹æ•°å·®åˆ†"] = log_diff_series
    
    # ç”Ÿæˆæ‰€æœ‰åºåˆ—çš„æè¿°æ€§ç»Ÿè®¡è¡¨
    all_stats_dfs = []
    jb_stats = {}
    
    for name, series in series_data.items():
        try:
            stats_df, normality_test = generate_descriptive_statistics(series)
            stats_df['VARIABLES'] = [name]  # æ›¿æ¢ä¸ºåºåˆ—åç§°
            all_stats_dfs.append(stats_df)
            jb_stats[name] = {
                'JBç»Ÿè®¡é‡': normality_test['statistic'],
                'på€¼': normality_test['p_value'],
                'æ˜¯å¦æ­£æ€': "æ˜¯" if normality_test['is_normal'] else "å¦"
            }
        except Exception as e:
            st.warning(f"æ— æ³•è®¡ç®— {name} çš„æè¿°æ€§ç»Ÿè®¡: {str(e)}")
    
    # åˆå¹¶æ‰€æœ‰ç»Ÿè®¡è¡¨
    if all_stats_dfs:
        combined_stats_df = pd.concat(all_stats_dfs, ignore_index=True)
        
        # è¡¨æ ¼æ ¼å¼åŒ–: ä¿ç•™å°æ•°ç‚¹ä½æ•°ä¸º3ä½
        format_cols = ['mean', 'p50', 'sd', 'min', 'max', 'skewness', 'kurtosis']
        for col in format_cols:
            if col in combined_stats_df.columns:
                combined_stats_df[col] = combined_stats_df[col].apply(
                    lambda x: f"{x:.3f}" if pd.notnull(x) else "N/A"
                )
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåºä»¥æé«˜å¯è¯»æ€§
        ordered_cols = ['VARIABLES', 'N', 'mean', 'p50', 'sd', 'min', 'max', 'skewness', 'kurtosis']
        ordered_cols = [col for col in ordered_cols if col in combined_stats_df.columns]
        combined_stats_df = combined_stats_df[ordered_cols]
        
        # è®¾ç½®VARIABLESåˆ—ä¸ºç´¢å¼•ï¼Œä½¿è¡¨æ ¼æ›´æ¸…æ™°
        combined_stats_df = combined_stats_df.set_index('VARIABLES')
        
        # ä½¿ç”¨st.tableè€Œä¸æ˜¯st.dataframeï¼Œä»¥è·å¾—æ›´å¥½çš„é™æ€è¡¨æ ¼å±•ç¤º
        st.table(combined_stats_df)
    else:
        st.warning("æ— æ³•ç”Ÿæˆæè¿°æ€§ç»Ÿè®¡è¡¨")
    
    # ç„¶åæ˜¯åŸæ¥çš„ARIMAå‚æ•°è®¾ç½®éƒ¨åˆ†
    st.markdown("### ARIMAæ¨¡å‹å‚æ•°")
    
    # æ·»åŠ ä¸€ä¸ªæŒ‰é’®ï¼Œç”¨äºæ˜¾ç¤ºARIMAæ¨¡å‹å‚æ•°çš„è¯´æ˜
    arima_params_ar_col, arima_params_d_col, arima_params_ma_col = st.columns([1,1,1])
    with arima_params_ar_col:
        p_param = st.number_input(
            "p (ARé˜¶æ•°)",
            min_value=0,
            max_value=10,
            value=2
        )
    
    with arima_params_d_col:
        d_param = st.number_input(
            "d (å·®åˆ†é˜¶æ•°)",
            min_value=0,
            max_value=2,
            value=1
        )
    
    with arima_params_ma_col:
        q_param = st.number_input(
            "q (MAé˜¶æ•°)",
            min_value=0,
            max_value=10,
            value=2
        )



# Prophetå‚æ•°è®¾ç½®
with model_tabs[2]:
    st.markdown("### Prophetæ¨¡å‹å‚æ•°")
    
    prophet_params_left_col, prophet_params_right_col = st.columns(2)
    with prophet_params_left_col:
        yearly_seasonality = st.selectbox(
            "å¹´åº¦å­£èŠ‚æ€§",
            options=["auto", "True", "False"],
            index=0
        )
        
        weekly_seasonality = st.selectbox(
            "å‘¨åº¦å­£èŠ‚æ€§",
            options=["auto", "True", "False"],
            index=0
        )
    
    with prophet_params_right_col:
        daily_seasonality = st.selectbox(
            "æ—¥åº¦å­£èŠ‚æ€§",
            options=["auto", "True", "False"],
            index=0
        )
        
        changepoint_prior_scale = st.slider(
            "å˜ç‚¹å…ˆéªŒæ¯”ä¾‹",
            min_value=0.001,
            max_value=0.5,
            value=0.05,
            step=0.001,
            format="%.3f"
        )

# ç”¨äºåœ¨ä¼šè¯é—´ä¿å­˜æ¨¡å‹è®­ç»ƒçŠ¶æ€
if 'trained_models' not in st.session_state:
    st.session_state['trained_models'] = {}

# ç”¨äºä¿å­˜æ¨¡å‹è®­ç»ƒå†å²è®°å½•
if 'training_history' not in st.session_state:
    st.session_state['training_history'] = {}

# é¡µé¢åº•éƒ¨ - å¸®åŠ©ä¿¡æ¯
with st.expander("ä½¿ç”¨å¸®åŠ©"):
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜
    
    1. **æ•°æ®å‡†å¤‡**: åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢ä¸Šä¼ å¹¶å¤„ç†æ‚¨çš„æ•°æ®
    2. **ç‰¹å¾é€‰æ‹©**: é€‰æ‹©ç”¨äºè®­ç»ƒæ¨¡å‹çš„ç‰¹å¾
    3. **æ¨¡å‹å‚æ•°**: é…ç½®æ¨¡å‹çš„è¶…å‚æ•°
    4. **å¼€å§‹è®­ç»ƒ**: ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"æŒ‰é’®å¯åŠ¨è®­ç»ƒè¿‡ç¨‹
    5. **ä¿å­˜æ¨¡å‹**: è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä¿å­˜æ¨¡å‹ä»¥ä¾¿åç»­ä½¿ç”¨
    
    ### å‚æ•°è§£é‡Š
    
    #### LSTMå‚æ•°
    - **éšè—å±‚å¤§å°**: ç¥ç»ç½‘ç»œéšè—å±‚çš„èŠ‚ç‚¹æ•°é‡
    - **LSTMå±‚æ•°**: æ¨¡å‹ä¸­LSTMå±‚çš„æ•°é‡
    - **Dropoutæ¯”ä¾‹**: é˜²æ­¢è¿‡æ‹Ÿåˆçš„éšæœºä¸¢å¼ƒæ¯”ä¾‹
    - **å­¦ä¹ ç‡**: æ¢¯åº¦ä¸‹é™çš„æ­¥é•¿
    - **æ‰¹æ¬¡å¤§å°**: æ¯æ¬¡æ›´æ–°æƒé‡ä½¿ç”¨çš„æ ·æœ¬æ•°é‡
    - **è®­ç»ƒè½®æ•°**: å®Œæ•´æ•°æ®é›†çš„è®­ç»ƒæ¬¡æ•°
    
    #### ARIMAå‚æ•°
    - **p (ARé˜¶æ•°)**: è‡ªå›å½’é¡¹çš„é˜¶æ•°
    - **d (å·®åˆ†é˜¶æ•°)**: å·®åˆ†é˜¶æ•°ï¼Œä½¿åºåˆ—å¹³ç¨³
    - **q (MAé˜¶æ•°)**: ç§»åŠ¨å¹³å‡é¡¹çš„é˜¶æ•°
    """)

# lstmæ‰§è¡Œè®­ç»ƒçš„é€»è¾‘
if 'start_training' in st.session_state and st.session_state['start_training']:
    # å‡†å¤‡ç‰¹å¾æ•°æ®
    # ç¡®ä¿selected_featureså·²å®šä¹‰ä¸”ä¸ä¸ºç©º
    if 'selected_features' not in locals() or not selected_features:
        st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ç”¨äºè®­ç»ƒ")
        st.stop()
    
    # ç¡®å®šä½¿ç”¨å“ªä¸ªæ•°æ®é›†è¿›è¡Œè®­ç»ƒ
    if 'tech_indicators' in st.session_state and st.session_state['tech_indicators'] is not None:
        # ä¼˜å…ˆä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        train_df = st.session_state['tech_indicators']
        st.info("ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®è¿›è¡Œè®­ç»ƒ")
    elif 'raw_data' in st.session_state and st.session_state['raw_data'] is not None:
        # å¦‚æœæŠ€æœ¯æŒ‡æ ‡æ•°æ®ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
        train_df = st.session_state['raw_data'] 
        st.warning("æœªæ‰¾åˆ°æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œå°†ä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œè®­ç»ƒã€‚å»ºè®®å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
    else:
        st.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®ã€‚è¯·å…ˆåœ¨æ•°æ®æŸ¥çœ‹é¡µé¢åŠ è½½æ•°æ®å¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
        st.stop()
    
    # æ£€æŸ¥é€‰æ‹©çš„ç‰¹å¾æ˜¯å¦åœ¨æ•°æ®é›†ä¸­
    missing_features = [f for f in selected_features if f not in train_df.columns]
    if missing_features:
        st.error(f"ä»¥ä¸‹ç‰¹å¾åœ¨æ•°æ®é›†ä¸­ä¸å­˜åœ¨: {', '.join(missing_features)}")
        st.stop()
    
    # ä½¿ç”¨run_lstm_trainingå‡½æ•°æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹
    training_result = run_lstm_training(
        selected_features=selected_features,
        df=train_df,
        sequence_length=sequence_length,
        train_test_ratio=train_test_ratio,
        hidden_size=hidden_size,
        num_layers=num_layers,
        dropout=dropout,
        learning_rate=learning_rate,
        batch_size=batch_size,
        epochs=epochs,
        progress_placeholder=progress_placeholder,
        loss_chart_placeholder=loss_chart_placeholder
    )
    
    # æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°
    st.subheader("æ¨¡å‹è¯„ä¼°")
    
    # ä¿å­˜å½’ä¸€åŒ–å™¨ä»¥ä¾›åç»­é¢„æµ‹ä½¿ç”¨
    st.session_state['feature_scaler'] = training_result['feature_scaler']
    st.session_state['target_scaler'] = training_result['target_scaler']
    
    # æ›´æ–°å³ä¾§æ ä¸­çš„è¯„ä¼°æŒ‡æ ‡
    st.session_state['model_metrics'] = training_result['metrics']
    
    # æ˜¾ç¤ºä¿å­˜æˆåŠŸä¿¡æ¯
    st.success(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {training_result['model_path']}")
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state['trained_model'] = training_result['model']
    st.session_state['model_params'] = training_result['model_params'] if 'model_params' in training_result else None
    st.session_state['training_params'] = training_result['training_params'] if 'training_params' in training_result else None
    st.session_state['training_history'] = training_result['history']
    st.session_state['X_test'] = training_result['X_test']
    st.session_state['y_test'] = training_result['y_test']
    st.session_state['seq_length'] = training_result['sequence_length']
    
    # æ›´æ–°è®­ç»ƒçŠ¶æ€
    st.session_state['training_complete'] = True
    
    # æ˜¾ç¤ºè®­ç»ƒå®Œæˆæ¶ˆæ¯
    st.success("æ¨¡å‹è®­ç»ƒå·²å®Œæˆï¼")
    # é‡æ–°åŠ è½½é¡µé¢ä»¥æ›´æ–°å·¦ä¾§æ çŠ¶æ€
    st.rerun()