# 综合设计说明书

**项目名称：基于Streamlit的多模型时序预测系统**

**作者：(你的名字)**
**学号：(你的学号)**
**学院：(你的学院)**
**专业：(你的专业)**
**题目：基于Streamlit的多模型时序预测系统设计与实现**

**指导者：(你的导师名字)**

**日期：(完成日期)**

---

## 综合设计说明书摘要

(此处填写项目摘要，简要介绍项目背景、目的、主要功能和技术实现)

**关键词：** Streamlit、时序预测、LSTM、ARIMA、模型评估、Web应用、数据可视化

---

## 目 录

1.  **引言**
    1.1. 研究背景与意义
        1.1.1. 时序数据分析的重要性与金融市场挑战
            金融市场作为现代经济体系的核心组成部分，其价格发现机制和风险配置功能对宏观经济稳定具有重要意义。随着金融市场的日益复杂化和数据化，准确预测金融资产价格变动已成为学术界和实务界共同关注的重要课题。金融时间序列数据具有高频性、高维性和高噪声等特征，同时表现出显著的非线性、异方差性和时变性，这些特性使得传统的线性预测方法面临严峻挑战。

            金融资产价格的波动受到宏观经济基本面、市场微观结构、投资者行为偏差以及外部冲击等多重因素的综合影响，呈现出复杂的动态特征。有效的价格预测不仅对投资组合管理、风险控制和资产定价具有直接价值，更是金融市场有效性检验和货币政策传导机制研究的重要基础。

        1.1.2. 传统计量方法的局限性与深度学习的发展
            传统的时间序列计量方法，如自回归积分滑动平均模型(ARIMA)、广义自回归条件异方差模型(GARCH)等，在金融时间序列建模中发挥了重要作用。这些方法基于严格的统计理论基础，具有良好的可解释性和理论支撑。然而，传统方法通常基于线性假设和特定的分布假定，在处理金融市场中普遍存在的非线性关系、结构性突变和复杂依赖结构时存在固有局限性。

            近年来，深度学习技术在计算机视觉、自然语言处理等领域取得的突破性进展，为金融时间序列预测提供了新的研究范式。深度神经网络通过多层非线性变换，能够自动学习数据中的复杂模式和高阶特征交互，在处理高维、非线性和非平稳时间序列方面展现出显著优势。特别是长短期记忆网络(LSTM)等循环神经网络架构，通过门控机制有效解决了传统循环网络的梯度消失问题，在捕捉时间序列长期依赖关系方面表现突出。

            然而，深度学习方法也面临模型复杂度高、可解释性不足、对数据质量要求严格等挑战。因此，在实际应用中，传统计量方法与深度学习技术的有机结合，能够充分发挥各自优势，为金融时间序列预测提供更加稳健和全面的解决方案。

        1.1.3. 交互式分析平台的研究价值
            随着数据科学和机器学习技术的快速发展，构建用户友好的交互式分析平台已成为促进理论研究向实际应用转化的重要途径。传统的命令行工具和静态分析报告难以满足现代数据分析的交互性和实时性需求。基于Web的交互式平台能够为研究人员和实务工作者提供直观的数据探索、模型配置、训练监控和结果评估环境，显著降低了高级分析技术的使用门槛。

            此外，交互式平台还具有重要的教学和研究价值。通过可视化的界面和实时的反馈机制，用户能够更好地理解模型的工作原理、参数对结果的影响以及不同方法的适用场景，从而促进理论知识与实践应用的深度融合。

    1.2. 研究目标与主要内容
        1.2.1. 研究目标
            本研究旨在设计并实现一个基于Streamlit框架的多模型时间序列预测系统，该系统集成传统计量方法与深度学习技术，为金融时间序列分析提供完整的建模工作流。具体目标包括：
            (1) 构建涵盖数据预处理、特征工程、模型训练和性能评估的完整分析流程；
            (2) 实现ARIMA和LSTM等代表性预测模型的集成与比较；
            (3) 开发用户友好的交互式界面，支持参数配置、训练监控和结果可视化；
            (4) 建立标准化的模型评估体系，支持多维度性能比较和分析。

        1.2.2. 主要研究内容
            本研究的核心内容包括以下几个方面：

            **数据处理与特征工程模块：** 实现金融时间序列数据的标准化预处理流程，包括数据清洗、缺失值处理、异常值检测等基础功能。集成常用技术指标计算方法，如移动平均线、相对强弱指数(RSI)、移动平均收敛发散指标(MACD)、布林带等，为后续建模提供丰富的特征变量。设计交互式数据可视化组件，支持K线图、趋势图、相关性分析等多种展示方式。

            **多模型预测框架：** 
            - ARIMA模型实现：基于经典时间序列理论，实现完整的ARIMA建模流程，包括平稳性检验、模型识别、参数估计和诊断检验。支持自动参数选择和手动参数配置两种模式，提供残差分析和预测区间估计功能。
            - LSTM模型实现：基于PyTorch框架构建深度学习预测模型，支持灵活的网络结构配置，包括隐藏层维度、网络深度、正则化参数等。实现特征选择机制，包括相关性分析、方差膨胀因子(VIF)检验和统计显著性检验。

            **模型评估与比较系统：** 建立多维度的模型性能评估体系，包括均方误差(MSE)、均方根误差(RMSE)、平均绝对误差(MAE)、决定系数(R²)和方向准确率等指标。设计可视化比较工具，支持预测结果对比、误差分析和模型诊断。实现评估报告的自动生成和导出功能。

            **交互式用户界面：** 基于Streamlit框架设计多页面Web应用，提供直观的操作界面和实时反馈机制。实现会话状态管理，确保用户操作的连续性和数据的一致性。

    1.3. 技术路线与可行性分析
        1.3.1. 技术架构选择
            本研究采用基于Python生态系统的技术架构，主要考虑因素如下：

            第一，Streamlit框架的优势。Streamlit作为新兴的数据应用开发框架，具有开发效率高、学习成本低、部署便捷等特点。其基于Python的纯代码开发模式与数据科学工作流高度契合，能够快速将研究原型转化为可交互的应用系统。框架提供的丰富组件库和自动化状态管理机制，显著简化了复杂交互逻辑的实现。

            第二，Python生态系统的完备性。Python在数据科学和机器学习领域拥有成熟完善的生态系统。NumPy和Pandas提供了高效的数值计算和数据处理能力；Statsmodels实现了完整的统计建模功能；PyTorch提供了灵活的深度学习框架；Matplotlib、Plotly和ECharts等可视化库支持丰富的图表展示需求。这些库的有机结合为本研究提供了坚实的技术基础。

        1.3.2. 模型选择的理论依据
            ARIMA模型作为时间序列分析的经典方法，具有坚实的理论基础和广泛的应用验证。其线性建模框架虽然相对简单，但在处理具有明确趋势和季节性特征的时间序列时仍具有良好的预测性能。更重要的是，ARIMA模型的可解释性强，能够为复杂的深度学习模型提供基准比较。LSTM网络通过门控机制有效解决了传统循环神经网络的梯度消失问题，在处理长序列依赖关系方面具有显著优势。其非线性建模能力使其能够捕捉金融时间序列中的复杂模式，特别适合处理多变量、高频和非平稳的金融数据。ARIMA和LSTM代表了时间序列预测的两种不同范式——统计建模和机器学习。两者的结合能够充分发挥各自优势，为不同特征的数据和应用场景提供最适合的建模方案。

        1.3.3. 技术可行性评估
            本研究所选择的技术栈均为开源项目，拥有活跃的社区支持和完善的文档体系。相关库的API稳定，版本兼容性良好，为项目的顺利实施提供了保障。与此同时，ARIMA模型的计算复杂度相对较低，普通计算环境即可满足需求；LSTM模型虽然计算量较大，但通过合理的模型设计和参数配置，在CPU环境下也能实现有效训练。如有GPU资源，可进一步提升训练效率。进一步地，本研究采用模块化的系统设计和标准化的代码规范，确保系统具有良好的可扩展性。此外，多页面应用架构为后续功能扩展提供了灵活的框架支持。最后，Web界面的直观性和交互性能够有效降低用户的学习成本，提高系统的实用价值和推广潜力。综上所述，本研究在技术上具有较强可行性。

    1.4. 论文结构安排
        本文的组织结构如下：
        第一章：引言。主要介绍项目的研究背景、意义、目标、主要研究内容以及技术选型和可行性。
        第二章：相关技术与理论基础。详细阐述Streamlit框架、时间序列预测模型以及相关的评估方法等。
        第三章：系统需求分析。从功能需求、非功能需求和用户场景等方面对系统进行全面分析。
        第四章：系统设计。阐述系统的总体架构、各主要功能模块（数据查看、模型训练、模型评估）的设计思路和核心工具函数设计。
        第五章：系统实现。具体描述开发环境、数据处理流程、LSTM和ARIMA模型的具体实现细节、模型评估与报告生成的实现方式。
        第六章：系统测试与分析。介绍测试策略、功能测试和非功能测试的执行情况，分析测试结果和遇到的问题，并对未来测试工作进行展望。
        第七章：总结与展望。对整个项目进行总结，归纳主要成果和创新点，分析存在的不足，并对未来的改进方向和扩展功能进行展望。

2.  **相关技术与理论基础**
    2.1. Streamlit框架介绍
        Streamlit是一个基于Python的开源Web应用框架，专门为数据科学和机器学习应用的快速开发而设计。该框架采用声明式编程范式，允许开发者使用纯Python代码构建交互式Web应用，无需掌握传统的前端技术栈。

        2.1.1. 核心技术特性
            Streamlit的技术架构基于脚本重新运行机制，即当用户与界面组件交互时，整个Python脚本会重新执行，并智能更新发生变化的界面元素。这种设计简化了状态管理的复杂性，使开发者能够专注于业务逻辑的实现。框架提供了内置的缓存机制，通过装饰器形式的缓存策略有效避免重复计算，提升应用性能。

            在组件体系方面，Streamlit提供了完整的用户界面组件库，涵盖数据展示、用户输入和页面布局三个层面。数据展示组件支持多种数据类型的智能渲染，包括文本、表格、图表和媒体文件。用户输入组件提供了丰富的交互控件，如滑块、选择框、按钮等，支持实时数据绑定。页面布局组件通过列布局、侧边栏、标签页等方式实现复杂界面的组织。

        2.1.2. 多页面应用架构
            Streamlit的多页面应用架构采用约定优于配置的设计理念。通过在项目根目录下创建pages子目录，并将各功能模块的Python脚本放置其中，框架会自动识别并生成导航结构。这种架构模式支持功能模块的独立开发和维护，同时通过session_state机制实现跨页面的数据共享和状态管理。

            本研究采用该架构模式，将数据处理、模型训练和模型评估三个核心功能分别实现为独立页面，既保证了功能的模块化，又确保了用户操作的连贯性。

        2.1.3. 交互机制与状态管理
            Streamlit的交互机制基于响应式编程模型，用户的每次交互都会触发脚本的重新执行。为了在多次执行间保持数据状态，框架提供了session_state对象，支持复杂数据结构的持久化存储。这种机制特别适合数据分析应用中的中间结果保存和跨步骤的数据传递。

    2.2. 时序预测模型
        时间序列预测是计量经济学和机器学习的重要研究领域，涉及从历史观测数据中学习时间依赖模式，并据此预测未来值。本研究选择ARIMA和LSTM作为代表性方法，分别体现了统计建模和深度学习两种不同的建模范式。

        2.2.1. ARIMA模型理论基础
            ARIMA模型是时间序列分析的经典方法，其理论基础建立在平稳随机过程理论之上。该模型通过自回归、差分和移动平均三个组成部分，能够有效处理具有趋势性和自相关性的时间序列数据。

            平稳性是ARIMA建模的核心前提。严格平稳要求时间序列的联合分布不随时间平移而改变，而弱平稳则仅要求一阶矩和二阶矩的时间不变性。在实际应用中，通常采用单位根检验方法评估序列的平稳性，其中ADF检验是最为常用的检验方法。对于非平稳序列，差分操作是实现平稳化的主要手段，通过消除趋势成分将非平稳序列转换为平稳序列。

            模型识别过程主要依赖自相关函数和偏自相关函数的分析。ACF反映序列在不同滞后期的总体相关性，而PACF则测量剔除中间变量影响后的直接相关性。通过观察ACF和PACF的截尾和拖尾特征，结合信息准则的比较，可以确定模型的最优阶数。参数估计通常采用极大似然估计方法，而模型诊断则通过残差分析验证模型的充分性。

        2.2.2. LSTM网络架构
            LSTM网络是循环神经网络的重要变体，专门设计用于解决传统RNN在处理长序列时面临的梯度消失问题。其核心创新在于引入了门控机制，通过遗忘门、输入门和输出门的协调控制，实现对信息的选择性记忆和遗忘。

            LSTM的细胞状态机制是其处理长期依赖关系的关键。细胞状态作为信息的载体，在时间步之间传递，而门控结构则决定哪些信息应该被保留、更新或输出。这种设计使得LSTM能够在长序列中保持重要信息，同时过滤掉无关的噪声。

            在时间序列预测任务中，LSTM通过滑动窗口方法将时间序列转换为监督学习问题。输入序列的长度和特征维度是影响模型性能的重要超参数。数据预处理通常包括归一化操作，以确保不同尺度的特征能够得到平衡的学习。

        2.2.3. 模型比较与选择
            ARIMA和LSTM代表了时间序列建模的两种不同哲学。ARIMA基于严格的统计理论，具有良好的可解释性和理论基础，适合处理具有明确统计特征的时间序列。LSTM则依赖数据驱动的学习机制，能够自动发现复杂的非线性模式，特别适合处理高维、多变量的时间序列数据。

            在模型选择方面，需要综合考虑数据特征、计算资源和预测目标等因素。对于具有明确趋势和季节性的序列，ARIMA通常能够提供稳定的预测性能。而对于包含复杂非线性关系的序列，LSTM的表现往往更为优越。在实际应用中，两种方法的结合使用能够充分发挥各自优势，为不同场景提供最适合的建模方案。

    2.3. 模型评估指标
        在时序预测任务中，对模型性能的评估至关重要。选择合适的评估指标可以帮助我们了解模型的预测准确度、稳定性和泛化能力。

        2.3.1. 常用回归评估指标 (MSE, RMSE, MAE, R²)
            由于时序预测本质上是一种回归问题（预测未来的数值），因此许多标准的回归评估指标被广泛使用：
            *   **均方误差 (Mean Squared Error, MSE):** 计算预测值与实际值之差的平方的平均值。MSE对较大的误差给予较高的权重。公式为：
                \[ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \]
                其中，$n$ 是样本数量，$y_i$ 是实际值，$\\hat{y}_i$ 是预测值。MSE越小，模型性能越好。
            *   **均方根误差 (Root Mean Squared Error, RMSE):** MSE的平方根，与原始数据的单位相同，因此更易于解释。RMSE同样对大误差敏感。公式为：
                \[ RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} \]
                RMSE越小，模型性能越好。
            *   **平均绝对误差 (Mean Absolute Error, MAE):** 计算预测值与实际值之差的绝对值的平均值。MAE对所有误差给予相同的权重，对异常值不如MSE敏感。公式为：
                \[ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \]
                MAE越小，模型性能越好。
            *   **决定系数 (R-squared, R²):** 衡量模型对数据变异性的解释程度，表示预测值与实际值之间的相关性强度。R²的取值范围通常在0到1之间（对于非线性回归可能为负）。R²越接近1，说明模型拟合效果越好。公式为：
                \[ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} \]
                其中，$\\bar{y}$ 是实际值的平均值。

        2.3.2. 方向准确率等时序特有指标
            除了通用的回归指标外，在金融时序预测（如股价预测）中，预测价格变动的方向通常与预测价格的绝对值同等重要，甚至更重要。
            *   **方向准确率 (Directional Accuracy, DA):** 衡量模型预测价格变动方向（上涨、下跌或持平）的准确性。通常计算预测的变动方向与实际变动方向一致的样本比例。例如，如果 $y_t > y_{t-1}$ 且 $\\hat{y}_t > y_{t-1}$ (同为上涨)，或 $y_t < y_{t-1}$ 且 $\\hat{y}_t < y_{t-1}$ (同为下跌)，则认为方向预测正确。
                \[ DA = \\frac{1}{n-1} \\sum_{t=2}^{n} I((\\hat{y}_t - y_{t-1})(y_t - y_{t-1}) > 0) \]
                其中 $I(\\cdot)$ 是指示函数，当条件满足时为1，否则为0。方向准确率越高，模型对市场趋势的把握能力越强。
            *   **平均绝对百分比误差 (Mean Absolute Percentage Error, MAPE):** MAE的相对版本，表示预测误差占实际值的百分比。在比较不同尺度序列的预测性能时有用，但当实际值接近零或为零时可能出现问题。
                \[ MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100\\% \]
            *   **Theil's U统计量:** 用于比较预测模型的预测精度与简单预测方法（如朴素预测）的精度。

        在本项目中，我们主要关注MSE, RMSE, MAE, R²以及方向准确率来综合评估模型的性能。

    2.4. 数据可视化技术
        数据可视化在时序分析和模型评估中扮演着不可或缺的角色。它能帮助用户直观理解数据模式、模型行为和评估结果。

        2.4.1. ECharts图表库
            Apache ECharts是一款功能强大、配置灵活、使用广泛的开源可视化库。本项目选择Streamlit-Echarts作为主要的图表渲染工具，主要原因如下：
            *   **丰富的图表类型:** ECharts支持常见的折线图、柱状图、散点图、K线图、热力图、雷达图等，能够满足本项目多样化的可视化需求。
            *   **高度的交互性:** ECharts图表具有良好的内置交互功能，如数据区域缩放 (dataZoom)、提示框 (tooltip)、图例切换 (legend)、工具箱 (toolbox)（如保存为图片、数据视图切换）等，极大地提升了用户体验。
            *   **灵活的配置项:** 可以通过Python字典形式的配置项对图表的各个方面（如标题、坐标轴、系列、颜色、样式等）进行精细控制。
            *   **与Streamlit的良好集成:** `streamlit-echarts` 组件使得在Streamlit应用中嵌入和动态更新ECharts图表变得非常方便。
            *   **美观的视觉效果:** ECharts默认提供了多种主题和良好的视觉设计。

            在本项目中，ECharts被用于：
            *   `1_DataView.py`: 绘制K线图（包含成交量和移动平均线）、收盘价折线图、技术指标相关性热力图。
            *   `2_ModelTraining.py`: 绘制LSTM训练过程中的损失曲线、ARIMA模型预分析的ACF/PACF图、时间序列图、直方图、QQ图，以及模型训练完成后的预测对比图和残差分析图。
            *   `3_ModelEvaluation.py`: 绘制模型性能对比的雷达图和柱状图、预测结果对比的多序列折线图、预测散点图、误差分布图和残差时序图。

        2.4.2. Matplotlib/Seaborn (如有使用)
            虽然本项目主要依赖ECharts进行前端交互式可视化，但在某些后端数据分析或特定统计图形的生成过程中，可能会间接使用到Matplotlib。例如：
            *   **Statsmodels库的内置绘图:** `statsmodels` 库在进行某些统计分析（如QQ图 `sm.qqplot`）时，其默认的绘图后端是Matplotlib。如果需要将这类图表集成到Streamlit中，通常需要将其渲染为图片对象再显示。
            *   **Seaborn:** Seaborn是基于Matplotlib的高级可视化库，提供更美观的统计图形。如果项目未来需要更复杂的统计可视化且ECharts不直接支持，可能会考虑引入Seaborn。但在当前版本中，并非主要的可视化工具。

            本项目的策略是优先使用Streamlit-Echarts以获得最佳的Web交互体验。当需要特定统计图形且ECharts不易实现时，可以考虑使用Matplotlib/Seaborn生成静态图片并在Streamlit中展示。

    2.5. Python与相关库
        Python因其丰富的第三方库生态、简洁的语法和强大的数据处理能力，成为数据科学和机器学习领域的主流语言。本项目构建在Python之上，并依赖于以下核心库：

        2.5.1. Pandas, NumPy, Scikit-learn, Statsmodels, PyTorch
            *   **Pandas:** 是Python数据分析的核心库，提供了高性能、易用的数据结构（主要是DataFrame和Series）和数据分析工具。在本项目中，Pandas用于：
                *   加载和解析CSV数据。
                *   数据清洗、转换、筛选和重塑。
                *   时间序列数据的索引和操作。
                *   技术指标计算的中间步骤。
                *   组织模型输入输出数据。
            *   **NumPy (Numerical Python):** 是Python进行科学计算的基础包，提供了强大的N维数组对象、广播功能、以及用于处理数组的各种例程（如数学运算、线性代数、傅里叶变换等）。在本项目中，NumPy用于：
                *   高效的数值运算，特别是在数据预处理和模型计算中。
                *   作为Pandas DataFrame的底层数据结构。
                *   PyTorch等深度学习框架处理张量数据的基础。
            *   **Scikit-learn (Sklearn):** 是一个功能全面的机器学习库，提供了各种监督学习和无监督学习算法，以及模型选择、评估和数据预处理工具。在本项目中，Scikit-learn用于：
                *   数据预处理：如使用 `MinMaxScaler` 进行数据归一化。
                *   模型评估：使用 `mean_squared_error`, `mean_absolute_error`, `r2_score` 等函数计算模型性能指标。
                *   特征选择：如使用 `f_regression` 进行统计显著性检验。
                *   数据划分：如使用 `train_test_split`（尽管本项目主要手动按比例划分）。
            *   **Statsmodels:** 是一个专注于统计模型估计和推断的Python库，提供了广泛的统计模型和检验方法。在本项目中，Statsmodels的核心用途是：
                *   ARIMA模型：使用 `statsmodels.tsa.arima.model.ARIMA` 进行ARIMA模型的拟合、预测和诊断。
                *   时间序列分析工具：如ADF检验 (`adfuller`)、Ljung-Box检验 (`acorr_ljungbox`)、ACF/PACF图 (`plot_acf`, `plot_pacf` 的计算基础)等。
                *   统计绘图：如QQ图 (`qqplot`)。
            *   **PyTorch:** 是一个由Facebook开源的深度学习框架，以其灵活性和动态计算图而闻名。在本项目中，PyTorch用于：
                *   构建和训练LSTM神经网络模型 (`torch.nn.LSTM`, `torch.nn.Linear` 等模块)。
                *   定义损失函数 (`torch.nn.MSELoss`) 和优化器 (`torch.optim.Adam`)。
                *   处理张量 (Tensor) 数据，并支持GPU加速训练。

        这些库共同构成了本项目数据处理、模型构建、训练和评估的技术基石。

3.  **系统需求分析**
    本章将详细阐述基于Streamlit的多模型时序预测系统的各项需求，包括功能性需求和非功能性需求，并对典型的用户场景进行分析。

    3.1. 功能需求
        系统主要由数据查看与预处理、模型训练、模型评估三个核心功能模块组成，并通过主页面进行导航和状态展示。

        3.1.1. 主页面 (`Home.py`) 需求
            *   **系统介绍:** 提供项目的概览、目标和主要功能的简介。
            *   **导航功能:** 提供清晰的导航链接，方便用户在不同功能页面之间切换。
            *   **系统状态显示:** (可选) 展示当前系统的一些关键状态信息，例如已加载数据摘要、已训练模型概况等。
            *   **环境信息展示:** 显示如PyTorch版本、CUDA可用性等与模型运行环境相关的信息。

        3.1.2. 数据查看与预处理模块需求 (`1_DataView.py`)
            *   **数据加载:**
                *   支持用户上传CSV格式的本地时序数据文件。
                *   提供加载内置示例数据的功能，方便用户快速体验系统。
                *   自动或手动指定数据中的日期列、价格列（开盘、收盘、最高、最低）和成交量列。
                *   支持列名标准化，将常见的中文或不规范列名（如"日期"，"收盘价"）自动映射或引导用户映射到标准名称（如"Date"，"Close"）。
            *   **数据预览与探索:**
                *   以表格形式展示加载数据的头部和尾部样本。
                *   显示数据的基本统计描述信息（如均值、标准差、分位数等）。
                *   确保数据按时间顺序正确排序（升序）。
            *   **技术指标计算:**
                *   基于OHLCV数据，计算常用的技术指标，例如：
                    *   移动平均线 (MA5, MA10, MA20等)
                    *   相对强弱指数 (RSI)
                    *   移动平均收敛散度 (MACD)
                    *   布林带 (Bollinger Bands)
                    *   其他可选指标（如KDJ, OBV, ATR等，根据`ta`库支持情况）。
                *   允许用户选择要计算和显示的技术指标。
                *   以表格形式预览计算出的技术指标数据。
            *   **数据可视化:**
                *   **K线图与成交量图:** 使用ECharts等库绘制专业的K线图，并联动显示成交量柱状图及选择的移动平均线。
                *   **收盘价折线图:** 当OHLC数据不完整但包含收盘价时，显示收盘价的趋势折线图。
                *   **特征相关性热力图:** 计算并可视化主要价格特征及技术指标之间的相关系数矩阵。
                *   所有图表应支持交互式操作，如缩放、平移、数据点提示，并提供保存为图片的功能。
            *   **数据导出:**
                *   支持将原始数据导出为CSV文件。
                *   支持将计算后的技术指标数据导出为CSV文件。
                *   在导出前处理时间戳数据以兼容PyArrow等库。

        3.1.3. 模型训练模块需求 (`2_ModelTraining.py`)
            该模块需支持LSTM和ARIMA两种主流时序预测模型的训练，并提供Prophet模型的占位（未来可扩展）。
            *   **通用配置:**
                *   **数据显示与选择:** 显示已加载数据的基本信息（形状、时间范围）。
                *   **训练/测试集划分:** 允许用户通过滑块设置训练集和测试集的比例。
                *   **模型保存:** 提供保存已训练模型（包括模型参数、训练参数、训练历史）的功能，用户可自定义模型名称。
                *   **模型状态与评估简报:** 在侧边栏实时显示模型训练状态（等待、训练中、已完成）和关键评估指标（如MSE, RMSE, MAE）。
            *   **LSTM模型训练需求:**
                *   **特征选择:**
                    *   允许用户从原始数据列或计算得到的技术指标中选择用于LSTM模型训练的特征。
                    *   提供基于相关性阈值、方差膨胀因子(VIF)阈值、P值阈值的自动特征筛选功能。
                    *   可视化筛选过程的详细结果，如相关性矩阵热力图、VIF值表格、P值图表。
                *   **参数配置:** 允许用户配置LSTM模型的关键超参数，包括：
                    *   输入序列长度 (Sequence Length)
                    *   预测序列长度 (Prediction Length)
                    *   隐藏层大小 (Hidden Size)
                    *   LSTM层数 (Number of Layers)
                    *   Dropout比例
                    *   学习率 (Learning Rate)
                    *   批次大小 (Batch Size)
                    *   训练轮数 (Epochs)
                *   **训练控制:**
                    *   提供"开始训练"按钮。
                    *   支持启用/禁用早停 (Early Stopping) 机制。
                *   **训练过程可视化:**
                    *   实时显示训练进度条和状态文本。
                    *   动态绘制训练损失和验证损失曲线图。
                *   **结果展示:**
                    *   训练完成后，清晰展示模型在测试集上的评估指标（MSE, RMSE, MAE, 方向准确率）。
                    *   可视化预测结果：使用ECharts绘制实际值与LSTM预测值的对比折线图。
                    *   可视化预测散点图：实际值 vs. 预测值，并显示R²值。
                    *   展示误差分析图表：误差时间序列图、误差分布直方图。
                    *   提供模型详细信息（模型参数、训练参数、使用特征、训练历史摘要）的展开查看。
            *   **ARIMA模型训练需求:**
                *   **数据预处理与分析:**
                    *   允许用户选择要分析的单一变量（通常为收盘价）。
                    *   提供数据变换选项：原始数据、对数变换、一阶差分、一阶对数差分。
                    *   对处理后的序列进行**平稳性检验** (ADF检验)，并显示检验统计量和p值。
                    *   对处理后的序列进行**正态性检验** (如Shapiro-Wilk或K-S检验)，并显示结果。
                    *   对处理后的序列进行**白噪声检验** (Ljung-Box检验)，并显示结果。
                    *   显示处理后序列的**ACF和PACF图**，辅助用户判断模型阶数，并提供初步的模型建议（如AR(p), MA(q), ARMA(p,q)）。
                    *   可视化处理后序列的时间序列图、分布直方图和QQ图。
                    *   展示原始数据及不同变换后序列的描述性统计表格。
                *   **参数配置:**
                    *   **自动参数优化:** 提供基于信息准则 (AIC, BIC) 自动搜索最优ARIMA(p,d,q)参数的功能，用户可设定p,d,q的最大搜索范围。
                    *   **手动参数配置:** 允许用户手动设置p (AR阶数), d (差分阶数), q (MA阶数)。
                    *   **预测方法选择:** 支持动态预测和静态预测两种方式。
                    *   **运行次数:** 允许用户设置模型运行次数，进行多次训练以评估模型稳定性，并可选择基于何种指标（MSE, RMSE等）选择最优模型。
                *   **训练控制:** 提供"开始训练ARIMA模型"按钮。
                *   **训练过程显示:** 显示训练进度条和状态文本。
                *   **结果展示:**
                    *   训练完成后，若为多次运行，显示最优模型的运行次序和随机种子。
                    *   清晰展示模型在测试集上的评估指标（MSE, RMSE, MAE, 方向准确率）。
                    *   可视化预测结果：使用ECharts绘制实际值与ARIMA预测值的对比折线图。
                    *   可视化模型残差：残差时间序列图、残差分布直方图。
                    *   若为多次训练，显示各指标在多次运行中的统计信息（平均值、标准差、最小值、最大值）。

        3.1.4. 模型评估模块需求 (`3_ModelEvaluation.py`)
            *   **模型状态概览:**
                *   自动检测并显示当前已在会话中成功训练的模型的数量和类型 (LSTM, ARIMA)。
                *   基于关键性能指标（如RMSE），初步推荐"最佳模型"。
                *   简要展示各已训练模型的核心状态或指标。
            *   **评估配置 (侧边栏):**
                *   **模型选择:** 允许用户选择一个或多个已训练的模型进行对比评估。
                *   **评估指标选择:** 允许用户选择要在报告和图表中显示的评估指标 (MSE, RMSE, MAE, MAPE, 方向准确率, R²)。
                *   **评估时间段选择:** (当前默认为测试集，未来可扩展至训练集或全部数据)。
                *   **图表设置:** 允许用户调整图表高度，选择是否显示置信区间（如有）、是否显示残差分析等。
            *   **模型性能对比:**
                *   **指标表格:** 以表格形式清晰对比所选模型在所选评估指标上的表现。
                *   **雷达图:** 当选择多个模型时，使用雷达图从多个维度（如准确性、稳定性等，可预设或基于指标生成）可视化模型综合性能。
                *   **指标柱状图:** 为每个选定的评估指标生成柱状图，直观对比各模型在该指标上的优劣，并高亮最佳模型。
            *   **预测结果分析:**
                *   **预测对比图:** 在同一图表中绘制实际值以及所选模型的预测值（LSTM, ARIMA），方便直观比较。
                *   **数据对齐处理:** 解决因模型特性（如LSTM的序列输入）或参数不同导致的预测序列长度不一致问题，提供对齐策略（如按最小长度截断、按最大长度填充NaN）。
                *   **散点图:** 为每个选定的模型绘制"实际值 vs. 预测值"散点图，并显示R²值，评估预测一致性。
                *   **详细指标展示:** 在各模型散点图下方，详细列出其在当前对齐数据上的各项评估指标。
            *   **(暂时隐藏) 误差分析:** (未来可恢复)
                *   **误差时间序列图:** 绘制各模型预测误差（实际值-预测值）随时间变化的序列图。
                *   **误差分布直方图:** 绘制各模型预测误差的分布直方图，分析误差分布特性。
                *   **残差ACF/PACF图:** 绘制ARIMA模型残差的ACF和PACF图，检验残差是否为白噪声。
            *   **(暂时隐藏) 模型诊断:** (未来可恢复)
                *   提供更深入的模型诊断工具，如异方差检验、参数稳定性检验等。
            *   **详细评估报告:**
                *   **报告配置:** 允许用户选择报告包含的章节（如执行摘要、性能指标、预测分析、建议结论等）和报告格式（HTML预览、Markdown文本、JSON数据）。
                *   **报告生成与预览:** 根据用户配置动态生成评估报告，并在页面提供预览（如HTML直接渲染或Markdown文本展示）。
                *   **报告导出:** 提供将生成的报告下载到本地的功能，文件名包含时间戳和格式后缀。
                *   **数据导出:** 提供将本次评估所涉及的关键数据（如模型信息、性能指标、原始预测值等）导出为JSON文件的功能。

    3.2. 非功能需求
        3.2.1. **性能需求:**
            *   **数据加载与处理:** 对于中等大小的CSV文件（如几MB，数万行数据），数据加载和基础技术指标计算应在数秒内完成。
            *   **模型训练:** LSTM模型训练时间取决于数据量、特征数和参数配置，对于数千样本、中等复杂度模型，训练应在可接受的时间内完成（几分钟到几十分钟，并提供GPU加速支持提示）。ARIMA模型训练（包括自动参数寻优）应相对较快。
            *   **页面响应:** Streamlit页面交互应流畅，图表渲染不应导致明显卡顿。
            *   **并发处理:** (作为单用户桌面应用，并发需求较低，但应保证单用户操作的稳定性)。
        3.2.2. **易用性需求:**
            *   **界面直观友好:** 遵循Streamlit设计风格，界面布局清晰，元素组织合理。
            *   **操作便捷:** 用户应能通过简单的点击、选择、输入即可完成数据加载、模型配置、训练和评估等操作。
            *   **信息提示清晰:** 对用户的操作给予明确的反馈（如成功、失败、警告信息），关键参数提供帮助性提示文本(tooltips)。
            *   **错误处理:** 对可预见的错误（如文件格式错误、数据缺失、参数配置不当）进行捕获和友好提示，避免程序崩溃。
            *   **默认参数合理:** 为模型参数和配置选项提供合理的默认值，方便初学者快速上手。
        3.2.3. **可扩展性需求:**
            *   **模型扩展:** 系统架构应易于集成新的预测模型（如Prophet、其他深度学习模型）。
            *   **功能模块扩展:** 方便在现有页面添加新的分析功能或图表，或增加新的评估维度。
            *   **技术指标扩展:** 易于添加新的技术指标计算方法。
        3.2.4. **可靠性与准确性需求:**
            *   **数据处理准确:** 技术指标计算、数据变换（如差分、归一化）等应准确无误。
            *   **模型实现正确:** LSTM和ARIMA模型的实现应遵循其标准算法和常用实践。
            *   **评估指标计算准确:** 各项模型评估指标（MSE, RMSE等）的计算公式和方法应正确。
            *   **状态持久化:** 用户在会话中加载的数据、选择的参数、训练的模型状态应通过`st.session_state`有效保持，避免页面刷新或切换导致信息丢失。
            *   **代码健壮性:** 代码应具有较好的容错性，对异常输入和边界条件有处理。

    3.3. 用户场景分析
        以下是一些典型的用户使用场景：
        *   **场景一：快速数据探索与可视化**
            用户（如金融分析初学者、学生）上传自己的股票数据CSV文件，通过数据查看页面快速了解数据概况，查看K线图、收盘价走势，并计算常用技术指标，对数据进行初步的探索性分析。
        *   **场景二：ARIMA模型入门与实践**
            用户希望学习和实践ARIMA模型。他/她加载数据后，进入模型训练页面的ARIMA标签。首先选择目标序列，进行数据变换和预分析（平稳性、白噪声、ACF/PACF），然后使用自动参数优化功能获取推荐的(p,d,q)值，或手动设置参数，进行模型训练，并查看预测结果和残差分析。
        *   **场景三：LSTM模型调参与训练**
            用户（具有一定机器学习背景）希望使用LSTM模型进行预测。他/她选择多个特征，配置LSTM网络的各项参数（层数、隐藏单元、学习率等），开始训练，并实时观察损失曲线。训练完成后，查看详细的评估指标和预测对比图。
        *   **场景四：多模型性能对比与评估**
            用户已经分别训练了LSTM和ARIMA模型，希望对它们的性能进行全面对比。他/她进入模型评估页面，选择这两个模型，查看它们在各项评估指标上的表现（表格、雷达图、柱状图），并对比它们的预测曲线与实际值的吻合程度，最终选择一个表现更优的模型，并生成一份详细的评估报告以供参考或分享。
        *   **场景五：参数敏感性分析与模型迭代**
            用户在训练某个模型后，对其结果不完全满意。他/她会返回模型训练页面，调整某些关键参数（如LSTM的序列长度、ARIMA的阶数），重新训练模型，然后再次到模型评估页面比较不同参数下的模型性能，通过多次迭代找到最优的模型配置。

4.  **系统设计**
    本章将详细描述基于Streamlit的多模型时序预测系统的架构设计、各主要功能模块的详细设计以及核心工具函数的设计思路。

    4.1. 系统总体架构
        本系统采用基于Streamlit的多页面应用 (Multi-Page App) 架构。用户通过主应用入口 (`Home.py`) 启动，并通过Streamlit内置的侧边栏导航机制在不同的功能页面之间切换。每个主要功能模块（数据查看、模型训练、模型评估）都对应一个独立的Python脚本文件，存放于 `pages/` 目录下。

        4.1.1. 多页面应用结构设计
            *   **`Home.py` (主页/入口页):** 作为应用的起始点，展示项目介绍、主要功能导航、以及系统环境信息（如PyTorch版本、CUDA可用性）。
            *   **`pages/1_DataView.py` (数据查看页面):** 负责数据的加载、预览、基本统计分析、技术指标计算与可视化展示。
            *   **`pages/2_ModelTraining.py` (模型训练页面):** 提供LSTM和ARIMA模型的参数配置、特征选择、模型训练、训练过程监控和初步结果展示功能。
            *   **`pages/3_ModelEvaluation.py` (模型评估页面):** 用于对已训练的模型进行详细的性能对比、预测结果分析、误差分析以及生成和导出评估报告。
            *   **`src/` 目录:** 存放核心逻辑代码，包括：
                *   `src/models/`: 包含模型定义（如 `lstm_model.py`, `arima_model.py`）和训练逻辑。
                *   `src/utils/`: 包含各种工具函数，如数据处理 (`data_processing.py`)、图表生成 (`chart_utils.py`)、会话状态管理 (`session.py`)、可视化辅助 (`visualization.py`)等。
                *   `src/assets/`: (如果使用) 存放静态资源，如图片、CSS文件等。
            *   **`data/` 目录:** 存放示例数据文件和用户上传数据的临时存储（如果需要）。
            *   **`models/` 目录:** (如果使用) 存放用户保存的已训练模型文件。

        4.1.2. 模块划分与交互设计
            系统遵循"关注点分离"原则，将不同功能解耦到独立的页面和模块中：
            *   **数据流:** 用户首先在"数据查看"页面加载和预处理数据。处理后的数据（如原始数据DataFrame、技术指标DataFrame）通过 `st.session_state` 在不同页面间共享。
            *   **模型训练流程:** 用户在"模型训练"页面选择模型类型（LSTM/ARIMA），配置参数，选择特征（对于LSTM），然后启动训练。训练得到的模型对象、评估指标、预测结果等也存储在 `st.session_state` 中，供后续"模型评估"页面使用。
            *   **模型评估流程:** "模型评估"页面从 `st.session_state` 中读取已训练模型的信息和结果，进行对比分析和报告生成。
            *   **用户界面 (UI) 与后端逻辑分离:** Streamlit页面文件主要负责UI布局、组件创建和用户交互响应。核心的计算密集型任务（如技术指标计算、模型训练、复杂图表数据准备）则封装在 `src/models/` 和 `src/utils/` 下的函数中，保持页面代码的简洁性。

        4.1.3. 会话状态管理 (`st.session_state`)
            `st.session_state` 是Streamlit提供的用于在用户单次会话中跨页面、跨组件交互保存和传递数据的重要机制。本系统广泛使用 `st.session_state` 来管理：
            *   **已加载数据:** 如 `st.session_state['raw_data']`, `st.session_state['tech_indicators']`。
            *   **用户选择的参数:** 如 `st.session_state['selected_features']`, `st.session_state['train_test_ratio']`，以及各模型的超参数。
            *   **模型训练状态与结果:** 如 `st.session_state['lstm_training_complete']`, `st.session_state['arima_model']`, `st.session_state['model_metrics']`, `st.session_state['lstm_test_predictions']`, `st.session_state['arima_training_result']`。
            *   **UI控制状态:** 如某些图表的显示/隐藏状态，展开框的默认状态等。
            通过封装 `get_state` 和 `set_state` 等辅助函数（在 `src/utils/session.py` 中），可以更规范和便捷地操作 `st.session_state`。

    4.2. 数据查看页面设计 (`1_DataView.py`)
        此页面旨在提供全面的数据导入、探索、预处理和可视化功能。
        4.2.1. 界面布局与组件设计
            *   **主区域:** 采用自上而下的线性布局，依次展示数据加载、数据预览、基本统计、技术指标计算与预览、特征相关性矩阵、股票走势与成交量分析、数据导出等功能区。
            *   **数据加载区:** 使用 `st.file_uploader` 接受用户上传，辅以 `st.button` 或 `st.selectbox` 加载示例数据。
            *   **数据显示:** 使用 `st.dataframe` 或封装的 `safe_dataframe_display` 函数展示表格数据。统计信息使用 `df.describe()` 后展示。
            *   **技术指标选择:** 使用 `st.multiselect` 让用户选择要计算和展示的指标。
            *   **图表展示:** 使用 `streamlit_echarts.st_echarts` 组件渲染交互式图表。
            *   **数据导出:** 使用 `st.button` 触发导出逻辑，并通过 `st.download_button` 提供下载链接。
        4.2.2. 数据加载与预览逻辑
            *   `load_example_data()`: 加载内置CSV数据。
            *   `normalize_column_names()`: (在 `src/utils/data_processing.py`) 实现列名标准化逻辑，处理常见中英文名映射。
            *   `sort_by_date()`: 确保数据按日期升序排列。
            *   加载后数据存储于 `st.session_state['raw_data']`。
        4.2.3. 技术指标计算与显示
            *   `calculate_technical_indicators()`: 核心函数，接收DataFrame，利用 `ta` 库计算多种技术指标。对缺失必需列（如Open, High, Low, Close, Volume）的情况进行友好提示和部分计算。
            *   计算结果存储于 `st.session_state['tech_indicators']`。
        4.2.4. 数据可视化图表设计
            *   `create_echarts_kline_volume()`: (在 `src/utils/chart_utils.py`) 生成K线图与成交量图的ECharts配置项，支持MA均线叠加。对于数据不全的情况，能回退到显示收盘价折线图。
            *   `create_correlation_heatmap()`: (在 `src/utils/chart_utils.py`) 生成相关性矩阵热力图的ECharts配置项。
            *   所有图表配置中均包含 `toolbox` 以支持图片导出。

    4.3. 模型训练页面设计 (`2_ModelTraining.py`)
        此页面提供LSTM和ARIMA模型的完整训练流程，包括特征工程、参数调优、训练监控和结果初步评估。
        4.3.1. 界面布局与参数配置区设计
            *   **标签页结构:** 使用 `st.tabs` 分别创建"LSTM"、"ARIMA"和（预留的）"Prophet"标签页，每个标签页内包含对应模型的特定配置和操作。
            *   **侧边栏 (`st.sidebar`):** 用于放置全局性配置，如训练测试集划分比例、模型保存控件、以及模型状态和关键评估指标的实时概览。
            *   **参数区域:** 在各自模型的标签页内，使用 `st.columns` 合理布局参数输入控件（如 `st.number_input`, `st.slider`, `st.selectbox`, `st.checkbox`)，并为重要参数提供 `help` 提示。
        4.3.2. 特征选择功能设计 (LSTM)
            *   位于LSTM标签页内，允许用户从 `st.session_state['tech_indicators']` 或 `st.session_state['raw_data']` 的列中选择特征。
            *   `select_features()`: (在 `src/models/lstm_model.py`) 核心函数，根据用户设置的相关性、VIF、P值阈值进行特征筛选。
            *   使用 `st.expander` 分别展示相关性筛选、VIF筛选和统计显著性筛选的详细结果（表格和图表），图表使用 `create_correlation_heatmap` 和 `create_significance_charts` (在 `src/models/lstm_model.py`) 生成。
        4.3.3. LSTM模型训练流程设计
            *   **数据准备:** 从 `st.session_state` 获取选择的特征和原始/技术指标数据，进行序列创建 (`create_sequences`)、数据归一化 (MinMaxScaler)。
            *   **模型实例化:** 根据用户配置的参数（隐藏层大小、层数、Dropout等）创建 `LSTMModel` (在 `src/models/lstm_model.py`) 实例。
            *   **训练执行:** 调用 `train_lstm_model()` (在 `src/models/lstm_model.py`) 或集成的 `run_lstm_training()`，包含训练循环、损失计算、反向传播、参数更新。通过回调或直接在循环中更新Streamlit界面的进度条 (`st.progress`) 和损失曲线 (`st.line_chart` 或 `st_echarts`)。
            *   **评估与结果保存:** 训练完成后，调用 `evaluate_lstm_model()` 计算评估指标，生成预测值。模型对象、归一化器、训练历史、测试数据和预测结果等存入 `st.session_state`。
            *   `plot_training_history()`: 可视化训练和验证损失。
            *   `prepare_lstm_charts()`: (在 `pages/2_ModelTraining.py` 或 `src/utils/chart_utils.py`) 准备预测对比图和散点图的ECharts配置。
        4.3.4. ARIMA模型训练流程设计
            *   **数据准备与分析:** 用户选择单一时间序列，进行可选的数据变换（对数、差分）。调用 `check_stationarity`, `check_white_noise`, `analyze_acf_pacf` (均在 `src/models/arima_model.py`) 进行预分析，并使用 `create_timeseries_chart`, `create_histogram_chart`, `create_qq_plot`, `create_acf_pacf_charts` 可视化结果。
            *   **参数确定:**
                *   自动优化：`find_best_arima_params()` (在 `src/models/arima_model.py`) 根据AIC/BIC准则在指定范围内搜索p,d,q。
                *   手动指定：用户直接输入p,d,q值。
            *   **模型拟合:** 调用 `fit_arima_model()` (在 `src/models/arima_model.py`) 或集成的 `run_multiple_arima_models()` 进行模型训练。若选择多次运行，则循环训练并根据指定指标选择最优模型。
            *   **预测与评估:** 使用 `forecast_arima()` (动态/静态预测) 生成预测值，`evaluate_arima_model()` 计算评估指标。`check_residuals()` 检查残差特性。
            *   **结果保存与可视化:** 模型对象、参数、指标、预测值、残差等存入 `st.session_state`。`prepare_arima_charts()` (在 `src/models/arima_model.py`) 准备预测对比图、残差序列图和残差分布图的ECharts配置。
        4.3.5. 训练过程可视化与结果初步展示
            *   **LSTM:** 动态损失曲线、进度条。
            *   **ARIMA:** 进度条（尤其在多次运行或参数寻优时）。
            *   训练完成后，在各自标签页内直接显示核心评估指标和关键图表（预测对比图、散点图/残差图）。

    4.4. 模型评估页面设计 (`3_ModelEvaluation.py`)
        此页面专注于对一个或多个已训练模型的性能进行深入比较和综合评估。
        4.4.1. 界面布局与标签页设计
            *   **主区域:** 包含"模型状态概览"和多个功能标签页。
            *   **标签页:** 使用 `st.tabs` 实现 "模型对比"、"预测分析"、"详细报告"。（"误差分析"和"模型诊断"暂时隐藏，但设计上应预留其恢复空间）。
            *   **侧边栏 (`st.sidebar`):** 用于评估配置，包括模型选择、评估指标选择、图表参数（如高度）等。
        4.4.2. 模型状态概览与信息获取
            *   `check_model_availability()`: 检查 `st.session_state` 中是否存在已训练的LSTM和ARIMA模型及其相关结果（指标、预测等），汇总模型信息。
            *   在页面顶部使用 `st.metric` 简洁展示已训练模型数量、初步的最佳模型（如基于RMSE）以及各模型的核心状态。
        4.4.3. 模型性能对比模块设计
            *   位于"模型对比"标签页。
            *   **指标表格:** 将 `st.session_state` 中各选定模型的评估指标整理成DataFrame，使用 `st.dataframe` 展示。
            *   **雷达图:** `create_model_comparison_radar()` 根据预设维度或选择的多个评估指标，为多于一个模型时生成雷达图ECharts配置。
            *   **指标柱状图:** 为每个选定的评估指标，动态生成对比各模型表现的柱状图ECharts配置。
        4.4.4. 预测结果分析模块设计
            *   位于"预测分析"标签页。
            *   `get_prediction_data()`: 核心函数，从 `st.session_state` 中统一获取并对齐LSTM和ARIMA的实际测试值和预测值以及对应的日期序列。处理可能的数据长度不一致问题。
            *   `create_prediction_comparison_chart()`: 生成实际值与各模型预测值（可多条）的对比折线图ECharts配置。
            *   `create_scatter_plot()`: 为每个模型生成实际值vs预测值的散点图ECharts配置，并计算显示R²。
            *   `calculate_model_metrics()`: 重新在对齐后的数据上计算各模型的评估指标并展示。
        4.4.5. 详细评估报告生成与导出模块设计
            *   位于"详细报告"标签页。
            *   **报告配置:** 使用 `st.multiselect` 选择报告章节，`st.selectbox` 选择报告格式 (HTML, Markdown, JSON)。
            *   `generate_evaluation_report()`: 根据用户配置，动态组织模型信息、评估指标、图表（如果选择包含）等内容，生成相应格式的报告字符串。
            *   **报告预览:** HTML内容可通过 `st.components.v1.html` 或 `st.markdown(unsafe_allow_html=True)` 预览，Markdown内容可直接用 `st.markdown` 预览。
            *   **导出功能:** 使用 `st.download_button` 提供报告文件和评估数据（JSON格式，包含模型信息和指标）的下载。`make_json_serializable()` 辅助处理Numpy等特殊类型的JSON序列化。
        4.4.6. (未来展望) 误差分析与模型诊断模块设计思路
            *   **误差分析:** (恢复后) 将会包含 `create_error_distribution_chart` (误差分布直方图) 和 `create_residual_analysis_chart` (残差时序图，特别是ARIMA的残差ACF/PACF图)。
            *   **模型诊断:** (恢复后) 可集成更高级的检验，如ARIMA模型的参数稳定性检验、异方差检验 (ARCH-LM检验)；LSTM模型的注意力图可视化、特征重要性分析等。

    4.5. 核心工具函数设计 (`src/utils/`)
        `src/utils/` 目录存放项目共用的辅助函数，以提高代码复用性和可维护性。
        4.5.1. 数据处理工具函数 (`data_processing.py`)
            *   `normalize_column_names()`: 标准化CSV导入数据的列名。
            *   `fix_datetime_for_arrow()`: 修复DataFrame中的时间戳，确保与PyArrow等库的兼容性，用于数据导出或特定组件。
            *   (可能包含) 其他数据清洗、转换函数。
        4.5.2. 图表生成工具函数 (`chart_utils.py`)
            *   `create_echarts_kline_volume()`: 生成K线图和成交量图的ECharts配置。
            *   `create_correlation_heatmap()`: 生成相关性热力图的ECharts配置。
            *   (可能包含) 其他通用图表（如普通折线图、柱状图）的ECharts封装函数，供各页面调用。
        4.5.3. 会话管理工具函数 (`session.py`)
            *   `get_state(key, default_value)`: 安全地从 `st.session_state` 获取值，若键不存在则返回默认值并初始化。
            *   `set_state(key, value)`: 向 `st.session_state` 设置值。
            *   `update_states(updates_dict)`: 批量更新 `st.session_state`。
            *   (可能包含) 清理特定会话状态的函数。
        4.5.4. (可选) 可视化辅助函数 (`visualization.py`)
            *   如果存在 `ModelVisualization` 类，它可能封装了更复杂的、跨多个图表的模型结果可视化逻辑，或者提供一些标准化的图表主题和布局。

5.  **系统实现**
    本章将详细阐述系统关键功能的具体实现方法，包括所采用的核心库、算法、关键代码逻辑以及如何将它们整合进Streamlit应用中。

    5.1. 开发环境与主要依赖库
        *   **Python:** 主要编程语言 (版本 3.8+ 推荐)。
        *   **Streamlit:** Web应用框架，用于构建用户界面和交互逻辑。
        *   **Pandas:** 用于高效的数据处理和分析，核心数据结构为DataFrame。
        *   **NumPy:** 用于数值计算，特别是数组操作。
        *   **Scikit-learn:** 用于机器学习任务，如数据预处理 (MinMaxScaler)、模型评估指标 (MSE, MAE, R²)、特征选择辅助（如 `f_regression`）。
        *   **Statsmodels:** 用于统计建模，特别是ARIMA模型的实现 (`statsmodels.tsa.arima.model.ARIMA`)以及相关的统计检验（如ADF检验、Ljung-Box检验）。
        *   **PyTorch:** 用于深度学习模型的构建和训练 (LSTM模型)。
        *   **TA (Technical Analysis Library):** 用于计算各种金融技术指标。
        *   **Streamlit-Echarts:** 用于在Streamlit应用中集成 Apache ECharts，实现交互式数据可视化。
        *   **Matplotlib/Seaborn:** (可能用于辅助绘图或特定统计图，如QQ图的内部实现)。

    5.2. 数据加载与预处理实现 (`1_DataView.py`)
        5.2.1. 列名标准化实现
            在 `src/utils/data_processing.py` 中的 `normalize_column_names(df)` 函数实现。该函数维护一个映射字典，包含常见的中文或不规范列名到标准英文列名的映射（例如："日期" -> "Date"，"收盘价" -> "Close"）。遍历DataFrame的列，如果列名在映射字典的键中，则将其重命名为映射值。函数返回处理后的DataFrame和被重命名的列名信息，以便在UI上提示用户。

        5.2.2. 技术指标计算实现 (`ta` 库)
            在 `1_DataView.py` 的 `calculate_technical_indicators(df)` 函数中实现。首先检查输入DataFrame是否包含必需的OHLCV列（Open, High, Low, Close, Volume）。然后，利用 `ta` 库提供的各种指标类（如 `ta.momentum.RSIIndicator`, `ta.trend.MACD`, `ta.volatility.BollingerBands` 等）计算相应的技术指标。例如，计算RSI：`features['RSI'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()`。对于 `ta` 库计算失败或特定指标，提供了基于Pandas滚动窗口和基本数学运算的备用计算逻辑。计算结果（一个新的DataFrame）被存储在 `st.session_state['tech_indicators']` 中。

    5.3. LSTM模型实现 (`2_ModelTraining.py` & `src/models/lstm_model.py`)
        5.3.1. 特征选择实现
            在 `src/models/lstm_model.py` 的 `select_features()` 函数中实现，主要包含三个步骤：
            *   **相关性筛选:** 计算所有潜在特征与目标变量（默认为"Close"）之间的皮尔逊相关系数。保留相关系数绝对值大于用户设定阈值的特征。相关性矩阵和与目标变量的相关性数据会返回给UI展示。
            *   **方差膨胀因子 (VIF) 筛选:** 针对通过相关性筛选的特征，计算VIF值以检测多重共线性。迭代移除VIF值最高的特征，直到所有剩余特征的VIF值都低于用户设定的阈值，或者只剩一个特征。处理过程中会捕获并报告完全共线性的特征。
            *   **统计显著性筛选 (P值):** 对剩余特征，使用 `sklearn.feature_selection.f_regression` 计算F统计量和对应的P值。保留P值小于用户设定阈值的特征。
            每一步筛选的结果（选择的特征列表、相关统计数据）都会被记录并返回，以便在UI中通过 `st.expander` 展示详细信息。

        5.3.2. 序列数据创建与归一化
            *   **序列创建 (`create_sequences`):** 在 `src/models/lstm_model.py` 中。对于给定的特征数据和目标数据，该函数根据用户指定的 `sequence_length`（输入序列长度）和 `prediction_length`（预测序列长度）创建输入序列 (X) 和对应的输出序列 (y)。例如，若 `sequence_length=5`，`prediction_length=1`，则 X 的每个样本是连续5个时间步的数据，y 是第6个时间步的目标值。
            *   **数据归一化:** 使用 `sklearn.preprocessing.MinMaxScaler` 对特征数据和目标数据分别进行归一化到 [0, 1] 区间。特征数据按列（每个特征独立）归一化，目标数据单独归一化。归一化器对象 (scalers) 被保存下来，用于后续对预测结果进行反归一化，以及在模型评估时对新的测试数据进行相同的变换。

        5.3.3. PyTorch LSTM模型构建
            在 `src/models/lstm_model.py` 中定义 `LSTMModel(nn.Module)` 类。其核心结构包括：
            *   `nn.LSTM`: PyTorch的LSTM层，接收 `input_size` (特征数量), `hidden_size`, `num_layers`, `dropout` (如果 `num_layers > 1`), `batch_first=True` 等参数。
            *   `nn.Linear`: 一个或多个全连接层，将LSTM层的输出映射到预测目标维度 (`output_size`，通常为1，如果 `prediction_length > 1` 且模型设计为多点输出，则为 `prediction_length`)。
            *   `forward()` 方法定义数据的前向传播路径：数据首先通过LSTM层，然后取LSTM最后一个时间步的隐藏状态（或所有时间步的输出，取决于设计），最后通过全连接层得到预测结果。

        5.3.4. 训练循环与损失函数
            在 `src/models/lstm_model.py` 的 `train_lstm_model()` (或集成的 `run_lstm_training()`) 函数中实现。主要步骤：
            *   **数据加载器 (`DataLoader`):** 将训练数据和验证数据（如果划分了）封装成PyTorch的 `DataLoader`，以便进行批处理训练。
            *   **损失函数:** 通常选用均方误差损失 `nn.MSELoss()`。
            *   **优化器:** 通常选用 Adam 优化器 `torch.optim.Adam(model.parameters(), lr=learning_rate)`。
            *   **训练循环:** 迭代 `epochs` 次。
                *   模型设为训练模式 `model.train()`。
                *   遍历训练 `DataLoader` 中的每个批次：梯度清零 `optimizer.zero_grad()`，前向传播 `outputs = model(inputs)`，计算损失 `loss = criterion(outputs, targets)`，反向传播 `loss.backward()`，更新权重 `optimizer.step()`。
                *   (可选) 学习率调度器 `torch.optim.lr_scheduler`。
                *   (可选) 验证步骤：模型设为评估模式 `model.eval()`，在验证集上计算损失，用于早停或监控过拟合。
                *   **早停 (Early Stopping):** 监控验证损失，如果在一定 `patience` 轮次内没有改善，则提前终止训练。
            训练过程中的训练损失和验证损失被记录下来，用于绘制损失曲线，并通过Streamlit组件（如 `st.progress` 和 `st.line_chart` 的占位符）实时更新UI。

        5.3.5. 评估指标计算
            在 `src/models/lstm_model.py` 的 `evaluate_lstm_model()` 函数中。模型在测试集上进行预测，预测结果经过反归一化后，与真实的测试集目标值进行比较。使用 `sklearn.metrics` 中的函数计算 MSE, RMSE, MAE。方向准确率则通过比较预测值与实际值的变动方向（涨/跌）来计算。计算得到的指标字典存储在 `st.session_state` 中。

    5.4. ARIMA模型实现 (`2_ModelTraining.py` & `src/models/arima_model.py`)
        5.4.1. 时间序列分析实现
            在 `src/models/arima_model.py` 中封装了多个时间序列分析函数：
            *   `check_stationarity()`: 使用 `statsmodels.tsa.stattools.adfuller` (ADF检验) 判断序列平稳性。返回ADF统计量、P值和临界值等。
            *   `diff_series()`: 实现序列的差分操作，支持普通差分和对数差分。
            *   `check_white_noise()`: 使用 `statsmodels.stats.diagnostic.acorr_ljungbox` (Ljung-Box检验) 判断序列是否为白噪声。
            *   `analyze_acf_pacf()`: 计算并返回ACF (`statsmodels.tsa.stattools.acf`) 和PACF (`statsmodels.tsa.stattools.pacf`) 值及其置信区间，用于辅助模型定阶。
            这些函数的分析结果会以文本和图表（通过 `create_acf_pacf_charts` 等生成ECharts配置）的形式展示在UI上。

        5.4.2. `statsmodels.tsa.arima.model.ARIMA` 应用
            核心的ARIMA模型拟合通过 `statsmodels.tsa.arima.model.ARIMA(endog, order=(p,d,q), ...).fit()` 实现。其中 `endog` 是输入的一维时间序列（通常是处理过的平稳序列），`order` 是 (p,d,q) 参数。项目中使用 `fit_arima_model()` 函数封装了这一过程，并处理了可能的拟合错误。

        5.4.3. 参数自动寻优
            在 `src/models/arima_model.py` 的 `find_best_arima_params()` 函数中实现。该函数通过遍历用户指定的 (p,d,q) 参数范围组合，为每个组合拟合ARIMA模型，并根据用户选择的信息准则（AIC或BIC，通过 `results.aic` 或 `results.bic` 获取）来选择最优的参数组合。这个过程可能会比较耗时，UI上会显示进度提示。实践中，也可以考虑使用 `pmdarima.auto_arima` 库（如果项目引入）进行更高效的自动定阶，但当前项目是手动循环实现的。

        5.4.4. 残差分析实现
            模型拟合后，从结果对象（`results`）中获取残差 (`results.resid`)。`check_residuals()` 函数会对残差进行分析：
            *   绘制残差的时序图和直方图（使用 `create_timeseries_chart` 和 `create_histogram_chart`）。
            *   对残差进行白噪声检验（Ljung-Box检验），理想情况下残差应为白噪声。
            *   绘制残差的ACF和PACF图，理想情况下应无明显自相关。
            这些分析有助于判断模型是否充分提取了数据中的信息。

    5.5. 模型评估与报告生成实现 (`3_ModelEvaluation.py`)
        5.5.1. 多模型数据对齐逻辑
            在 `get_prediction_data()` 函数中，当LSTM和ARIMA都训练完成后，它们的测试集预测结果和实际值需要被对齐以便于比较。由于LSTM的序列处理可能导致其预测序列比ARIMA（通常在原始测试集上直接预测）短，或者由于用户不同的划分比例，该函数会尝试基于日期索引或序列长度进行对齐，通常会裁剪到共同的、最短的有效长度，或者根据用户选择的对齐策略进行处理。

        5.5.2. ECharts图表集成
            项目广泛使用 `streamlit_echarts.st_echarts` 组件显示各种交互式图表。每个图表（如K线图、相关性热力图、预测对比图、散点图、残差图等）都有一个对应的Python函数（通常在 `src/utils/chart_utils.py`, `src/models/` 或页面脚本中）负责生成符合ECharts规范的配置字典 (option)。这些配置字典详细定义了图表的类型、数据、坐标轴、图例、提示框、工具箱等元素。

        5.5.3. 报告动态生成逻辑
            在 `3_ModelEvaluation.py` 的 `generate_evaluation_report()` 函数中实现。根据用户选择的报告章节和格式：
            *   **HTML:** 通过拼接HTML字符串构建报告，包含基本的CSS样式。
            *   **Markdown:** 通过拼接Markdown语法的字符串构建报告。
            *   **JSON:** 构建一个嵌套的Python字典，包含所有报告信息，然后使用 `json.dumps()` 转换为JSON字符串。`make_json_serializable()` 函数用于预处理字典，将Numpy数组等非标准JSON类型转换为列表或Python原生类型。
            报告内容（如模型指标、最佳模型推荐）动态地从 `st.session_state` 中存储的模型信息和评估结果中提取。

    5.6. 会话状态管理实现 (`src/utils/session.py`)
        为了简化和规范对 `st.session_state` 的访问，`src/utils/session.py` 中定义了辅助函数：
        *   `get_state(key, default=None)`: 尝试从 `st.session_state` 中获取 `key` 对应的值。如果 `key` 不存在，则将 `key` 初始化为 `default` 值，并返回该默认值。
        *   `set_state(key, value)`: 直接将 `value` 赋给 `st.session_state[key]`。
        *   `update_states(updates_dict)`: 接收一个字典，遍历其中的键值对，并用它们更新 `st.session_state`。
        这些函数确保了在应用的任何地方以一致的方式访问和修改会话状态，减少了因键名错误或未初始化状态引发的问题。

6.  **系统测试与分析**
    本章主要阐述对Streamlit多模型时序预测系统进行的测试活动，包括测试策略、具体测试案例、已发现的一些典型问题及其分析，以及对系统性能的初步评估和未来测试工作的展望。

    6.1. 测试策略与环境
        *   **测试策略:** 本项目在开发阶段主要采用手动测试和探索性测试相结合的方式。针对每个新功能或修复的BUG，开发者会模拟用户操作，在Streamlit应用界面上进行交互测试。同时，针对核心算法和数据处理逻辑，会进行小规模的单元测试（例如，通过打印中间结果或使用 `assert` 语句进行验证）。
        *   **测试环境:**
            *   操作系统: Windows (开发和主要测试环境), （理论上Streamlit应用可跨平台运行，但未严格测试其他OS）
            *   浏览器: 主要在最新版 Chrome 浏览器上进行测试。
            *   Python及库版本: 与 “5.1. 开发环境与主要依赖库” 中列出的版本一致。
            *   硬件: 同时在有NVIDIA GPU（用于测试LSTM的CUDA加速）和无GPU的CPU环境下进行测试。

    6.2. 功能测试
        功能测试旨在验证系统是否按照需求规格说明书（或用户故事/功能点）正确实现了各项功能。

        6.2.1. 数据查看页面 (`1_DataView.py`) 测试
            *   **数据加载:**
                *   测试上传不同格式（但均为CSV）、不同大小的CSV文件，包括包含规范列名和不规范列名的文件。验证列名标准化功能是否按预期工作。
                *   测试加载内置示例数据功能是否正常。
                *   测试数据加载后的预览表格、统计信息是否正确显示。
            *   **技术指标计算:**
                *   选择不同的技术指标组合进行计算，验证计算结果是否在合理范围内（可与已知金融软件对比或手动小样本计算）。
                *   测试当输入数据缺少必要列（如无Volume列无法计算OBV）时，系统是否能给出友好提示并跳过相关指标的计算。
                *   测试技术指标数据预览表格和选择功能。
            *   **图表显示:**
                *   验证K线图（带成交量和MA均线）是否能正确渲染。测试在缺少部分OHLC数据时，是否能优雅降级显示收盘价折线图。
                *   验证相关性热力图是否能正确显示用户选择的特征间的相关性。
                *   测试所有图表的图片导出功能。
            *   **数据导出:**
                *   测试原始数据和技术指标数据导出为CSV文件的功能，验证导出文件的内容和格式是否正确，特别是日期和数值的格式。

        6.2.2. 模型训练页面 (`2_ModelTraining.py`) 测试
            *   **LSTM模型训练:**
                *   **特征选择:** 测试不同筛选阈值（相关性、VIF、P值）下的特征筛选结果是否符合预期，详细结果展开框是否能正确显示信息和图表。
                *   **参数配置:** 测试不同的LSTM超参数组合（序列长度、隐藏层大小、层数、学习率、批次大小、Dropout等）下的模型训练。
                *   **训练过程:** 验证训练进度条、损失曲线（训练/验证损失）是否实时更新。测试早停机制是否生效。
                *   **结果展示:** 验证训练完成后，评估指标（MSE, RMSE, MAE, 方向准确率）和预测对比图、散点图是否正确显示。
                *   **模型保存:** 测试模型保存功能，验证保存的文件是否完整。
            *   **ARIMA模型训练:**
                *   **数据预处理与分析:** 测试选择不同变量、不同数据变换方法（原始、对数、差分）后的数据展示、平稳性检验、白噪声检验、ACF/PACF图分析是否正确。
                *   **参数配置:**
                    *   测试自动参数优化功能（基于AIC/BIC），验证其是否能找到合理的(p,d,q)组合。
                    *   测试手动指定(p,d,q)参数进行训练。
                    *   测试不同预测方法（动态/静态）和运行次数（单次/多次）。
                *   **训练过程:** 对于多次运行，验证进度显示和最终最优模型的选择逻辑。
                *   **结果展示:** 验证评估指标、预测对比图、残差时序图、残差分布图是否正确显示。若多次运行，验证统计信息是否展示。
            *   **全局功能:**
                *   测试训练集/测试集划分比例的调整对两个模型训练数据量的影响。
                *   测试在未加载数据时，模型训练页面的行为（应提示先加载数据）。

        6.2.3. 模型评估页面 (`3_ModelEvaluation.py`) 测试
            *   **模型状态概览:** 验证在不同模型（仅LSTM, 仅ARIMA, 或两者均有）训练完成后，状态概览是否能正确显示已训练模型数量、最佳模型推荐和各模型核心指标。
            *   **模型对比:**
                *   测试选择不同模型组合进行对比，验证性能指标表格、雷达图（多于一个模型时）、指标对比柱状图是否正确显示和计算。
            *   **预测分析:**
                *   测试 `get_prediction_data()` 函数在不同场景下（如LSTM和ARIMA预测序列长度不一致）的数据对齐逻辑和结果。
                *   验证预测对比图（实际值 vs LSTM预测 vs ARIMA预测）和各模型的散点图是否正确显示。
                *   验证在对齐后的数据上重新计算的各项指标是否准确。
            *   **(已隐藏功能的回顾性思考)** 针对之前遇到的误差分析图表不显示问题，核心是确保导入正确的图表函数 (`create_timeseries_chart`, `create_histogram_chart` from `src.models.arima_model`) 并传入正确格式的Series/DataFrame数据（包含日期索引和数值）。
            *   **详细报告:**
                *   测试选择不同报告章节、不同报告格式（HTML, Markdown, JSON）下的报告生成与预览功能。
                *   测试报告内容是否准确反映了当前模型的评估结果。
                *   测试"导出报告"和"导出数据"功能，验证下载文件的格式和内容，特别是 `make_json_serializable` 对Numpy类型的处理。

    6.3. 非功能测试 (初步)
        6.3.1. 易用性测试
            主要通过开发者和（如果有的话）小范围用户的实际操作体验进行评估。Streamlit本身提供了良好的交互性，测试重点在于：
            *   导航是否清晰，用户能否方便地在不同页面和功能间切换。
            *   参数设置和选项是否易于理解，`help` 提示是否有效。
            *   错误提示和警告信息是否明确，能否引导用户正确操作。
            *   页面布局是否合理，信息展示是否过载或不足。

        6.3.2. 兼容性测试
            *   **GPU兼容性:** 项目包含 `gpu_test.py` 脚本，用于验证用户的GPU环境（NVIDIA显卡、CUDA、cuDNN）是否能被PyTorch正确识别和使用，这对于LSTM模型的训练加速至关重要。测试该脚本在不同GPU环境下的运行情况。
            *   **浏览器兼容性:** 主要在Chrome上测试，未来可扩展到Firefox, Edge等主流浏览器，检查是否存在渲染问题或功能异常。
            *   **Python库版本兼容性:** 确保在 `requirements.txt` 中指定的库版本组合下，系统能稳定运行。

        6.3.3. 性能考量
            目前未进行严格的量化性能测试，主要基于开发过程中的观察：
            *   **数据加载与技术指标计算:** 对于中等大小的CSV文件（如几万行），加载和技术指标计算速度尚可接受（秒级）。大型文件可能会有延迟。
            *   **模型训练时间:**
                *   LSTM: 训练时间受数据集大小、特征数量、序列长度、隐藏层复杂度、epochs等多种因素影响。在GPU环境下，训练速度显著快于CPU。对于中等规模问题，训练时间可能在几分钟到几十分钟。
                *   ARIMA: 单次模型拟合通常较快（秒级）。但参数自动寻优（遍历p,d,q组合）或多次运行（评估稳定性）时，总时间会显著增加。
            *   **图表渲染:** ECharts渲染复杂图表（如K线图、多序列对比图）在数据点过多时可能会有轻微延迟。
            *   **Streamlit应用响应:** 整体响应速度良好，但复杂页面或大量计算后的状态更新可能会有短暂卡顿。

    6.4. 测试结果与缺陷分析 (示例性)
        在开发过程中，通过不断的测试发现并修复了一些典型缺陷：
        *   **图表显示问题 (模型评估页):** 最初由于错误地调用了自定义的、未完善的图表函数，导致ARIMA模型的误差分析图表不显示。通过导入并使用模型训练页面中经过验证的 `src.models.arima_model` 中的图表函数，并确保传入的数据是带有正确索引的Pandas Series/DataFrame，问题得以解决。这强调了代码复用和接口一致性的重要性。
        *   **ARIMA图表函数导入路径问题:** 由于 `sys.path` 配置不当，导致模型评估页面无法正确导入 `src.models.arima_model` 中的函数。通过调整 `sys.path` 或确保项目结构支持直接相对导入解决。
        *   **Streamlit SetPageConfigMustBeFirstCommandError:** 在导入模块成功后立即调用 `st.success()` 触发。将这类UI反馈移至 `st.set_page_config()` 之后解决。
        *   **JSON序列化错误 (`TypeError: Object of type ndarray is not JSON serializable`):** 在导出评估数据时，`model_info` 中包含了Numpy数组。通过实现 `make_json_serializable` 辅助函数，在 `json.dumps()` 前递归转换Numpy类型为Python原生list/int/float，解决了问题。
        *   **数据类型不匹配导致PyArrow错误:** 在Streamlit组件（如 `st.dataframe` 或下载按钮）处理Pandas DataFrame时，如果包含特定精度的时间戳（如 `datetime64[ns]`）或某些特殊类型，可能会引发PyArrow序列化错误。通过 `fix_datetime_for_arrow` 函数将时间戳转换为微秒精度或字符串，以及确保数值类型正确，可以规避此类问题。
        *   **预测数据对齐问题:** LSTM和ARIMA模型的预测结果在长度和起始点上可能不一致，导致在模型评估页面对比时出现错误或误导性图表。通过在 `get_prediction_data` 中实现明确的数据对齐逻辑（如裁剪到共同长度）来缓解。

    6.5. 未来测试展望
        为进一步提升系统质量和稳定性，未来可以引入和加强以下测试工作：
        *   **单元测试 (Unit Testing):** 使用 `unittest` 或 `pytest` 框架，为核心工具函数（如 `src/utils/` 下的函数）和模型内部的关键算法（如特征选择逻辑、序列创建、特定指标计算）编写单元测试用例。
        *   **集成测试 (Integration Testing):** 测试不同模块间的交互，例如从数据加载到模型训练再到模型评估的完整流程，确保数据在各阶段正确传递和处理。
        *   **端到端测试 (End-to-End Testing):** 使用如 Selenium, Playwright 或 Cypress 等工具，模拟用户在Web界面上的完整操作流，自动化测试整个应用的功能。
        *   **性能基准测试 (Performance Benchmarking):** 对数据加载、模型训练（不同参数、不同数据规模）、图表渲染等关键操作进行量化性能测试，设定性能基准，并监控版本迭代间的性能变化。
        *   **健壮性与异常处理测试:** 构造异常输入（如格式错误的CSV、包含大量缺失值的数据、无效的模型参数配置），测试系统的错误处理能力和健壮性。
        *   **可用性与用户体验 (UX) 测试:** 招募真实用户进行场景化测试，收集反馈，持续优化界面设计和交互流程。

7.  **总结与展望**
    经过详细的需求分析、系统设计、实现与初步测试，基于Streamlit的多模型时序预测系统已初具规模，能够为用户提供从数据探索到模型训练、评估和报告生成的全流程支持。

    7.1. 项目总结
        7.1.1. 项目目标与完成度
            本项目旨在开发一个用户友好的、基于Web的时序预测应用，集成多种经典和现代预测模型（初期以LSTM和ARIMA为主），提供交互式的数据分析、模型训练和评估功能。目前，项目已基本达成初期目标：
            *   **数据处理与可视化:** 实现了CSV数据上传、列名标准化、多种技术指标计算和丰富的图表展示（K线图、相关性热力图、统计分布图等）。
            *   **LSTM模型模块:** 完成了特征选择（相关性、VIF、P值）、灵活的参数配置、基于PyTorch的训练与评估、损失曲线可视化、预测结果展示和模型保存功能。
            *   **ARIMA模型模块:** 完成了时序数据预分析（平稳性、白噪声、ACF/PACF）、自动/手动参数配置、基于Statsmodels的训练与评估、残差分析、预测结果展示。
            *   **模型评估模块:** 实现了多模型性能指标对比（表格、雷达图、柱状图）、预测结果对比（折线图、散点图）、数据对齐处理、以及详细评估报告的动态生成与多格式导出（HTML, Markdown, JSON）。
            *   **用户界面:** 基于Streamlit构建了清晰的多页面导航结构和友好的交互组件。

        7.1.2. 主要功能与创新点回顾
            *   **集成多模型框架:** 系统设计上支持未来方便地集成更多时序预测模型。
            *   **交互式探索:** 用户可以通过UI组件直观地进行参数调整、特征选择和结果比较，降低了时序建模的门槛。
            *   **全面的评估报告:** 自动生成包含摘要、指标、图表和建议的评估报告，并支持多格式导出，方便用户记录和分享结果。
            *   **端到端工作流:** 提供从数据接入到最终评估报告的完整工作流程支持。
            *   **教育与实验价值:** 系统不仅可用于实际预测任务，也可作为学习和实验不同时序模型特性的平台。

        7.1.3. 遇到的主要挑战与解决方案
            *   **图表渲染与数据类型:** Streamlit与ECharts集成时，对数据格式（尤其是时间序列的索引和Numpy/Pandas特定类型）有严格要求。通过数据清洗、类型转换（如`fix_datetime_for_arrow`）和标准化的图表生成函数解决。
            *   **模型间数据对齐:** LSTM和ARIMA处理数据的方式不同，导致预测序列在评估对比时需要仔细对齐。通过在评估模块中加入明确的数据对齐逻辑（基于长度或用户选择）来处理。
            *   **状态管理:** Streamlit的会话状态管理对于跨页面数据传递至关重要。通过封装 `get_state`, `set_state` 等工具函数进行规范化管理。
            *   **Python环境与包依赖:** 不同库版本间的兼容性可能引发问题。通过使用虚拟环境和维护 `requirements.txt` 来确保环境一致性。
            *   **计算性能:** 模型训练（尤其是LSTM和ARIMA的参数寻优）可能是计算密集型的。通过允许用户调整参数（如epochs）、利用GPU加速（对LSTM）以及在UI上提供进度反馈来改善用户体验。

    7.2. 未来工作展望
        7.2.1. 功能增强建议
            *   **集成更多模型:** 如Prophet、Transformer、N-BEATS、LightGBM等，丰富模型选择。
            *   **高级特征工程:** 增加自动特征生成、特征交叉、更复杂的特征变换方法（如小波变换）。
            *   **集成学习/模型融合:** 允许用户组合多个模型的预测结果，以期获得更稳健的性能。
            *   **超参数自动优化 (Advanced):** 集成如Optuna, Hyperopt等更专业的超参数优化库。
            *   **增量学习/在线学习:** 支持模型在新数据到来时进行增量更新，而非完全重新训练。
            *   **可解释性分析 (XAI):** 为LSTM等复杂模型引入SHAP, LIME等可解释性分析工具，帮助用户理解模型决策。
            *   **模型部署接口:** 提供将训练好的模型导出为可部署格式（如ONNX, PMML）或提供简单的API服务封装的选项。
            *   **数据源扩展:** 支持从数据库、API等更多来源加载数据。

        7.2.2. 性能优化方向
            *   **异步执行与缓存:** 对于耗时操作（如模型训练、复杂数据处理），研究使用Streamlit的缓存机制 (`@st.cache_data`, `@st.cache_resource`) 或异步执行方式，避免UI阻塞。
            *   **数据处理优化:** 使用更高效的Pandas操作，或在必要时考虑Dask等并行计算库处理大规模数据。
            *   **模型推理优化:** 对已训练模型进行剪枝、量化等操作，以加速预测过程（特别是在部署场景）。

        7.2.3. 测试体系完善
            *   **全面实施单元测试:** 为所有核心函数和模块编写详尽的单元测试。
            *   **建立集成测试和端到端测试:** 自动化测试关键的用户场景和工作流程。
            *   **引入持续集成/持续部署 (CI/CD):** 自动化测试和部署流程。

        7.2.4. 用户体验提升
            *   **更细致的错误处理与引导:** 提供更具体、更友好的错误信息和解决建议。
            *   **个性化配置保存:** 允许用户保存常用的参数配置、特征集等。
            *   **国际化与本地化:** 支持多语言界面。
            *   **更美观和可定制的UI主题。**

    7.3. 最终结论
        本项目成功构建了一个功能相对完善的交互式时序预测Web应用。它集成了数据处理、模型训练（LSTM和ARIMA）和详细评估功能，为用户提供了一个便捷的平台来进行时序分析和预测实验。通过Streamlit框架，实现了快速原型开发和友好的用户交互。尽管目前系统在性能、测试覆盖度和功能丰富性上仍有提升空间，但已为后续的迭代开发和功能扩展奠定了坚实的基础。我们相信，随着持续的改进和新技术的融入，该系统将能更好地服务于金融分析、学术研究等领域的时间序列预测需求。

8.  **参考文献**

**附录 (可选)**

(可以包含核心代码片段、复杂图表、用户手册等)

---
