# 基于深度学习的股票收益率预测与投资组合决策
## 引言

随着数据时代的来临，各行各业的数据规模爆发式增长，其中金融业作为数据密集型行业的典型代表，金融资产价格的预测与投资组合决策的优化问题给金融从业者以及相关研究人员带来了全新挑战[1]。由于金融市场受到宏观经济、投资者心理、政府政策等多方面影响，金融资产价格波动剧烈、噪声高，金融市场表现出非线性、不平稳性、复杂性、动态性等特点[2]，传统的计量分析方法在处理复杂的金融数据时存在一定的局限性。因此，学者们尝试利用基于机器学习的人工智能方法来解决传统统计学难以解决的问题，来为金融市场提供描述性、说明性和预测性模型[3]，传统机器学习方法被大量应用于金融资产预测特别是时间序列预测中，其中的支持向量机（SVR）、人工神经网络（ANN）应用最为广泛。近年来，深度学习凭借其在时间序列数据处理、图像识别和自然语言等方面的出色表现，在预测金融市场发展趋势方面逐步成为领导者。深度学习通过构建多层神经网络，来模仿和学习人类大脑的工作机制，以此来处理复杂的模式和数据。深度学习得益于其神经网络结构的设计，可以更好地学习输入特征与预测目标之间的非线性关系，并在包括股市预测等金融资产预测方面，表现出比线性统计模型和其他经典机器学习方法更加优越的性能[4]。

1952年，Markowitz提出了著名的均值方差分析模型（Mean-Variance，MV）[5]。该模型以各备选资产的预期收益率量化收益，以各资产收益率间的方差-协方差矩阵量化风险，通过求解最优化问题构建理论最优投资组合，实现分散化投资，降低股价难以预测的不确定性带来的风险，提升投资组合的绩效[7]。均值方差分析模型被广泛应用于解决各类投资组合构建问题，具有重要的理论和实践意义。均值方差分析模型的分析，依赖于输入值的准确性，并对输入预测的准确性极为敏感，资产组合中的各资产超额收益率（资产预期收益率和无风险利率的差）的预测误差，将导致投资组合的绩效劣化[8,9]。目前，已经有许多研究表明，正确的投资组合管理可以在一定程度上战胜市场，在保证更低风险的同时获取更多的收益。一些学者利用机器学习的方法预测投资组合中的资产的收益率，以提高预测的准确度，进而提升投资组合模型的绩效。近年来深度学习的不断发展，让更多学者看到了深度学习在金融资产价格预测与投资组合优化决策方面的潜力，为金融市场的投资决策提供新的思路。

本综述基于中国知网（CNKI）数据库与Web of science核心合集数据库、的相关检索结果，将从金融领域中深度学习的常用模型介绍、股票收益率预测、投资组合决策三个方面进行综述。

## 金融领域深度学习概述

近年来，深度学习作为人工智能的重要分支，凭借其在时间序列处理、图像识别和自然语言处理等方面的出色表现，成为促进人工智能更好地应用于金融数据分析的的关键技术。深度学习是一类基于基于深度神经网络结构的机器学习模型，可以逐步从输入中提取高级特征，通过构建多层神经网络来模仿和学习人类大脑的工作机制，更好地处理对于传统机器学习方法难以处理的非线性问题。基于深度学习的时间序列预测模型发展脉络如图1所示，金融领域出现最多的深度学习模型主要有五种：BP神经网络、卷积神经网络(CNN)、循环神经网络(RNN)、长短期记忆神经网络(LSTM)、Transformer。

### BP神经网络

作为经典神经网络模型之一的 BP神经网络，是按误差进行逆传播算法训练的一种网络。BP神经网络由输入层、隐藏层和输出层组成，是误差反向传播算法的学习过程，是一种对非线性可微函数进行权重训练的多层高级神经网络。 它可以利用输出层的误差反馈来估计直接引导层的误差，进而计算出上一层可能存在的误差。在前向传播期间，模式作用于输入层。在隐藏层处理后，输入误差的反向传播阶段根 据特定的形式通过隐藏层为每一层返回一个输出误差给输入 层，并将其“分发”到每一层，以获得每个层单元的参考误差或误差信号。采用梯度下降法迭代模型和更新网络参数，不足之处在于模型训练收敛速度较慢。此外，BP 神经网络没 有自反馈调节机制，因此不具备记忆功能，对时间序列数据的预测精度有待进一步提高[10]。

### 卷积神经网络

CNN是一种受人类视觉机制启发的深度学习模型，主要用于图像分类、图像识别问题，后来也被用于文本分类。CNN主要利用卷积计算机制处理数据，提取相应的特征信息，从而完成对复杂模式和结构的学习。CNN主要由卷积层、池化层和全连接层构成。

![image-20240722115023278](https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202407221150766.webp)

<center><strong>CNN结构图

输入层获取原始输入，接下来特征提取层(包括卷积层和池化层)学习相关的特征。卷积层是 CNN 中核心的部分，通过应用滤波器对输入数据进行卷积操作，计算出不同位置的特征映射，从而提取抽象程度更高的特征。池化层也被称为降维方法，主要用于降低特征图维度的操作，同时保留图片最显著特征信息，这样就减少了输入的空间维度。最后，将特征提取层产生的特征传递到全连接层，全连接层将前面卷积层和池化层学习到的特征信息进行扁平化处理，并映射到神经网络的输出层。

CNN的优点是可以通过卷积自动对需要的特征进行提取，并且它还共享卷积核，可以用来处理高维数据，在局部特征信息提取、权值共享、平移不变性、归纳偏置能力等多方面具有明显的优势， 使得其模型拥有更好的泛化能力。CNN的缺点是有限感受野问题，使得其模型在捕捉全局特征信息、建模长距离依赖关系等方面存在突出的短板，在池化层采样的过程中丢失很多有用的信息，并且由于特征提取的封装，为改进网络性能罩了一层黑盒。

### 循环神经网络

RNN主要用于处理时间序列数据，包括音频、语音和语言等序列数据，由连续结构化的RNN单元组成，结合之前状态的RNN结构,如图2所示。用于传统预测分析的人工神经网络(Artificial Neural Network, ANN)模型不适用于序列数据，因为它们将每个输入视为一个独立的实体，而序列数据 中的观察结果不是相互独立的。与其他前馈网络不同的是， RNN使用内部存储器来处理传入的输入，在其操作过程中，逐个处理序列数据。值得注意的是，它考虑了处理序列中元素的时间因子，使用隐藏状态保留先前处理的观察结果，并在下一个将要处理的观察结果中使用。因此，RNN中的输出不仅取决于当前的输入，而且还取决于从网络先前隐藏状态计算出的输出。

![image-20240722115246455](https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202407221152824.webp)

<center><strong>结合之前状态的RNN结构图

RNN的特殊结构使其具有如下两个优点：首先，它可以针对任意长度的序列输入向量进行建模；其次，在处理序列数据时，可以考虑到每个时间步骤的前后信息。RNN中的信息通过循环传播，这使得模型可以使用相同的参数，从而降低参数的复杂度。RNN的缺点是不支持长期记忆并且面临梯度消失问题。

### 长短期记忆神经网络

LSTM是RNN的一种变体，LSTM网络由LSTM单元组 成。LSTM单元由输入门、输出门和遗忘门组成，这三个门控制着信息的流动。遗忘门决定应该保留或丢弃单元状态中的哪些信息，而输入门负责在单元状态中应该存储哪些新信息，输出门接收当前输入、先前隐藏状态输出和新计算的单元状态，以便为当前输入观察依次生成新的隐藏状态和输出。有了这些功能，每个单元格都会记住任意时间间隔内的所需值。基本的LSTM单元如图3所示(σ：sigmoid函数； tanh：双曲正切函数；×：乘法；+：加法)。

<img src="https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202407221154876.webp" alt="image-20240722115416505" style="zoom: 50%;" />

<center><strong>基本的LSTM单元

LSTM通过引入门控机制解决了RNN的缺点，如梯度消失和不支持长期记忆问题。LSTM网络的优势在于可以记住网络中的短期和长期值，因此被广泛应用于自动语音识别、语言 翻译、手写字符识别、时间序列数据预测等序列数据分析。

### Transformer

Transformer 是一种深度学习架构，是基于自注意力机制（Self-attention） 而非传统的循环神经网络的模型。它适用于多种序列数据处理任务，并在各个领域取得了显著的成功。Transformer的核心是 Self-attention 机制，在全局上下文信息的兼顾上表现极佳，在机器翻译和自然语言处理（NLP）领域展现出了强大的性能，例如基于Transformer的语言模型GPT-4[11]。Self-attention 机制在捕捉数据或特征的内部相关性方面优于传统方法，能更好地解决长距离依赖问题。Transformer拥有编码器栈（Encoder stack）和解码器栈（Decoder stack）， Encoder stack 和 Decoder stack 中分别为连续N 个具有相同结构的Encoder 和Decoder。每一个Encoder 和 Decoder 都是串联的组合，Encoder和Decoder都包含Self-attention 和前馈网络两个核心模块。Attention机制本质是加权求和以 获得对上下文的全局感知。Self-attention计算每个部件的权重，标明互相间的关系，Self-attention可以分解成Multi-head  attention，而前馈网络是根据这些权重进行一次变形。

![image-20240722142939672](https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202407221429204.webp)

<center><strong>基于Transformer的时间序列预测原理示意图[12]

Transformer 的时间序列预测原理如图所示，由嵌入部分、Encoder-Decoder 部分与逻辑回归部分组成。Transformer 输入模块首先通过一个嵌入层，对输入序列的每个数据进行词嵌入，将原本一维数据升维成二维矩阵，将新张量与位 置编码相加，并通过Multi-head attention 模块传递。Encod er-Decoder 的核心是Self-attention 机制，Transformer 神经网 络在Self-attention 机制的基础上升级为Multi-head attention 机制。Multi-head attention 模块是由单头注意力在输入序列中 的通道维度上划分成很多个头形成的，每个头使用不同的可 学习权重，对应生成不同的Q、K、V值。然后，Multi-headattention 模块的输出被传递到一个两层前馈网络，该网络的输入和输出以残差方式与层归一化连接[13]。逻辑回归部分由一个线性变换与Softmax映射组成，其作用是将Decoder的 输出回归到输出向量空间中并重新映射为下一时刻观察点的预测概率。

Transformer 具有长序列处理能力强、并行计算能力强、不受位置信息限制且具有全局感受野的优点。其缺点是：存在模型解释性较差、训练和调参复杂、对于输入数据的噪声不敏感、预测速度慢，以及还需要更多内存和计算资源的缺陷。

## 收益率预测

### 收益率预测的传统方法

如何对金融市场价格进行准确预测，一直是一个经典难题。由于金融市场的复杂性、高噪声和高波动性，及时预测金融市场走势具有很大的难度。金融市场价格预测问题的根源来自于对于有效市场假说（EMH）的争论。Fama提出：市场是有效的，任何关于资产价格的技术分析和基本面分析都是无效的[14]。许多学者对此提出质疑，他们通过传统计量模型如自回归模型（AR）、自回归条件异方差模型（ARCH）[15]、随机游走模型（Random Walk Theory）等以及机器学习的方法，建立线性模型通过回归得出了关于反对市场有效性的结论。

然而，伴随着数据的激增，金融市场变得更加复杂，金融数据中包含更多噪声以及更强不确定性，传统方法似乎不再奏效：依赖于严格假定的传统的参数模型，往往难以捕捉金融市场日益复杂的非线性因素；而传统的非参数估计虽然不需要对未知函数进行一致性估计，但在处理高维数据时却存在 “维数灾难”问题；传统机器学习虽然可以灵活地处理高维数据，但仍存在过度依赖人工设计、过拟合、收敛速度慢等缺陷[16]。

### 基于深度学习的股价预测方法
随着机器学习和人工智能算法的快速发展，与传统方法相比，基于深度学习的预测方法更有利于分析和预测具有非线性和波动性的股票变化趋势。近年来的相关实证研究逐渐展现了深度学习在解决金融市场价格预测问题上的优势。

针对股票预测，RNN及其变种成为最优先选择的深度学习模型。2018年，Hajiabotorabi等[17]采用优化的RNN预测了4种不同的股票价格。为了解决高噪声股票市场数据没有可学习的监督信息的问题，并保证交易决策的鲁棒性，Si等[18]采用四层全连接网络和LSTM对中国股市进行预测,通过不同权重的目标对模型进行训练，获得了更好的预测效果。2022年章宁[19]等人使用Transformer模型进行预测，并将预测结果与LSTM及SVR模型进行对比，取得了预期超额收益率预测的良好效果。

单一深度学习方法有其自身的优缺点。如DMLP具有解决复杂非线性模式的能力，但局部最小化会影响其训练过程；LSTM 虽然能够长时间记住信息并分析数据中的交互作用和隐藏模式，但在写入和读取数据时缺乏索引，计算费时。因此，部分研究尝试将两个或多个深度学习模型融合，以结合单一模型的优点构建新模型来改善性能。现有的许多研究已经表明集成学习方法比单一深度学习模型具有更好的性能。2018 年 Zhou 等人［20］提出了一个利用 LSTM和卷积神经网络（CNN）进行对抗性训练来预测高频股市的通用框架。2018年谷歌（Google）开发了一种双向的Transformer框架BERT（Bidirectional Encoder Representations from Transformers）[21]。2021年Lu等人［22］也是将CNN、双向长短期记忆神经网络（BiLSTM）与注意机制（AM）进行了结合，应用到上证综合指数上。2022 年 Darapaneni 等人［23］使用 LSTM 与随机 森林进行混合搭建，利用历史价格和可用的情绪数据来预测股票的未来走势。2022年Shi等 人［23］ 提出一种基于注意力机制的CNN-LSTM和极限梯度提升算法（XGBoost）混合模型来预测股价。2024年危冰淋[25]等人提出一种Transformer-LSTM多因素碳排放权交易价格预测的深度学习模型，同时运用SVR、MLP、LSTM、Transformer单一模型进行预测，结果表明Transformer-LSTM模型得到的预测价格与湖北省碳排放权交易价格 （HBEA）的实际价格更为吻合。

## 投资组合决策

Markowitz提出的均值方差分析模型有效地证明了通过构建投资组合、分散化投资实现相同风险水平下更高期望收益率的可行性[5]。在传统投资组合模型中，备选资产的预期超额收益率的预测误差将导致投资组合模型的投资绩效劣化。

一些研究采用机器学习方法对备选资产的收益率进行预测，以提高预测准确度，进而提升投资组合模型的绩效。部分研究人员试图在投资组合中应用LSTM、Transformer等模型，对组合收益进行预测。2018年LEE等[26]使用简单RNN，LSTM和GRU对未来股票收益进行预测，然后根据预测选择股票来构建基于阈值的投资组合，获得了较好的性能。2020年Wang等[27]深入探讨了最优投资组合形成之前的资产预选过程，从而保证了最优投资组合的高质量输入，然后结合了LSTM网络和Markovitz均值方差分析方法来构建投资决策模型。2020年张虎等人[29]运用自注意力神经网络模型结合过去60个交易日的因子数据预测沪深 300成分股未来一个月的价格变动趋势，从而选出前50 个上涨 概率最大的股票构建投资组合。2021年闫洪举[30]提出了一种基于深度自动编码器的方法，以确定构建指数跟踪组合所需的股票，并利用深度神经网络模型对个股的权重进行测算。2022年章宁[19]等人基于Transformer 模型的预测结果，通过传统投资组合模型来构建理论最优投资组合，将实证结果与LSTM和SVR模型进行对比，检验该模型对投资组合模型绩效具有显著提升能力。2024年刘祺[28]等人利用GARCH模型对数据集进行预处理，减少数据噪声，并引入BiLSTM网络减少训练损失，根据数据特征修改网络结构，提高预测精度，采用Bayes方法进行投资组合，构建了ARIMA GARCH-CNN-BiLSTM-AT-XGBoost模型，实现了较于其他混合模型更优的组合绩效。

## 结论

金融领域对于股价预测的深度学习模型主要有BP神经网络、卷积神经网络(CNN)、循环神经网络(RNN)、长短期记忆神经网络(LSTM)、Transformer模型，以及各类混合模型。这些模型在金融时间序列的预测上表现出了较于传统机器学习更有效的水平，可以更好地应对当下数据爆炸时代数据的非线性、复杂性、动态性等难题。更准确的预测有助于提升投资组合的绩效水平，并且基于深度学习的各类模型可以及时调整组合权重，实现投资组合动态优化，有望在因子选股、量化投资等方面发挥更大的作用。





## 参考文献

［1］ Guerard J B， Markowitz H， Xu Ganlin. Earnings fore⁃ casting in a global stock selection model and efficient port⁃ folio construction and management［J］. International  Journal of Forecasting. 2015，31（2）：550-560.

[2]Paiva F D, Cardoso R T N, Hanaoka G P, et al. Decision-making for Financial Trading: A Fusion Approach of Machine Learning and Port⁃ folio Selection [J]. Expert Systems With Applications,2019,(115).

[3]Andriosopoulos D. Computational Approaches and Data Analytics in Financial Services: A Literature Review [J].Journal of the Operational Research Society,2019,70(10).

 [4]Baek Y, Kim H Y. ModAugNet: A New Forecasting Framework for Stock Market Index Value With an Overfitting Prevention LSTM Mod⁃ ule and a Prediction LSTM Module [J].Expert Systems With Applica⁃ tions,2018,(113).

 [5]Markowitz H. Portfolio Selection [J].The Journal of Finance,1952,7(1).

 [7]戴玉林. 马科维兹模型的分析与评价[J].金融研究,1991,(9).

 [8]Best M J, Grauer R R. On the Sensitivity of Mean-variance-efficient Portfolios to Changes in Asset Means: Some Analytical and Computa⁃ tional Results [J].The Review of Financial Studies,1991,4(2). 

[9]Britten-Jones M. The Sampling Error in Estimates of Mean-variance Efficient Portfolio Weights [J].The Journal of Finance,1999,54(2).

[10]张伟豪.基于长短期记忆神经网络的股票时间序列预测[J].信息与电脑(理论版),2022,34(09):68-72.

 [11] OpenAI. GPT-4 Technical report[J]. ArXiv, abs/2303.08774. 

 [12]ASHISH V, NOAM S, NIKI P, et al. Attention is all you  need[J]. Conference on neural information processing sys tems, 2017, 30: 5998-6008.

[13]YI T, MOSTAFA D, DARA B, et al. Effi  cient transformers: a  survey[J]. ACM cOMPUTING surveys, 2023,55(6):1-28.

 [14]Fama E F.The behavior of stock-market prices [J].The Journal of Business,1965,38(1):34-105.

[15] ENGLE R E. Autoregressive conditional heteroskedastic⁃ ity with estimates of the variance of united kingdom in⁃ flation［J］.Econometrica，1982，50（50）：987-1007.

[16]苏治,卢曼,李德轩.深度学习的金融实证应用:动态、贡献与 展望[J].金融研究,2017(5):111-126.

[17] HAJIABOTORABI Z, KAZEMI A, SAMAVATI F F, et al. Improving DWT-RNN model via B-spline wavelet multiresolution to forecast a high frequency time series[J]. Expert Systems With Applications, 2019, 138:112842.

[18] SI W Y, LI J K, DING P, et al, A multi-objective deep reinforcement learning approach for stock index future's intraday trading[C]//10th International Symposium on Computational Intelligence and Design(ISCID). IEEE, 2017:431-436.

[19] 章宁,闫劭彬,范丹.基于深度学习的收益率预测与投资组合模型[J].统计与决策,2022,38(23):48-51.

[20] ZHOU X，PAN Z，HU G，et al. Stock market prediction on high-frequency data using generative adversarial nets ［J］.Mathematical Problems in Engineering，2018(4): 1-11.

[21] DEVLIN J, CHANG M W, LEE K, et al. Bert: Pre-training of deep bidirectional transformers for language understanding[J]. arXiv:1810.04805,2018.

[22] LU W，LI J，WANG J，et al. A CNN-BiLSTM-AM method for stock price prediction［J］. Neural Computing and Applications，2021，33（5）：4741-4753.

[23] DARAPANENI N，PADURI A R，SHARMA H，et al. Stock price prediction using sentiment analysis and deep learning for indian markets［EB/OL］. https://arxiv. org/abs/2204.05783，2022-04-07.

[24] SHI Z，HU Y，MO G，et al. Attention-based CNN LSTM and XGBoost hybrid model for stock prediction ［EB/OL］. https://arxiv.org/abs/2204.02623，2022-04 06.

[25]危冰淋,刘春雨,刘家鹏.基于Transformer-LSTM模型的多因素碳排放权交易价格预测[J].价格月刊,2024,(05):49-57.DOI:10.14076/j.issn.1006-2025.2024.05.06.

[26] LEE S I, YOO S J. Threshold-based portfolio: the role of the threshold and its applications[J]. The Journal of Supercomputing, 2018:1-18.

[27] WANG WY,LIWZ,ZHANG N,et al. Portfolio formation with preselection using deep learning from long term financial data [J]. Expert Systems with Applications, 2020, 143:113042.

[28]刘祺,施三支,娄磊,等.基于ARIAM-GARCH深度学习的股价预测与决策[J].长春理工大学学报(自然科学版),2024,47(01):119-130.

[29] 张虎,沈寒蕾,刘晔诚.基于自注意力神经网络的多因子量化选股问题研究[J].数理统计与管理,2020,39(03):556-570.

[30] 闫洪举.基于深度学习的指数跟踪方法研究[J].统计与决策,2021,37(05):143-147.